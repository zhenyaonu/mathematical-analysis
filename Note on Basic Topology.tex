\documentclass[12pt]{article}
\pagestyle{plain}
%\documentclass{article}
%\usepackage[utf8]{inputenc}
%\usepackage[english]{babel}

\usepackage{latexsym,amsmath,amssymb}
\usepackage{amsthm}
%\usepackage[notref,notcite]{showkeys}
\usepackage{amsfonts}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{lmodern}
\usepackage{pifont}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{thmtools}
\usepackage{wrapfig}
\usepackage{extarrows}
\usepackage{breqn}
\usepackage{physics}
\graphicspath{ {images/} }


\setlength{\oddsidemargin}{1pt}
\setlength{\evensidemargin}{1pt}
\setlength{\marginparwidth}{30pt} % these gain 53pt width
\setlength{\topmargin}{1pt}       % gains 26pt height
\setlength{\headheight}{1pt}      % gains 11pt height
\setlength{\headsep}{1pt}         % gains 24pt height
%\setlength{\footheight}{12 pt} 	  % cannot be changed as number must fit
\setlength{\footskip}{24pt}       % gains 6pt height
\setlength{\textheight}{650pt}    % 528 + 26 + 11 + 24 + 6 + 55 for luck
\setlength{\textwidth}{460pt}     % 360 + 53 + 47 for luck

\title{Sections and Chapters}

\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}{Proposition}[section]
\newtheorem{exercise}{Exercise}[section]
\newtheorem{remark}{Remark}[section]
\theoremstyle{definition}
\newtheorem{example}{Example}[section]
\numberwithin{equation}{subsection}

\def\dsp{\def\baselinestretch{1.35}\large
\normalsize}
%%%%This makes a double spacing. Use this with 11pt style. If you
%%%%want to use this just insert \dsp after the \begin{document}
%%%%The correct baselinestretch for double spacing is 1.37. However
%%%%you can use different parameter.


\def\U{{\mathcal U}}

\begin{document}

\centerline{\bf Note on Basic Topology}
\centerline{Zhen Yao}

\bigskip

\section{Euclidean Spaces}
\hspace*{1em}$\mathbb{R}^n$ is the $n$-field Cartesian product of $\mathbb{R}$, i.e., $\mathbb{R}^n = \mathbb{R}\times\mathbb{R}\times\cdots\mathbb{R} = \{(x_1,x_2,\cdots,x_n)|x_i\in\mathbb{R}, i=1,2,\cdots,n\}$. Also, $\mathbb{R}^n$ is a linear space with respect to the addition and multiplication  of points by scalars (i.e., real numbers) which are defined for $x=(x_1,x_2,\cdots,x_n)$ and $y=(y_1,y_2,\cdots,y_n), c\in\mathbb{R}$ as follows:
\begin{align*}
    x+y & = (x_1+y_1, x_2+y_2, \cdots, x_n+y_n)\\
    cx & = (cx_1,cx_2,\cdots,cx_n)
\end{align*}
so that $x+y \in\mathbb{R}^n$ and $cx \in\mathbb{R}^n$. We also define the inner product (or scalar product) of $x$ and $y$
\begin{align*}
    (x,y) = x\cdot y = \sum^n_{i=1}x_iy_i
\end{align*}
and the norm of $x$ by
\begin{align*}
    \left\|x\right\| = (x\cdot x)^{\frac{1}{2}} = \left(\sum^n_{i=1}x_i^2 \right)^{\frac{1}{2}}
\end{align*}
The structure now defined is called euclidean $n$-spaces. 

\medskip

\begin{theorem}
Suppose $x,y,z\in\mathbb{R}^n$ and $\alpha$ is real. Then 
\begin{enumerate}
    \item $\left\|x\right\|\geq 0$.
    \item $\left\|x\right\| = 0$ if and only if $x = 0$.
    \item $\left\|\alpha x\right\| = |\alpha|\left\|x\right\|$.
    \item $\left\|x\cdot y\right\| \leq \left\|x\right\|  \left\|y\right\|$, this is called Cauchy-Schwarz inequality.
    \item $\left\|x + y\right\| \leq \left\|x\right\| + \left\|y\right\|$, this is called Triangle inequality.
    \item $\left\|x - z\right\| \leq \left\|x - y\right\| + \left\|y - z\right\|$.
\end{enumerate}
\end{theorem}
\begin{proof}
We only proof (d). If $x = (0,0,\cdots,0) = 0$, or $y = 0$, then it is obvious. If $x \neq 0$ and $y\neq 0$, then for $t\in\mathbb{R}$, we have 
\begin{align*}
    0 \leq \left\|x+ty\right\| & = (x+ty, x+ty) \\
    & = (x,x) + 2t (x,y) + t^2(y,y)
\end{align*}
And we know that $(x,x) + 2t (x,y) + t^2(y,y)$ is a quadratic function which is not negative. Hence, we have 
\begin{align*}
    & \Delta = \left(2(x,y)\right)^2 - 4 (x,x)(y,y) \leq 0 \\
    \Rightarrow & \left\|(x,y)\right\| \leq \left\|x\right\|  \left\|y\right\|
\end{align*}
\end{proof}

\section{Metric Spaces}
\begin{definition}
A set $X$, whose elements we call points, is said to be a metric space if with any two points $x$ and $y$ of $X$ there is associated a real number $d(x,y): \mathbb{R}^n \times \mathbb{R}^n \rightarrow \mathbb{R}$ called the distance from $x$ to $y$, which is defined as 
\begin{align*}
    d(x,y) = \left\|x - z\right\|
\end{align*}
which has the following properties
\begin{enumerate}
    \item $d(x,y) > 0$ if $x\neq y$.
    \item $d(x,y) = 0$ if $x = y$.
    \item $d(x,y) = d(y,x)$.
    \item $d(x,y) \leq d(x,z) + d(z,y)$.
\end{enumerate}
\end{definition}

\medskip

\begin{definition}
Let $\{x_i\}^\infty_{i=1}$ be a sequence of points in $\mathbb{R}^n$ and $y\in\mathbb{R}^n$. We say that $\{x_i\}^\infty_{i=1}$ converges to $y$ if 
\begin{align*}
    \lim_{i\to\infty}\left\|x_i - y \right\| = 0
\end{align*}
Then we write $\lim_{i\to\infty}x_i = y$. Equivalently, $\lim_{i\to\infty}x_i = y$ if \begin{align*}
    \forall \varepsilon > 0, \exists N > 0, \forall n > N, d(x_n, y) < \varepsilon.
\end{align*}
\end{definition}

\medskip

\begin{theorem}
Let $x_i = (x_{1i}, x_{2i}, \cdots, x_{ni}) \in \mathbb{R}^n$, and $y = (y_{1}, y_{2}, \cdots, y_{n}) \in \mathbb{R}^n$. Then 
$$\lim_{i\to\infty}x_i = y$$ if and only if $$\lim_{i\to\infty}x_{ki} = y_k,k = 1,2,\cdots,n.$$
\end{theorem}
\begin{proof}
We have 
\begin{align*}
    \left\|x_i - y\right\| & = \sqrt{(x_{1i}-y_1)^2 + \cdots + (x_{ni}-y_1)^2} \\
    & \geq \sqrt{(x_{ki}-y_k)^2} = |x_{ki} - y_k|
\end{align*}
Hence, $\left\|x_i - y\right\| \to 0 \Rightarrow |x_{ki} - y_k| \to 0$.

On the other hand, if $|x_{ki} - y_k|$ as $i\to\infty$ for $k = 1,2,\cdots, n$, then
\begin{align*}
    \max_k |x_{ki} - y_k| \to 0 \quad \text{as}\quad i\to\infty
\end{align*}
and hence
\begin{align*}
    \left\|x_i - y\right\| & = \sqrt{(x_{1i}-y_1)^2 + \cdots + (x_{ni}-y_1)^2} \\
    & \leq \sqrt{n \max_k (x_{ki}-y_k)^2} \\
    & \leq \sqrt{n} \max_k |x_{ki} - y_k| \to 0.
\end{align*}
\end{proof}

\medskip

\begin{definition}
Let $(X,d)$ be a metric space and let $x_i\in X, i = 1,2,\cdots,$ and $x\in X$. We say that the sequence $\{x_n\}^\infty_{i=1}$ converges to $x$, saying
$\lim_{i\to\infty}x_i = x$ if $\lim_{i\to\infty}d(x_i, x) = 0$.
\end{definition}

\medskip

\begin{example}
Examples of metric spaces:
\begin{enumerate}
    \item $(\mathbb{R}^n,\rho_1)$, where $\rho_1(x,y) = \max_i |x_i-y_i|$. And $B(0,1)$ in $(\mathbb{R}^2,\rho_1)$ is shown as below\\
    \begin{figure}[h]
        \centering
        \includegraphics[width=0.4\textwidth]{unit_ball_norm_1}
        \caption{$B(0,1)$ in $(\mathbb{R}^2,\rho_1)$}
        \label{fig:unit_ball_norm_1}
    \end{figure}
    \item $(\mathbb{R}^n,\rho_2)$, where $\rho_2(x,y) = \sum^n_{i=1} |x_i-y_i|$, this is called taxi metric or New York metric. And $B(0,1)$ in $(\mathbb{R}^2,\rho_2)$ is shown as bellow\\
    \begin{figure}[h]
        \centering
        \includegraphics[width=0.4\textwidth]{unit_ball_norm_2}
        \caption{$B(0,1)$ in $(\mathbb{R}^2,\rho_2)$}
        \label{fig:unit_ball_norm_2}
    \end{figure}
    \item $(\mathbb{R}^n,\rho_3)$, where $\rho_3(x,y) = \left\|x-y\right\|$, this is called standard euclidean space.
    \item $(\mathbb{R}^n,\rho_4)$, where $\rho_4(x,y) = \left\|x-y\right\|^{1/2}$.
    \item $(X,d)$, where $X$ is arbitrary set and 
    \begin{align*}
        d(x,y) = \left\{
        \begin{aligned}
        & 1, \text{if} \quad x \neq y\\
        & 0, \text{if} \quad x = y
        \end{aligned}
        \right.
    \end{align*} 
    This is called discrete metric space.
    \item One can prove that every continuous function on $[0,1]$ is bounded. This fact implies that $(C,d)$, where $C([0,1]) = \{f:[0,1]\rightarrow \mathbb{R}, f \, \text{is continuous}\}$ with $d(f,g) = \left\|f-g\right\|_\infty = \sup \{|f(x) - g(x)|: x,y\in[0,1]\}$ is a metric space.
    \item Let $l^1 = \{x = \{x_n\}^\infty_{n=1}: \sum^\infty_{n=1}|x_n| < \infty\}$, i.e., $l^1$ is the space of all absolutely convergent sequences. For $x = \{x_n\}^\infty_{n=1}, y = \{y_n\}^\infty_{n=1} \in l^1$, we define 
    \begin{align*}
        d(x,y) = \sum^\infty_{n=1} |x_n - y_n|
    \end{align*}
    We will prove that $(l^1,d)$ is a metric space.
    
    First we have $d(x,y) < \infty$ for $\forall x,y \in l^1$. And we   have $|x_n-y_n|\leq |x_n|+|y_n|$, and hence
    \begin{align*}
        d(x,y) = \sum^\infty_{n=1} |x_n - y_n| \leq \sum^\infty_{n=1} |x_n| + \sum^\infty_{n=1} |y_n| < \infty
    \end{align*}
    Now we have $(1):d(x,y) \geq 0$ and $(2):d(x,y) = d(y,x)$, which is     obvious. And $(3): d(x,y) = 0 \Leftrightarrow \forall x_n = y_n \Leftrightarrow x =     y$. Finally, we have 
    \begin{align*}
        |x_n - y_n| \leq |x_n - z_n| + |z_n - y_n|
    \end{align*}
    and hence 
    \begin{align*}
        \sum^\infty_{n=1}|x_n - y_n| & \leq \sum^\infty_{n=1}|x_n - z_n| +     \sum^\infty_{n=1}|z_n - y_n|\\
        \Rightarrow d(x,y) & \leq d(x,z) + d(z,y).
    \end{align*}
    \item Let $l^2 = \{x = \{x_n\}^\infty_{n=1}: \sum^\infty_{n=1}|x_n|^2 < \infty\}$. For $x = \{x_n\}^\infty_{n=1}, y = \{y_n\}^\infty_{n=1} \in l^1$, we define
    \begin{align*}
        d_2(x,y) = \sqrt{\sum^\infty_{n=1} (x_n - y_n)^2}
    \end{align*}
    Thus, $(l^2, d_x)$ is a metric space and this space is call Hilbert space.
\end{enumerate}
\end{example} 

\medskip

\begin{theorem}
If $x_n\rightarrow x$ and $y_n\rightarrow y$ in a metric space, then $d(x_n, y_n) \rightarrow d(x,y)$.
\end{theorem}
\begin{proof}
The triangle inequality yields 
\begin{align*}
    d(x,y) \leq d(x,x_n) + d(x_n,y_n) + d(y_n,y)
\end{align*}
Then, we have $d(x,y) - d(x_n,y_n) \leq d(x,x_n) + d(y_n,y)$. Also, we have 
\begin{align*}
    d(x_n,y_n)\leq d(x_n,x) + d(x,y) + d(y,y_n)
\end{align*}
and then $d(x_n,y_n) - d(x,y)\leq d(x_n,x) + d(y,y_n)$. These two inequalities yield 
\begin{align*}
    |d(x,y) - d(x_n,y_n)| \leq d(x,x_n) + d(y_n,y) \to 0 
\end{align*}
and hence $$|d(x,y) - d(x_n,y_n)| \to 0 $$ which implies $d(x,y) \to d(x_n,y_n)$.
\end{proof}

\medskip

\section{Elements of Topology}
Let $(X,d)$ be a metric space. For $x\in X$ and $r>0$, we define 
\begin{align*}
    B(x,r) = \{y\in X: d(x,y) < r\}
\end{align*}
and call it the ball of radius $r$ centered at $x$. For example, if $(X,d)$ is a discrete metric space, then $B(x,1/2) = \{x\}$, $B(x,1) = \{x\}$ and $B(x,2) = X$.

\medskip

\begin{definition}\label{openset}
We say that a set $U\subset X$ is open if $$\forall x\in X, \exists r > 0, B(x,r)\subset U.$$
\end{definition}

\medskip

\begin{definition}[Definition in Rudin's Principle of Mathematical Analysis]Let $X$ be a metric space. 
\begin{enumerate}
    \item A neighborhood or a ball of $x$ is a set $N_r(x)$ consisting of all $y$ such that $d(x,y)<r$, for some $r>0$. The number $r$ is called the radius of $N_r(x)$.
    \item A point $x$ is a limit point of set $E$ if every neighborhood of $x$ contains a point $y\neq x$ such that $y\in E$.
    \item If $x\in E$ and $x$ is not a limit point of $E$, then $x$ is called an isolated point of $E$.
    \item $E$ is closed if every limit point of $E$ is a point of $E$.
    \item A point $x$ is an interior point of $E$ if there is a neighborhood(or ball) $N_r(x)$ of $x$ such that $N_r(x)\in E$.
    \item $E$ is open if every point of $E$ is an interior point of $E$.
    \item The complement of $E$ (denoted by $E^c$) is the set of all points $x\in X$ such that $x\notin E$.
    \item $E$ is perfect if $E$ is closed and if every point of $E$ is a limit point of $E$.
    \item $E$ is bounded if there is a real number $M$ and a point $x\in X$ such that $d(x, y) < M$ for all $y\in E$.
    \item $E$ is dense in $X$ if every point of $X$ is a limit point of $E$, or a point of $E$(or both).
\end{enumerate}
\end{definition}

\medskip

\begin{theorem}
Every ball $B(x,r)$ is open.
\end{theorem}
\begin{proof}
Let $B(x_0,r_0)$ be a ball. We will prove it is open. If $x\in B(x_0, y_0)$, then $d(x, x_0)<r_0$, then there exists a $r>0$, such that $$d(x,x_0)+r < r_0$$
We will now prove that $B(x,r)\subset B(x_0,r_0)$. Indeed, if $y\in B(x,r)$, then we have 
\begin{align*}
    d(x_0,y) & \leq d(x_0,x) + d(x,y) \\
    & \leq d(x_0,x) + r < r_0
\end{align*}
Since every point of $B(x,r)$ belongs to $B(x_0,r_0)$, we can conclude that $B(x,r)\subset B(x_0,r_0)$. According to Definition \ref{openset}, we proved that $B(x_0,r_0)$ is open.
\end{proof}

\medskip

\begin{theorem}
Let $(X,d)$ be a metric space, then
\begin{enumerate}
    \item $\varnothing, X$ are open.
    \item Intersection of a finite family $U_1, \cdots, U_n \subset X$ of open sets, $\bigcap^n_{i=1}U_i$ is open.
    \item Union of an arbitrary family $U_i,i\in I$ of open sets, $\bigcup^n_{i\in I}U_i$ is open.
\end{enumerate}
\end{theorem}
\begin{proof}
~\begin{enumerate}
    \item This is obvious.
    \item Suppose $U_1, \cdots, U_n \subset X$ are open. Let $x\in \bigcap^n_{i=1}U_i$, we need to show $B(x,r)\subset \bigcap^n_{i=1}U_i$ for some $r>0$. We have 
    \begin{align*}
        x\in U_1 \Rightarrow B(x,r_1) & \subset U_1, \text{for some} \, r_1 > 0 \\
        x\in U_2 \Rightarrow B(x,r_2) & \subset U_2, \text{for some} \, r_2 > 0 \\
        & \vdots \\
        x\in U_n \Rightarrow B(x,r_n) & \subset U_n, \text{for some} \, r_n > 0
    \end{align*}
    Hence, we can pick $r = \min\{r_1, r_2\cdots,r_n\}$, and it follows that $B(x,r) \subset \bigcap^n_{i=1}U_i$.
    \item Let $\{U_i\}_{i\in I}$ be an arbitrary family of open sets and let $x\in \bigcup_{i\in I}U_i$. Then there exists a $i_0\in I$ such that $x\in U_{i_0}$, and hence $B(x,r) \subset U_{i_0} \subset \bigcup_{i\in I}U_i$ for some $r>0$. The proof is complete.
\end{enumerate}
\end{proof}

\medskip

\begin{definition}
Given $A\subset X$, where $X$ is a metric space. The interior of the set $A$ is defines as 
$$\text{int}A = \{x\in A: \exists r > 0, B(x,r)\subset A\}$$
\end{definition}

\medskip

\begin{theorem}
int$A$ is always open. It is the largest open set contained in $A$ in the sense that if $U\subset A$ is open, then $U \subset \text{int}A$.
\end{theorem}
\begin{proof}
~\begin{enumerate}
    \item If $U\subset A$, then for $\forall x\in U$, there exists $r>0$ such that $B(x,r)\subset U \subset \text{int}A$. This implies that $x\in \text{int}A$. Thus, $U\subset \text{int}A$.
    \item If $x\in \text{int}A$, then there exists $r>0$ such that $B(x,r)\subset A$. Since $B(x,r)$ is open and $B(x,r)\subset A$, we have $\text{int}A$ is open.
\end{enumerate}
\end{proof}

\medskip

\begin{definition}
Let $(X,d)$ be a metric space. We say that $A\subset X$ is closed if $X\setminus A$ is open.
\end{definition}

\medskip

\begin{theorem}[Theorem 2.23 in Rudin's book]
A set $A$ is open if and only if it complement is closed.
\end{theorem}
\begin{proof}
First, suppose $A^c$ is closed. For $x\in A$, then $x\notin A^c$, and $x$ is not a limit point of $E^c$. Then there exists $r>0$ such that $B(x,r) \cap A^c = \varnothing$. Then, we have $B(x,r) \subset A$. Thus $x$ is an interior point of $A$ and it follows that $A$ is open.

Next, suppose $A$ is open. Let $x$ be a limit point of $A^c$. Then every neighborhood of $x$ contains a point of $A^c$, so $x$ is not a interior point of $A$. Since $A$ is open, then $x\notin A$, which means $x\in A^c$. Since $x$ is a limit point of $A^c$, then $A^c$ is closed. The proof is complete.
\end{proof}

\medskip

\begin{theorem}
Let $(X,d)$ be a metric space, then
\begin{enumerate}
    \item $\varnothing, X$ are closed.
    \item Intersection of an arbitrary family $U_i,i\in I$ of closed sets, $\bigcap^n_{i\in I}U_i$ is closed.
    \item Union of a finite family $U_1, \cdots, U_n \subset X$ of closed sets, $\bigcup^n_{i=1}U_i$ is open.
\end{enumerate}
\end{theorem}
\begin{proof}
~\begin{enumerate}
    \item $\varnothing$ is closed, since $X\setminus \varnothing = X$ is open. Also, $X$ is closed, since $X\setminus X = \varnothing$ is open.
    \item Suppose $\{U_i\}_{i\in I}$ is an arbitrary family of closed sets. Then the set $X\setminus U_i$ are open, and we have 
    \begin{align*}
        \bigcup_{i\in I} (X\setminus U_i) = X \setminus \bigcap_{i\in I} U_i
    \end{align*}
    is open and hence $\bigcap_{i\in I} U_i$ is closed.
    \item Suppose the set $U_1, \cdots, U_n \subset X$ are closed. Then the sets $X\setminus U_i$ are open and hence
    \begin{align*}
        \bigcap^n_{i=1} (X\setminus U_i) = X \setminus \bigcup^n_{i=1} U_i
    \end{align*}
    is open and it follows that $\bigcup^n_{i=1} U_i$ is closed.
\end{enumerate}
\end{proof}

\begin{definition}[Definition 2.26 in Rudin's book]
If $X$ is a metric space, if $E\subset X$, and if $E'$ denotes the set of all limit points(or accumulation points) of $E$ in $X$, the closure of $E$ is the set $\bar{E} = E \bigcup E'$.
\end{definition}

\medskip

\begin{theorem}
In any metric space, the set $\bar{B}(x,r) = \{y\in X: d(x,y)\leq r\}$ is closed.
\end{theorem}
\begin{proof}
We can prove this theorem by proving that $X\setminus \bar{B}(x_0,r_0) = \{y\in X: d(x_0,y) > r\}$ is open.If $x\in X\setminus\bar{B}(x_0,r_0)$, then $d(x_0,x) > r$ and hence there exists $r > 0$ such that
\begin{align*}
    d(x_0,x) > r_0 + r
\end{align*}

And with triangle inequality, for $\forall y\in B(x,r)$, we have $d(x_0,y) \geq d(x,x_0) - d(x,y) > r_0$, since $d(x,y) < r$. Thus, we have $B(x,r)\subset X\setminus \bar{B}(x_0,r_0)$, which implies that $X\setminus \bar{B}(x_0,r_0)$ is open.
\end{proof}

\medskip

\begin{theorem}
A set $A\subset U$ is closed if and only if the following implication is true: if a sequence $\{x_n\}_{n=1}^\infty\in A$ such that $x_n\rightarrow x$, then $x\in A$, i.e., if for every convergent sequence of $A$, its limit belongs to $A$.
\end{theorem}
\begin{proof}
~\begin{enumerate}
    \item Suppose $A$ is closed. We need to prove that if $x_n \in A$, then $x\in A$. Suppose by contradiction that $x_n\in A \rightarrow x$, but $x\notin A$. Then, $x\in X\setminus A$. Since $X\setminus A$ is open, there exists a $\varepsilon > 0$ such that $B(x,\varepsilon) \subset X\setminus A$. Then $d(x_n,x) > \varepsilon$ for all $n$ and thus $x_n$ does not converges to $x$, which is a contradiction.
    \item Suppose that a set $A\subset X$ has the property that if $X_n \in A$ which converges to $x$, then $x\in A$. We need to prove that $A$ is closed. And we only need to prove that $X\setminus A$ is open. Then, we need to prove that, for $x\in X\setminus A$
    \begin{align*}
        \exists \varepsilon > 0, B(x, \varepsilon)\subset X\setminus A.
    \end{align*}
    
    Suppose by contradiction that the above statement is not true, i.e., 
    \begin{align*}
        \forall \varepsilon > 0, B(x,\varepsilon)\not\subset X\setminus A
    \end{align*}
    which means $B(x,\varepsilon)\bigcap A \neq \varnothing$. Then, taking $\varepsilon = 1/n$, $B(x,1/n)\bigcap A \neq \varnothing$. Then we take $x_n\in B(x,1/n)\bigcap A$. Then $x_n\in A$ and $d(x,x_n) < 1/n$, so $x_n\rightarrow x$. Since we assume $x\notin A$, and we get a contradiction. The proof is complete.
\end{enumerate}
\end{proof}

\begin{definition}
Let $(X,d)$ be a metric space. We say that $x\in X$ is an accumulation point(or cluster point, or limit point) of a set $A\subset X$ if there is a sequence $\{x_n\}^\infty_{n=0}$ such that $x_n\neq x$ and $x_n \rightarrow x$.
\end{definition}

\medskip

\begin{theorem}
$x\in X$ is an accumulation point if and only if every open set containing $x$ contains an element of $A$ different than $x$.
\end{theorem}
\begin{proof}
~\begin{enumerate}
    \item First, let $x \in U$ and $U$ is open. Then $B(x,\varepsilon)\subset U$ for some $\varepsilon > 0$. Let $x_n\in A$, $x_n \neq x$ and $x_n\to x$. Then there exists $n$ such that $x_n\in B(x,\varepsilon)\subset U$, where $x_n \neq x$.
    \item Second, for each ball $B(x, 1/n)$, there is a $x_n\in B(x,1/n)\bigcap A$ and $x_n \neq x$. Then it follows that $x_n\to x$. The proof is complete.
\end{enumerate}
\end{proof}

\medskip

\begin{theorem}
$A$ is closed if and only if all accumulation points of $A$ belong to $A$.
\end{theorem}
\begin{proof}
~\begin{enumerate}
    \item First, suppose $A$ is closed, then $X\setminus A$ is open. So if $x\notin A$, then $B(x,\varepsilon)\subset X\setminus A$ for some $\varepsilon>0$. Then $B(x,\varepsilon)$ contains no point of $A$ and hence $x$ cannot be an accumulation point. Therefore, every accumulation point must belong to $A$.
    \item Suppose all accumulation points of $A$ belong to $A$. We need to show that $A$ is closed, it suffices to prove that $X\setminus A$ is open. Let $x\in X\setminus A$, then $x$ is not an accumulation point of $A$, then there exists a open set $U$ such that $x\in U$ and $U$ contains no point of $A$. Hence, $U\subset X\setminus A$, and it follows $B(x,\varepsilon)\subset U\subset X\setminus A$ for some $\varepsilon > 0$. Thus, $X\setminus A$ is open. The proof is complete.
\end{enumerate}
\end{proof}

\medskip

\begin{theorem}[Theorem 2.27 in Rudin's book]
The closure of $A$: $\text{cl}(A)$ is intersection of all closed sets that contain $A$. Therefore, $\text{cl}(A)$ is closed. Moreover, $\text{cl}(A)$ is the smallest closed set that contains $A$ in the sense that if $E$ is another closed set such that $A\subset E$, then $\text{cl}(A)\subset E$.
\end{theorem}
\begin{proof}
~\begin{enumerate}
    \item First, if $x\in X$ and $x\notin \text{cl}(A)$, then $x$ is neither a point of $A$ nor a accumulation point of $A$. Hence, for $x$ there exists a $B(x,\varepsilon) \bigcap A = \varnothing$, for some $\varepsilon > 0$. Then we have that $X\setminus \text{cl}(A)$ is open, which implies $\text{cl}(A)$ is closed.
    \item Second, If $E$ is closed and $A\subset E$, since $\text{cl}(A)$ is the intersection of all closed sets that contain $A$, and $E$ is in the family whose intersection we take, and hence $\text{cl}(A)\subset E$.
\end{enumerate}
\end{proof}

\medskip

\begin{theorem}
The closure of $A\subset X$ is $\text{cl}(A) = \{x\in X|\exists x_n\in A, n = 1,2,\cdots, x_n\to x\}$.
\end{theorem}
\begin{remark}
We do not assume $x_n \neq x$ here.
\end{remark}
\begin{proof}
If $x\in A$, then $x_n = x$ satisfies that $x_n\to x$. If $x$ is an accumulation point of $A$, then there is a sequence $x_n\in A$ such that $x_n\to x$. Therefore, we have 
\begin{align*}
    \text{cl}(A) \subset \{x\in X|\exists x_n\in A,  x_n\to x\}
\end{align*}

On the other hand, if $x_n\in A$ and $x_n\to x$, then either all $x_n \neq x$ and $x$ is an accumulation point of $A$ or $x_n  = x$ for some $n$ and $x\in A$, which implies $$\{x\in X|\exists x_n\in A,  x_n\to x\}\subset \text{cl}(A)$$
The proof is complete.
\end{proof}

\medskip

\subsection{Boundary of a set}

\begin{definition}
Let $(X,d)$ be a metric space, and $A\subset X$. Boundary of $A$ is defined as $\text{bd}(A) =  \text{cl}(A)\bigcap  \text{cl}(X\setminus A)$.
\end{definition}

\medskip

\begin{theorem}
$x\in \text{bd}(A)$ if and only if there exists a sequence in $A$ and a sequence of $X\setminus A$ such that they both converge to $x$.
\end{theorem}
\begin{proof}
It is an obvious result following the definition above.
\end{proof}

Another theorem follows this theorem immediately.

\begin{theorem}
$x\in \text{bd}(A)$ if and only if $\forall \varepsilon > 0$, $B(x,\varepsilon)\bigcap A\neq\varnothing$ and $B(x,\varepsilon)\bigcap (X\setminus A)\neq\varnothing$.
\end{theorem}

\medskip

\subsection{Complete metric space}
\begin{definition}
Let $(X,d)$ be a metric space. We say that a sequence $\{x_n\}^\infty_{n=1}$ of $X$ is a Cauchy sequence if $\forall\varepsilon > 0$, there $\exists N > 0$, such that $\forall n,m \geq N$, $d(x_n,x_m) < \varepsilon$.
\end{definition}

\begin{definition}
A sequence $\{x_n\}^\infty_{n=1}\in X$ is called bounded if $x_n\in B(x_0,R)$ for some ball $B(x_0,R)$ and $\forall n = 1,2,3,\cdots$.
\end{definition}

\medskip

\begin{theorem}
Properties of Cauchy sequence.
\begin{enumerate}
    \item Every convergent sequence in a metric space is a Cauchy sequence.
    \item Every Cauchy sequence in a metric space is bounded.
    \item If a subsequence of a Cauchy sequence in a metric space is convergent, then the whole sequence is convergent to the same limit.
\end{enumerate}
\end{theorem}
\begin{proof}
~\begin{enumerate}
    \item (a) and (b) are obvious.
    \item For (c), suppose $\{x_n\}$ is a Cauchy sequence and $x_{n_k}\to x$. We need to prove that $x_n\to x$. For $\{x_{n_k}\}$, we have $\forall \varepsilon > 0$, there exists a $N_1$ such that for $\forall k \geq N_1$, $d(x_{n_k},x)<\varepsilon/2$. Also, since $\{x_n\}$ is a Cauchy sequence, then for $\forall \varepsilon > 0$, there exists a $N_2$ such that for $\forall n,m \geq N_1$, $d(x_n,x_m)<\varepsilon/2$. Take $N = \max\{N_1, N_2\}$, since $n_N \geq N$ , we have for $n \geq N$,
    \begin{align*}
        d(x,x_n) \leq d(x_n, x_{n_N}) + d(x_{n_N}, x) < \varepsilon
    \end{align*}
    which means $x_n\to x$. The proof is complete.
\end{enumerate}
\end{proof}

\medskip

\begin{definition}
We say that a metric space is complete if every Cauchy sequence is convergent. For example, $\mathbb{R}$ is complete, but $\mathbb{Q}$ is not.
\end{definition}

\medskip

\begin{theorem}
$\mathbb{R}^n$ is complete.
\end{theorem}
\begin{proof}
We have 
\begin{align*}
    & \{x_k\}_k = ((x_{k1},x_{k2},\cdots, x_{kn}))\,\text{is Cauchy sequence} \\
    \Leftrightarrow & \{x_{ki}\}_k, i = 1,2,\cdots, n \,\text{is Cauchy sequence} \\
    \Leftrightarrow & \{x_{ki}\}_k, i = 1,2,\cdots, n \,\text{is convergent} \\
    \Leftrightarrow & \{x_k\}_k\,\text{is convergent}
\end{align*}
The proof is complete.
\end{proof}

\begin{definition}
Let $\{x_n\}$ be a sequence in a metric space. We say that $x\in X$ is a cluster point of $\{x_n\}$ if $x$ is the limit of a sbusequence of $\{x_n\}$.
\end{definition}
\begin{remark}
$ $
\begin{enumerate}
  \item $x\in X$ is an accumulation point of a set $A\subset X$ if there is a sequence $\{x_n\}^\infty_{n=0}\in A$ such that $x_n\neq x$ and $x_n \rightarrow x$.
  \item $x\in X$ is a limit point of set $A\subset X$ if every neighborhood of $x$ contains a point $y\neq x$ such that $y\in A$.
\end{enumerate}
\end{remark}

\medskip

\begin{theorem}
The set of cluster points is closed.
\end{theorem}
\begin{proof}
Suppose $a_k$ is a cluster point of $\{x_n\}$ and $a_k\to a$. We need to prove that $a$ is a cluster point of $x_n$. Each $a_k$ is a cluster point of a subsequence $x_{n_k}$, then in any neighborhood of $a$ there are infinitely many elements of $x_n$, and hence we can select a subsequence $x_{n_k}$ that converges to $a$.
\end{proof}

\begin{theorem}
Let $A\subset X$ be a closed subspace of a complete metric space $(X,d)$, then $(A,d)$ is a complete metric space as well.
\end{theorem}
\begin{proof}
If $\{x_n\}$ is a Cauchy sequence in $A$, then it is a Cauchy sequence in $X$, so it converges to some point in $X$. Since $A$ is closed, then $x\in A$, which proves that $(A,d)$ is complete.
\end{proof}

\begin{theorem}
In a metric space, $x_n\to x$ if and only if every subsequence of $x_n$ has a further subsequence that converges to $x$. 
\end{theorem}
\begin{proof}
($\Rightarrow$) This is obvious result of convergence. \\
\hspace*{1em}\, ($\Leftarrow$) Suppose that $\{x_n\}$ has the property above, but $x_n$ does not converge, that is $\exists \varepsilon > 0$, for $\forall N > 0$, there exists $n \geq N$ such that $d(x_n,x)\geq\varepsilon$. Thus we can pick a subsequence $\{x_{n_k}\}$ of $\{x_n\}$ such that
$$d(x_{n_k},x)\geq\varepsilon$$
Clearly, we can know $\{x_{n_k}\}$ has no sequence converging to $x$, which is a contradiction.
\end{proof}

\medskip

\subsection{Compact spaces}
\begin{definition}
We say that a subset $A\subset X$ of a metric space is compact if every sequence in $A$ has a subsequence converging to a point in $A$.
\end{definition}

\begin{definition}[Definition 2.31 \& 2.32 in Rudin's book]
$ $
\begin{enumerate}
    \item By an open cover of a set $A$ in a metric space $X$ we mean a collection $\{G_\alpha\}$ of open subsets of $X$ such that $A\subset \bigcup_\alpha G_\alpha$.
    \item A subset $A$ of a metric space $X$ is said to be compact if every open cover of $A$ contains a finite subcover.
\end{enumerate}
\end{definition}

\begin{proposition}
If $A$ is compact, then $A$ is bounded and closed.
\end{proposition}
\begin{proof}
Let $A\subset X$ be compact. To prove that $A$ is closed we need to prove that 
\begin{align*}
    A\ni x_n\to x \Rightarrow x\in A
\end{align*}
Since $x_n\in A$ and $A$ is compact, then it has a subsequence $\{x_{n_k}\}$ convergenting to a point $x$, then clearly $x\in A$. 

Now we prove that $A$ is bounded. Suppose $A$ is not bounded, we fixed $x_0\in X$ and find a sequence $\{x_n\}\in A$ such that $d(x_n, x_0) \geq n$. Then no subsequence of $\{x_n\}$ converges, which is a contradiction.
\end{proof}

\begin{theorem}[Heine-Borel Theorem]
$A\subset \mathbb{R}^n$ is compact if and only if $A$ is bounded and closed.
\end{theorem}
\begin{proof}
~\begin{enumerate}
    \item ($\Rightarrow$) This is a result of proposition above.
    \item ($\Leftarrow$) We prove it for $n = 3$. Let $x_k\in A, k = 1,2,3,\cdots$. Since $A$ is bounded, we can know that all three elements of $x_k = (x_{1k},x_{2k},x_{3k})$ are bounded in $\mathbb{R}$. Then the sequence $\{x_{1k}\}_k$ is bounded, so Bolzano-Weierstrass theorem, it has a convergent subsequence. Then $x_{1k_n}\to x_1$ and $x_1\in A$ since $A$ is closed. Similiarly, $\{x_{2k_n}\}$ also has a convergent subsequence $\{x_{2k_{n_m}}\}$ converging to $x_2\in A$, and $\{x_{3k_{n_m}}\}$ also has a convergent subsequence $\{x_{3k_{n_{m_l}}}\}$ converging to $x_3\in A$. Thus, we have 
    \begin{align*}
        x_{k_{n_{m_l}}} = \left(x_{1k_{n_{m_l}}},x_{2k_{n_{m_l}}},x_{3k_{n_{m_l}}}\right)\to (x_1,x_2,x_3)\in A
    \end{align*}
    Then $A$ is compact.
\end{enumerate}
\end{proof}

\medskip

\begin{definition}
Let $(X,d)$ be a metric space and $A\subset U$ a subset. We say that a family of open sets $\{U_i\}_{i\in I}$ forms a open covering of $A$ if $A\subset  \bigcup_{i\in I} U_i$. Now, $\{U_{i_k}\}_{i_k\in I}, k = 1,2,\cdots,N$ forms a finite subcovering of $A$ if $A\subset \bigcup_{i_k=1}^N U_{i_k}$.
\end{definition}

\medskip

\begin{theorem}[Bolzano-Weierstrass theorem]
Let $(X,d)$ be a metric space and $A\subset X$ a subset. Then $(X,d)$ is compact if and only if every open covering of $A$ has a finite subcovering.
\end{theorem}
\begin{remark}
We denote balls in metric space $(X,d)$ and $(A,d)$ by $B^X(x,r)$ and $B^A(x,r)$ respectively. Clearly, $B^A(x,r) = B^X(x,r)\bigcap A$.
\end{remark}

Before we prove the Bolzano-Weierstrass theorem, we need to mention some other theorem and lemma. 

\begin{theorem}[Theorem 2.30 in Rudin's book]
$U\subset A$ is open in $(A,d)$ if and only if there is $W \subset X$ open in $(X,d)$ such that $U = W\bigcap A$.
\end{theorem}
\begin{proof}
~\begin{enumerate}
    \item ($\Leftarrow$) Suppose $W\subset X$ open in $X$ and $U = W\bigcap A$. Then for $\forall x\in U$, there exists a $r>0$ such that $B^X(x,r)\subset W$ and hence $B(x,r)^X\bigcap A\subset U\bigcap A = U$, where $B(x,r)^X\bigcap A$ is a ball in $A$. Then $U$ is open in $(A,d)$.
    \item ($\Rightarrow$) Suppose $U\subset A$ is open in $(A,d)$. Then for $\forall x\in U$, there exists a $r>0$ such that $B^X(x,r)\bigcap A\subset U$, where $B^X(x,r)\bigcap A$ is a ball in $A$. Clearly, $U = \bigcup_{x\in X}B^X(x,r)\bigcap A$.\\
    Now we set $W = \bigcup_{x\in X}B^X(x,r)$ and $W$ is open in $(X,d)$ and $$W\bigcup A = \bigcup_{x\in X}B^X(x,r)\bigcap A = U$$
    The proof is complete.
\end{enumerate}

\end{proof}

\begin{corollary}
$E\subset A$ is closed in $(A,d)$ is and only if there is a set $F\subset X$ closed in $(X,d)$ such that $E = F\bigcap A$.
\end{corollary}

\begin{theorem}\label{finitcover}
A metric space $X$ is compact if and only if every open covering of $X$ has a finite subcovering.
\end{theorem}
\begin{proof}
~\begin{enumerate}
    \item ($\Leftarrow$) Suppose that every open covering of $X$ has a finite subcovering. We need to prove that every sequence $\{x_n\}$ in $X$ has a convergent subsequence. 
    
    By contradiction, we suppose that $\{x_n\}\in X$ does not has convergent subseqnece(Note that $\{x_n\}$ has infinitely many different values, otherwise we would have a constant, and thus convergent subsequence). Therefore we can select a subsequence $\{x_{n_k}\}$ such that $x_{n_k} \neq x_{n_l}$ for $k\neq l$ and $\{x_{n_k}\}$ does not converge. Observe that the set $\{x_{n_1},x_{n_2},x_{n_3},\cdots\}$ is closed and the set has no accumulation point.
    
    In particular, every $x_{n_k}$ is not a accumulation point of the sequence $\{x_{n_k}\}$, and hence there is a $\varepsilon_k>0$ such that the ball $B(x_{n_k}, \varepsilon_k)$ contains no points of this sequence other than $x_{n_k}$, i.e., 
    \begin{align*}
        x_{n_l}\notin B(x_{n_k}, \varepsilon_k), \text{if}\,l\neq k
    \end{align*}
    Clearly, $X\setminus \{x_{n_1},x_{n_2},x_{n_3},\cdots\}$ is open and hence $$X = \bigcup^\infty_{k=1}B(x_{n_k},\varepsilon_k) \cup \left(X\setminus \{x_{n_1},x_{n_2},x_{n_3},\cdots\}\right)$$ 
    is an open covering of $X$. Thus, this covering has no finite subcovering.
    \item ($\Rightarrow$) We need a lemma.
    \begin{lemma}
    Let $\bigcup_{i\in I}U_i$ be an open covering of a compact metric space of $X$ such that $X = \bigcup_{i\in I}U_i$. Then there is $r>0$(called Lebesgue number of the covering) such that $\forall x\in X$, $\exists i\in I$ such that $B(x,r)\subset U_i$.
    \end{lemma}
    \begin{proof}
    Prove by contradiction. Then we can find $x_n\in X$ such that $B(x_n,1/n)$ is not contained in any of the open set $U_i$. Since $X$ is compact, $\{x_n\}$ has a cinvergent subsequence $x_{n_k}\to x_0\in U_{i_0}$ for some $i_0\in I$. Then we have $B(x_0, \varepsilon)\subset U_{i_0}$ for some $\varepsilon>0$. Since $x_n\to x_0$, it is clear that $B(x_n,1/n)\subset B(x_0, \varepsilon)$, which is a contradiction.
    \end{proof}
    We need one definition and one more lemma.
    \begin{definition}
    A metric space $X$ is said totally bounded if $\forall \varepsilon>0$, there exists a finite covering of $X$ by balls of radius $\varepsilon$.
    \end{definition}
    \begin{lemma}
    If a metric space $X$ is compact, then $x$ is totally bounded.
    \end{lemma}
    \begin{proof}Prove by contradiction. Then there is a $\varepsilon>0$ such that no finite family of balls with radius $\varepsilon$ covers $X$. Let $x_1\in X$, then $B(x_1,\varepsilon)\neq X$. Then there exists $x_2\notin B(x_1,\varepsilon)$, and $B(x_1,\varepsilon)\cup B(x_2,\varepsilon)\neq X$. Then there exists $x_3\notin B(x_1,\varepsilon)\cup B(x_2,\varepsilon)$, and $B(x_1,\varepsilon)\cup B(x_2,\varepsilon)\cup\neq X$. We can continue this process and construct a sequence $\{x_1,x_2,x_3,\cdots\}$ in $X$ such that $d(x_k,x_l)\geq \varepsilon$ for $k\neq l$. Clearly, $\{x_n\}$ has no convergent subsequence, which is contradicted with compactness of $X$.
    \end{proof}
    Now we continue the proof of the implication ($\Rightarrow$) of theorem \ref{finitcover}. 
    
    ($\Rightarrow$) Suppose that $X$ is compact, i.e., every sequence in $x$ has a convergent subsequence. We need to prove that every open covering of $X$ has a finite subcovering. \\
    Let $X = \bigcup_{i\in I}U_i$ and let $r>0$ be a Lebesgue number of the covering. Since $X$ is totally bounded, $X$ has finite coverings by balls of radius $r$, i.e.,
    \begin{align*}
        X = \bigcup^N_{i=1}B(x_i,r)
    \end{align*}
    By the definition of Lebesgue number, we have $B(x_i,r)\subset U_{k_i}$. Then,
    \begin{align*}
        X = \bigcup^N_{i=1}B(x_i,r) \subset \bigcup^N_{i=1}U_{k_i}
    \end{align*}
    which gives a finite open subcovering of $X$. The proof of theorem \ref{finitcover} is complete. This also completes the proof is Bolzano-Weierstrass theorem.
\end{enumerate}
\end{proof}

\medskip

\begin{theorem}
A metric space $X$ is compact if and only if it is complete and totally bounded.
\end{theorem}
\begin{proof}
~\begin{enumerate}
    \item ($\Rightarrow$) Suppose $X$ is compact. Then $X$ is totally bounded. To prove it is complete, let $\{x_n\}$ be a Cauchy sequence in $X$.  The by compactness, we can know some subsequence of $\{x_{n_k}\}$ is convergent, such that $x_{n_k}\to x_0$. Then $\{x_n\}$ also converges to $x_0$. Thus, $X$ is complete.
    \item ($\Leftarrow$) Suppose that $X$ is complete and totally bounded. We need to prove that every sequence $\{x_n\}$ in $X$ has a convergent subsequence. 
    
    Since $X$ is totally bounded , then it has a finite open covering of balls with radius $1$, i.e.,
    \begin{align*}
        X = \bigcup^{N_1}_{i=1}B\left(x_i^{(1)},1\right)
    \end{align*}
    Hence, infinitely many elements of sequence $\{x_n\}$ belong to at least one of the balls, saying $B(x_{i_1}^{(1)},1)$. This ball has a finite open covering by balls with radius of $\frac{1}{2}$, i.e.,
    \begin{align*}
        B(x_{i_1}^{(1)},1) = \bigcup^{N_2}_{i=1}B\left(x_i^{(2)},\frac{1}{2}\right)\cap B\left(x_i^{(1)},1\right)
    \end{align*}
    Still, infinitely many elements of the sequence belong to at least one of the set on the right hand side, saying $B\left(x_{i_2}^{(2)},\frac{1}{2}\right)\cap B(x_{i_1}^{(1)},1)$. And this set has a finite open covering by balls of radius of $\frac{1}{3}$, i.e.,
    \begin{align*}
        B\left(x_{i_2}^{(2)},\frac{1}{2}\right)\cap B(x_{i_1}^{(1)},1) = \bigcup^{N_3}_{i=1} B\left(x_{i}^{(3)},\frac{1}{3}\right)\cap B\left(x_{i_2}^{(2)},\frac{1}{2}\right)\cap B\left(x_i^{(1)},1\right)
    \end{align*}
    Still, infinitely many elements of the sequence belong to at least one of the set on the right hand side, and we continue this process and pick a subsequence from the given sequence $\{x_n\}$ such that 
    \begin{align*}
        x_{n_1} &\in B\left(x_i^{(1)},1\right) \\
        x_{n_2} &\in B\left(x_{i_2}^{(2)},\frac{1}{2}\right)\cap B\left(x_i^{(1)},1\right) \\
        x_{n_3} &\in B\left(x_{i_3}^{(3)},\frac{1}{3}\right)\cap B\left(x_{i_2}^{(2)},\frac{1}{2}\right)\cap B\left(x_i^{(1)},1\right)\\
        & \vdots
    \end{align*}
    
    Therefore, for $k,;l\geq N$, we have $x_{n_k},x_{n_l}\in B\left(x_{i_N}^{(2)},\frac{1}{N}\right)$ and hence
    \begin{align*}
        d(x_{n_k},x_{n_l}) < \frac{2}{N}
    \end{align*}
    Thus the sequence is Cauchy sequence and therefore convergent, it follows that $X$ is complete.
\end{enumerate}

\end{proof}

\begin{theorem}
If $F_k\subset X$ are nonempty compact sets such that $F_1\supset F_2\supset F_3\supset\cdots$, then $\bigcap^\infty_{k=1}F_k\neq\varnothing$.
\end{theorem}
\begin{proof}
Let $x_k\in F_k$ for $k = 1,2,3,\cdots$. Then $X_n\in F_k$ for all $n\geq k$. In particular, $x_n\in F_1$ for all $n$. Hence $x_n$ has a convergent subsequence  in $F_1$($F_1$ is compact), saying $x_{n_l}\to x_0\in F_1$. Now, we have $x_{n_l}\in F_k$ for all $n_l \geq k$, and hence the limit $x_0$ of $\{x_{n_l}\}$ must belong to every $F_k$, i.e., $x_0\in \bigcup^\infty_{k=1}F_k$ which proves the intersection is not empty.
\end{proof}
\begin{remark}
The claim is not true if $F_k$ are open or closed but unbounded, for example
\begin{align*}
    \bigcap^\infty_{k=1}\left(0,\frac{1}{k}\right) &= \varnothing \\
    \bigcap^\infty_{k=1}\left[k,\infty\right) &= \varnothing
\end{align*}
\end{remark}

\medskip

\subsection{Cantor set}
\begin{definition}
By the segment $(a,b)$ we mean the set of all real numbers $x$ such that $a<x<b$. By the interval $[a,b]$ we mean the set of all real numbers $x$ such that $a\leq x\leq b$.
\end{definition}
The set which we are now constructing shows that there exists perfect set in $\mathbb{R}^1$ which contain no segment. 
\begin{enumerate}
    \item Let $E_0$ be the interval $[0,1]$.
    \item Remove the segment $\left(\frac{1}{3},\frac{2}{3}\right)$, and let $E_1$ be the union of the interval of $$\left[0,\frac{1}{3}\right],\left[\frac{1}{3},1\right].$$
    \item Remove the middle thirds of these two intervals and let $E_2$ be the union of $$\left[0,\frac{1}{9}\right],\left[\frac{2}{9},\frac{1}{3}\right],\left[\frac{6}{9},\frac{7}{9}\right],\left[\frac{8}{9},1\right].$$
    \item Continue this way and we can get a sequence of compact sets $E_n$, such that $E_1\supset E_2\supset E_3\supset\cdots$ and $E_n$ is the union of $2^n$ intervals with length $3^{-n}$.
\end{enumerate}

We show the Cantor set in seven iterations as below:
\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{Cantor_set_in_seven_iterations}
    \caption{Cantor set in seven iterations}
    \label{fig:Cantor_set}
\end{figure}

The set
\begin{align*}
    P = \bigcap^\infty_{n=1}E_1
\end{align*}
is called the Cantor set. $P$ is clearly compact and $P$ is not empty. And one can prove that $P$ is uncountable.

\medskip

\subsection{Connected sets}
\begin{definition}
~\begin{enumerate}
  \item $\varphi:[a,b]\to X$ is called continuous if $x_n\to t$, then $\varphi(x_n)\to\varphi(x)$ for every sequence $\{x_n\}$ in $[a,b]$. 
  \item If $A\subset X$ is a subset of a metric space, a continuous path connecting $x,y\in A$ inside $A$ is any continuous function $\varphi:[a,b]\to A$ such that $\varphi(a) = x, \varphi(b) = y$.
  \item A set $A$ is called path connected if every two points in $A$ can be connected by a continuous path inside $A$.
\end{enumerate}
\end{definition}

\begin{definition}
A set $A\subset X$ is called disconnected if there exists open sets $U, V$ in $X$ such that 
\begin{enumerate}
    \item $A\subset U\cup V$;
    \item $A\cap U\neq \varnothing$ and $A\cap V\neq \varnothing$;
    \item $A\cap (U\cap V) = \varnothing$
\end{enumerate}
Moreover, $A$ is called connected if it is not disconnected.
\end{definition}
Disconnected set is shown as below, $A$ is the grey area, which is contained in two open sets $U$ and $V$, which are plotted by dotted line: \\
\def\firstcircle{(0,0) circle (1cm)}
\def\secondcircle{(2.7,0) circle (1cm)}
\def\thirdcircle{(0,0) circle (1.5cm)}
\def\forthcircle{(0,0) circle (1.5cm)}
\colorlet{circle edge}{black!90}
\colorlet{circle area}{black!20}
\tikzset{filled/.style={fill=circle area, draw=circle edge, thick},
    outline/.style={draw=circle edge, thick}}
%\setlength{\parskip}{5mm}
% Set A and B
\begin{figure}[h]
    \label{fig:disconnected}
    \begin{center}
        \begin{tikzpicture}
            \centering
            \draw[filled] \firstcircle node {$A$}
            \secondcircle node {$A$};
            \draw[black,thick,dashed] (2.7,0) circle (1.5cm);
            \draw[black,thick,dashed] (0,0) circle (1.5cm);
            \node[anchor=south] at (current bounding box.north) {$A \subset U\cup V$};
        \end{tikzpicture}
    \end{center}
    \caption{Disconnected set}
\end{figure}

\medskip

\begin{exercise}
Prove that the space $X$ is connected if and only if the only subsets of $X$ that are open and closed at the same time are $\varnothing$ and $X$.
\end{exercise}

\begin{proof}
~\begin{enumerate}
    \item ($\Rightarrow$) Suppose $X$ is connected. We want to show that if $E\subset X$ is open and closed at the same time, then $E = X$ or $E = \varnothing$. 
    
    Suppose by contraction that there exists a $E\subset X$ such that $E\neq X$, $E\neq\varnothing$ and $E$ is open and closed at the same time. Then $U = E$, $V = X\setminus E$ are both open. And we have $X \subset U\cup V$, $X\cap U \neq \varnothing$, $X\cap V \neq \varnothing$, $X\cap U = V \neq \varnothing$ and $X\cap (U\cap V) = X\cap E\cap (X\setminus E) = \varnothing$. Thus, $X$ is disconnected, which is a contradiction.
    \item ($\Leftarrow$) Suppose that the only subsets of $X$ that are open and closed at the same time are $\varnothing$ and $X$. We need to show that $X$ is connected. 
    
    By contradiction that $X$ is not connected. Then, there exists two open sets $U$ and $V$ such that $X = U\cup V$, $X\cap U \neq \varnothing$, $X\cap V \neq \varnothing$, $X\cap U = V \neq \varnothing$. Then $U\neq \varnothing$ and it is also closed since $X\setminus U = V$ is open, then this is a contradiction with the fact that $X$ and $\varnothing$ are only sets that are open and closed at the same time.
\end{enumerate}
\end{proof}

\medskip

\begin{theorem}
If $A\subset X$ is path connected, then $A$ is connected.
\end{theorem}
\begin{proof}
Prove by contradiction and suppose $A$ is path connected but not connected. Then $A \subset U\cup V$, $A\cap U\neq\varnothing$, $A\cap V\neq\varnothing$, and $A\cap (U\cap V)=\varnothing$. 

Let $x\in A\cap U$, $y\in A\cap V$, and let $\varphi:[a,b]\rightarrow A$ be a continuous path such that $\varphi(a) = x, \varphi(b) = y$. Define $c = \sup\{t\in[a,b]|\, \varphi\left([a,t]\right)\subset A\cap U\}$. If $\varphi(c)\in A\cap U$, then $c\neq b$\,(otherwise it would implies $\varphi(c) = \varphi(b) = y \in A\cap U$, which is impossible). 

Since $\varphi(c)\in A\cap U$ and $c<b$, it follows from the continuity of $\varphi$ that there exists a $\varepsilon > 0$ such that $\varphi\left([c,c+\varepsilon]\right)\subset U$, which contradicts the definition of $c$. Therefore, $\varphi(c)\in A\cup V$. Then by the same argument as above, that there exists a $\varepsilon>0$ such that $\varphi([c-\varepsilon,c])\in V$ implying $\varphi(c-\varepsilon)\in V$, which contradicts the definition of $c$.
\end{proof}

\medskip

\begin{theorem}
If $A$ is connected, then the closure $\text{cl}(A)$ of $A$ is also connected.
\end{theorem}
\begin{proof}
Prove by contradiction and suppose that $A$ is connected while $\text{cl}(A)$ is not closed. Then there exists open sets $U,V$ such that $\text{cl}(A)\subset U\cup V, \text{cl}(A)\cap U \neq\varnothing, \text{cl}(A)\cap V \neq\varnothing$, and $\text{cl}(A)\cup (U \cup V) = \varnothing$. Then we have 
\begin{enumerate}
    \item $A\subset U\cup V$.
    \item $A\cup U \neq\varnothing$.
    \item $A\cup V \neq\varnothing$.
    \item $A\cup (U \cup V) = \varnothing$.
\end{enumerate}
which means that $A$ is disconnected. Contradiction. 

The properties $(1)$ and $(4)$ are obvious. Now we prove property $(2)$. Since $\text{cl}(A)\cap U \neq\varnothing$, then there is a $x\in \text{cl}(A)\cap U$. Hence there is a sequence $\{x_n\}\in A$ such that $$x_n\to x\in \text{cl}(A)\cap U$$
Since $U$ is open, then there exists sufficiently large $N > 0$ such that $\forall n>N$, $x_n\in A\cap U$, which proves that $A\cap U\neq\varnothing$.
\end{proof}

\begin{example}
The graph of the function $y = \sin \frac{1}{x}, 0\leq x\leq \pi$, i.e., the set  $$G = \left\{(x, \sin \frac{1}{x})|\, 0< x\leq \pi\right\}$$
is path connected, hence $G$ is connected.

Therefore, $\text{cl}(G)$ is connected. However, $\text{cl}(G)$ is the union of $G$ and the segment $[-1,1]$ on the $y-$axis. It is clear that this set is not path connected. $\text{cl}(G)$ is an example of a set which is connected but not path connected. The plot of $y = \sin \frac{1}{x}, 0\leq x\leq \pi$ is shown as below:
\begin{figure}[h]
    \centering
    \includegraphics[width=0.55\textwidth]{function_sin_x}
    \caption{$y = \sin(1/x)$}
    \label{fig:function_sin_x}
\end{figure}
\end{example}

\medskip

\newpage
\begin{theorem}[Theorem 2.47 in Rudin's book]
A subset $E$ of the real line $\mathbb{R}^1$ is connected if and only if it has the following property: If $x\in E, y\in E$ and $x<z<y$, then $z\in E$.
\end{theorem}
\begin{proof}
~\begin{enumerate}
    \item ($\Rightarrow$) Prove by contradiction and suppose that if there exists a $z\in (x,y)$ and $z\in E$, then $E = U\cup V$, where 
    \begin{align*}
        U = E\cap (-\infty,z), V = E\cap(x,\infty)
    \end{align*}
    Since $x\in U, y\in V$, $U$ and $V$ are not nonempty. Since $U\subset (-\infty, z)$ and $V\subset (z,\infty)$, then they are separated. Also, we can have $E\cap(U\cap V) = \varnothing$, which means $E$ is not connected. This is a contradiction.
    \item ($\Leftarrow$) Supposed that $E$ is not connected. Then there exist sets $U$ and $V$ separating $E$ such that $E\subset U\cup V, E\cap U\neq\varnothing, E\cap V\neq\varnothing$ and $E\cap(U\cap V) = \varnothing$. Now we pick $x\in U$ and $y\in V$ and without losing generality, assume that $x < y$. Define 
    \begin{align*}
        z = \sup\{(U\setminus V)\cap[x,y]\}
    \end{align*}
    Then $z\in \text{cl}(U)$ and $z\notin V$. In particular, $x\leq z < y$. If $z\notin U\setminus V$, then $z$ certainly does not belong to $E$. If $z\in U\setminus V$, then $z\notin \text{cl}(V)$, hence there exists a $z_1$ such that $z<z_1<y$ and $z_1\notin V$. Then $x<z_1<y$ and $z\notin E$. This is a contradiction.
\end{enumerate}
\end{proof}


\medskip

\subsection{Continuity}
\begin{definition}
Let $(X,d), (Y,\rho)$ be two metric spaces and $A\subset X$. Consider a mapping $f:A\to Y$. If $x_0$ is an accumulation point of $A$, then we say that $\lim_{x\to x_0}f(x) = b \in Y$, if 
\begin{align*}
    \forall\varepsilon>0, \exists\delta>0, 0<d(x,x_0)<\delta \Rightarrow \rho(f(x),b)<\varepsilon
\end{align*}
Equivalently, $\lim_{x\to x_0}f(x) = b$, if
\begin{align*}
    x_0 \neq x_n (x_n\in A) \to x_0 \Rightarrow f(x_n) \to b
\end{align*}
\end{definition}

\begin{definition}
We say that a mapping $f:A\to Y$ is continuous at point $x_0\in A$, if $A\ni x_n\to x_0$ then $f(x_n)\to f(x_0)$(no need of condition: $x_n\neq x_0$). 

If $x_0$ is not an accumulation point of $A$, i.e., $x_0$ is an isolated point, then $f$ is always continuous at $x_0$.
\end{definition}

\begin{definition}
We say that $f:A\to Y$ is continuous if $f$ is continuous at every point in $A$. Equivalently, $f:A\to Y$ is continuous if for every $x\in A$ and $\forall\varepsilon>0$, there exists a $\delta>0$ such that 
\begin{align*}
    d(x,y)<\delta \Rightarrow \rho(f(x),f(y))<\varepsilon.
\end{align*}
This is Definition 4.5 in Rudin's book. 
\end{definition}

\begin{example}
~\begin{enumerate}
    \item If $X$ is a discrete metric space, then every function $f:X\to Y$ is continuous.
    \item $f:\mathbb{Z}\to Y$ or $f:\mathbb{N}\to Y$ is always continuous.
\end{enumerate}
\end{example}

\medskip

\begin{theorem}[Theorem 4.8 in Rudin's book]
A mapping $f:X\to Y$ is continuous if and only if for every open set $U\subset Y$, $f^{-1}(U)$ is an open set in $X$.
\end{theorem}
\begin{proof}
~\begin{enumerate}
    \item ($\Rightarrow$) Suppose $f$ is continuous and $U\subset Y$ is a open set. We want to prove that $f^{-1}(U)$ is open. 
    
    If $x\in f^{-1}(U)$, then $f(x)\in U$ and hence $B(f(x),\varepsilon)\subset U$ for some $\varepsilon > 0$. It follows from the continuity of $f$ there exists a $\delta > 0$ such that $d_Y(f(x),f(y))<\varepsilon$, if $d_X(x,y) < \delta$. Hence, $B(x,\delta)\subset f^{-1}(U)$ and then $f^{-1}(U)$ is open.
    \item ($\Leftarrow$) Suppose now that $f^{-1}(U)$ is open for every open set $U\subset Y$. We need to prove that $f$ is continuous. 
    
    Let $\varepsilon>0$ be given, then $B(f(x_0),\varepsilon)$ is open. Hence $x_0\in f^{-1}(B(f(x_0),\varepsilon))$, which is open. Then there exists a $\delta>0$ such that $B(x_0,\delta)\subset f^{-1}(B(f(x_0),\varepsilon))$. And hence if $d_X(x_0,x)<\delta$, then $d_Y(f(x_0),f(x))<\varepsilon$, which proves the continuity of $f$.
\end{enumerate}
\end{proof}

\medskip

\begin{definition}
We say that a mapping $f:X\to Y$ is $L-Lipschitz$ if $\forall x,y\in X$, $d_Y(f(x),f(y))\leq L d_X(x,y)$. 

We say that a mapping $f:X\to Y$ is Lipschitz if it is $L-Lipschitz$ for some $L>0$.
\end{definition}

\medskip

\begin{proposition}
Every Lipschitz mapping is continuous.
\end{proposition}
\begin{proof}
Suppose $f:X\to Y$ is Lipschitz, then for $x_n\to x$, we have $$d_Y(f(x_n),f(x))\leq L d_X(x_n,x)\to 0$$ 
and hence $f(x_n)\to f(x)$.
\end{proof}
Now we use different method to prove this theorem by showing that $f^{-1}(U)$ is open for every open set $U\subset Y$.
\begin{proof}
Let $U\subset Y$ be given, and let $x\in f^{-1}(U)$. We will prove that 
\begin{align*}
    B\left(x, \frac{\varepsilon}{L}\right)\subset f^{-1}(U)
\end{align*}
where $\varepsilon$ is taken such that $B(f(x),\varepsilon)\subset U$. Now we have
\begin{align*}
    y\in B\left(x, \frac{\varepsilon}{L}\right) \Rightarrow d_X(x,y) < \frac{\varepsilon}{L}
\end{align*}
with $f$ being Lipschitz mapping, we have 
\begin{align*}
    d_Y(f(x),f(y))\leq L d_X(x,y) \leq \varepsilon
\end{align*}
then $f(y)\in B(f(x),\varepsilon)\subset U$. Then $B\left(x, \frac{\varepsilon}{L}\right)\in f^{-1}(U)$.
\end{proof}

\medskip

\begin{example}[Riemann function]
$f$ is defined as below
\begin{align*}
    f(x) = \left\{
    \begin{aligned}
    & 0, \text{if} \quad x \in \mathbb{R}\setminus\mathbb{Q}\\
    & \frac{1}{q}, \text{if} \quad x \in \mathbb{Q}, x = \frac{p}{q}, q > 0
    \end{aligned}
    \right.
\end{align*}
and where the greatest common divisor of $p$ and $q$ is $1$. Then $f$ is continuous at all irrational points and discontinuous at all rational points.
\end{example}

\begin{example}
$f(x,y)$ is defined as below
\begin{align*}
    f(x) = \left\{
    \begin{aligned}
    & 0, \text{if} \quad x \in \mathbb{R}\setminus\mathbb{Q} \\
    & 1, \text{if} \quad x \in \mathbb{Q}
    \end{aligned}
    \right.
\end{align*}
and $f$ is discontinuous everywhere.
\end{example}

\begin{remark}
Practical way of proving continuity of a function of two(or more) variables at a given point is based on the following observation: If
\begin{align*}
    |f(x,y) - L| \leq g(x,y)\rightarrow 0
\end{align*}
where $(x,y)\to(x_0,y_0), (x,y)\neq(x_0,y_0)$, then $\lim_{(x,y)\to(x_0,y_0)}f(x,y) = L$.
\end{remark}

\medskip

\begin{theorem}
If $f:X\to Y$ is continuous and $A\subset X$ is compact, then $f(A)\subset Y$ is compact.
\end{theorem}
\begin{proof}
Let $y_n\in f(A), n = 1,2,\cdots$ be a sequence. Then $y_n = f(x_n)$ for some $x_n\in A$. Since $A$ is compact, then there is a convergent subsequence $\{x_{n_k}\}$ such that $x_{n_k}\to x_0\in A$. Hence, $y_{n_k} = f(x_{n_k})\to f(x_0) \in f(A)$.
\end{proof}

\begin{theorem}
If $f:X\to Y$ is continuous and $A\subset X$ is connected,then $f(A)\subset Y$ is connected.
\end{theorem}
\begin{proof}
Suppose $f(A)$ is not connected. Then there exist open sets $U$ and $V$ such that $f(A)\subset U\cup V, f(A)\cap U\neq\varnothing, f(A)\cap V\neq\varnothing$ and $f(A)\cap (U\cap V)=\varnothing$. 

Then we have $A\subset f^{-1}(U), A\subset f^{-1}(U), A \cap f^{-1}(U)\neq\varnothing, A \cap f^{-1}(V)\neq\varnothing$ and $A\cap (f^{-1}(U)\cap f^{-1}(V))=\varnothing$, which implies that $A$ is disconnected. This is a contradiction.
\end{proof}

\begin{theorem}
If $f:X\to Y$ is continuous and $A\subset X$ is path connected,then $f(A)\subset Y$ is also path connected.
\end{theorem}
\begin{proof}
Let $y_1, y_2\in f(A)$. Then $y_1 = f(x_1), y_2 = f(x_2)$ for some $x_1, x_2\in A$. Since $A$ is connected, then there exists a continuous mapping $\varphi:[a,b]\to A$, such that $\varphi(a) = x_1$ and $\varphi(b) = x_2$. Then we have $\psi = f\circ \varphi: [a,b]\to f(A)$ and $\psi(a) = y_1$, $\psi(b) = y_2$, this is continuous path connecting $y_1$ and $y_2$ in $f(A)$. Thus, $f(A)$ is path connected.
\end{proof}

\begin{theorem}
If $f:A\to \mathbb{R}$ is continuous, where $A\subset X$ is compact, then $f$ attains maximum and minimum in $A$, i.e.,
\begin{align*}
    \exists x_1\in A, \forall x\in A, f(x_1)\geq f(x) \\
    \exists x_2\in A, \forall x\in A, f(x_2)\leq f(x)
\end{align*}
\end{theorem}
\begin{proof}
There is a sequence $\{x_n\}\in A$ such that $f(x_n)\to \sup\{f(x)|x\in A\}$. Since $A$ is compact, then there exists a subsequence $\{x_{n_k}\}$ of $x_n$ such that $x_{n_k}\to x_1$. Then we have $f(x_1) = \sup\{f(x)|x\in A\}$. 

Similar argument works with minimum.
\end{proof}

\begin{corollary}
If $f:[a,b]\to \mathbb{R}$ is continuous, then $f$ is bounded.
\end{corollary}

\medskip

\begin{example}
Consider $f(x) = \frac{1}{x}, x\in (0,1]$ is continuous but unbounded on its domain, since $(a,b]$ is not closed, so the corollary does not apply.
\end{example}

\medskip

Now we classify all connected subsets. 

\begin{lemma}\label{inter_value_connected}
If $A\subset X$ is connected, and $a<c<b, a,b\in A$, then $c\in A$.
\end{lemma}
\begin{proof}
By contradiction and suppose $c\notin A$. Then we can know that $A\subset (-\infty,c)\cup(c,\infty), A\cap (-\infty,c)\neq\varnothing, A\cap (c,\infty)\neq\varnothing$ and $A\cap((-\infty,c)\cap(c,\infty)) = \varnothing$. Thus, $A$ is disconnected, which is a contradiction.
\end{proof}

\begin{theorem}
$A\subset \mathbb{R}$ is connected if and only if $A$ is an interval.
\end{theorem}
\begin{proof}
~\begin{enumerate}
    \item ($\Leftarrow$) Any interval is connected since it is path connected.
    \item($\Rightarrow$) Let $a = \inf\{x|x\in A\}$ and $b = \sup\{x|x\in A\}$. Then there exist sequence $\{a_n\}\in A$ and $\{b_n\}\in A$ such that $a_n\to a$ and $b_b\to b$. It follows from Lemma \ref{inter_value_connected} that $[a_n, b_n]\subset A$. Hence $(a,b) = \bigcup^\infty_{n=1}[a_n,b_n]\subset A$. With the definition of $a$ and $b$ that no number less than $a$ belongs to $A$ and no number bigger than $b$ belongs to $A$. Thus, $A$ is an interval with endpoints $a$ and $b$.
\end{enumerate}
\end{proof}

\begin{theorem}[Intermediate Value Theorem]
If $f:A\to \mathbb{R}$ is continuous, $A\subset X$ is connected and $f(x) = a < c < b = f(y)$, then there exists a $z\in A$ such that $f(z) = c$.
\end{theorem}
\begin{proof}
Since $f$ is continuous, then $f(A)$ is an interval that contains $a$ and $b$, so it must contains $c$. 
\end{proof}

\begin{theorem}
Let $f:A\to \mathbb{R}^n$, $f(x) = (f_1(x), f_2(x), \cdots, f_n(x))$. Then $f$ is continuous if and only if the functions $f_i$ are continuous for $i = 1,2,\cdots, n$.
\end{theorem}
\begin{proof}
If $x_k\to x_0$, then $(f_1(x_k), f_2(x_k), \cdots, f_n(x_k))\to (f_1(x_0), f_2(x_0), \cdots, f_n(x_0))$ if $f_i(x_k)\to f_i(x_0)$.
\end{proof}

\medskip

Now we show a new method to prove the Arithmetic-Geometric mean inequality.

\begin{theorem}[Arithmetic-Geometric mean inequality]
Let $x_1,\cdots,x_n\geq 0$, then 
\begin{align*}
    \sqrt[n]{x_1 \cdots x_n}\leq \frac{x_1+\cdots+x_n}{n}
\end{align*}
and the equality holds if and only if $x_1=\cdots=x_n$.
\end{theorem}
\begin{proof}
Let $x_1+\cdots+x_n = a$. We assume that $a > 0$ or otherwise the inequality is obvious. 

Consider the set $A = \{(z_1,\cdots,z_n)\in\mathbb{R}^n|z_1+\cdots+z_n = a, z_1,\cdots,z_n\geq 0\}$. The set is bounded and closed, and therefore compact. Hence the function $f(z_1,\cdots,z_n) = \sqrt[n]{z_1,\cdots,z_n}$ has maximum in $A$ at some point $(z_1^0,\cdots,z_n^0)\in A$. We will prove that $z_1^0=\cdots=z_n^0$.

Observe first that $z_1^0,\cdots,z_n^0 \geq 0$ because $0$ cannot be maximum of $f$. Suppose that $z_i^0\neq z_j^0$ for some $i\neq j$, then 
\begin{align*}
    \left(\frac{z_i^0 + z_j^0}{2}\right)^2 > z_i^0 z_j^0
\end{align*}
and therefore
\begin{align*}
    \sqrt[n]{z_1^0\cdots\left(\frac{z_i^0 + z_j^0}{2}\right) \cdots \left(\frac{z_i^0 + z_j^0}{2}\right)\cdots  z_n^0} > \sqrt[n]{z_1^0\cdots z_j^0 \cdots z_j^0\cdots  z_n^0}
\end{align*}
and $\left( z_1^0,\cdots,\frac{z_i^0 + z_j^0}{2},\cdots,\frac{z_i^0 + z_j^0}{2},\cdots,z_n^0\right)\in A$, this is contradicted with the definition of $(z_1^0,\cdots,z_j^0,\cdots,z_j^0,\cdots,z_n^0)$. Thus $z_1^0 = \cdots = z_n^0 = \frac{a}{n}$, and we have 
\begin{align*}
    \sqrt[n]{x_1\cdots x_n} \leq \sqrt[n]{z_1^0 \cdots z_n^0} = \frac{a}{n} = \frac{x_1 + \cdots + x_n}{n}
\end{align*}
\end{proof}

\medskip

\subsection{Uniform continuity}
\begin{definition}
$f:A\to Y, A\subset X$ is called uniformly continuous, if for $\forall \varepsilon > 0$, there exists a $\delta > 0$ such that for $\forall x,y\in A$, if $d_X(x,y)<\delta$, then $d_Y(f(x),f(y))<\varepsilon$. 
\end{definition}

\medskip

\begin{proposition}
If $f:(a,b)\to \mathbb{R}$ is uniformly continuous, where $(a,b)$ is a bounded interval, then $f$ is bounded.
\end{proposition}
\begin{proof}
By the definition of uniformly continuity, we take $\varepsilon = 1$. Then there is a $\delta > 0$ such that if $|x-y|\leq\delta$, then $|f(x)-f(y)| < 1$. Choose $N$ such that $N\delta > \frac{b-a}{2}$. 

Let $x\geq \frac{a+b}{2}$, consider a sequence $x_k = \frac{a+b}{2}+\delta k, k=0,1,2\cdots$. Then there is $n<N$ such that $x_n \leq x$ but $x_{n+1}>x$. Thus we have 
\begin{align*}
    \left|f(x) - f\left(\frac{a+b}{2}\right)\right| & = \left|(f(x_n)-f(x_{n_1})) + (f(x_{n_1})-f(x_{n_2})) + \cdots + (f(x_1)-f(x_{n_0}))\right| \\
    & \leq \left|f(x_n)-f(x_{n_1})\right|  + \left|f(x_{n_1})-f(x_{n_2})\right| + \cdots + \left|f(x_1)-f(x_{n_0})\right| \\
    & \leq n+1 \leq N
\end{align*}
which proves $f$ is bounded. 
\end{proof}

\begin{exercise}
Suppose $f:A\to \mathbb{R}$ is uniformly continuous, where $A\subset X$ is a bounded subset of a metric space. Dose it follow that $f$ is bounded? 
\end{exercise}

No. And we will provide a counterexample. 

\begin{proof}
If $X$ is a discrete metric space, then any function $f:X\to\mathbb{R}$ is uniformly continuous. Indeed, let arbitrary $\varepsilon > 0$, then take $\delta = 1$, then if $d_X(x,y)< \delta = 1$, it follows that $x = y$ and $|f(x)-f(y)| = 0 < \varepsilon$. 
Now take $X = \mathbb{Z}$ with the metric metric. Then $X$ is bounded and and $f:X\to \mathbb{R}, f(n) = n$. Then $f$ is uniformly continuous, but not bounded.
\end{proof}

\medskip

\begin{definition}
We say that a function $f:A\to Y$, where $A\subset X$ is $\alpha-$Hlder continuous, $\alpha > 0$, if $\exists c > 0$ such that
\begin{align*}
    d_Y(f(x),f(y))\leq c d_X(x,y)^\alpha
\end{align*}
for all $x,y\in A$.
\end{definition}

\medskip

\begin{theorem}
If $f:A\to Y$ is continuous and $A\subset X$ is compact, then $f$ is uniformly continuous.
\end{theorem}
\begin{proof}
Prove by contradiction, and suppose $\exists\varepsilon > 0$, $\forall \delta > 0$, there exist $x,y\in A$ such that if $d_X(x,y)<\delta$, then $d_Y(f(x),f(y)) < \varepsilon$. \\
\hspace*{1em}\, In particular, there exist sequences $\{x_n\}, \{y_n\}\in A$ such that $d_X(x_n,y_n) < \frac{1}{n}$ and $d_Y(f(x_n),f(y_n))\geq \varepsilon$. Since $A$ is compact, there is a subsequence $\{x_{n_k}\}$ such that $x_{n_k}\to x_0\in A$. Since $d_X(x_{n_k},y_n) < \frac{1}{n_k}$, we also have $y_{n_k}\to x_0$. Hence, with $f$ being continuous, $f(x_{n_k})\to f(x_0)$ and $f(y_{n_k})\to f(x_0)$. Therefore, $d_Y(f(x_{n_k}),f(Y_{n_k}))\to 0$, which contradicts the inequality $d_Y(f(x_{n_k}),f(Y_{n_k})) > \varepsilon$.
\end{proof}

\medskip

Recall that for $f:\mathbb{R}^n\to\mathbb{R}^m$, the graph is defined by
\begin{align*}
    G_f = \{(x,y)\in \mathbb{R}^n\times \mathbb{R}^m|= \mathbb{R}^{n+m}| y = f(x)\}
\end{align*}

\begin{exercise}
Prove that if $f$ is continuous, then $G_f$ is a closed subset of $\mathbb{R}^{n+m}$. Is converse implication true? 
\end{exercise}
\begin{proof}
~\begin{enumerate}
    \item Let $f$ be continuous. We need to prove that if $G_f\ni (x_k,y_k)\to (x_0,y_0)$, then $(x_0,y_0)\in G_f$. We have $(x_k,y_k)\in G_f$, then $y_k = f(x_k)$. Now we have $x_k\to x_0\in \mathbb{R}$, then $f(x_k)\to y_0$. Since $f$ is continuous, then $f(x_k)\to f(x_0)$. Hence $y_0 = f(x_0)$ and therefore $(x_0,y_0) = (x_0, f(x_0)) \in G_f$.
    \item The converse implication is false. For example, consider function 
    \begin{align*}
        f(x) = \left\{
        \begin{aligned}
        & \frac{1}{x}, \text{if}\,\, x \neq 0 \\
        & 0, \text{if}\,\, x = 0
        \end{aligned}
        \right.
    \end{align*}
    which is discontinuous. But its graph is a closed subset of $\mathbb{R}^3$, which is shown as below.
    \begin{figure}[h]
        \centering
        \includegraphics[width=0.60\textwidth]{function_1_x}
        \caption{$y = \sin(1/x)$}
        \label{fig:function_1_x}
    \end{figure}
\end{enumerate}
\end{proof}

\medskip

\begin{exercise}
Prove that if $f:\mathbb{R}^n\to \mathbb{R}^m$ is bounded, then $f$ is continuous if and only if $G_f$ is a closed subset of $\mathbb{R}^{n+m}$.
\end{exercise}
\begin{proof}
~\begin{enumerate}
    \item ($\Rightarrow$) is proved in the previous exercise.
    \item ($\Leftarrow$) Suppose $G_f$ is closed, then we want to prove that if $x_n\to x_0$, then $f(x_n)\to f(x_0)$. We prove it by contradiction and assume that there is a sequence $x_n\to x_0$ such that $\lim_{x_n\to x_0}f(x_n)\neq f(x_0)$.
    
    Then there is a $\varepsilon > 0$, and for $\forall N > 0$ such that if $n > N$, i.e., $\forall n > 0$, we will have $|f(x_n) - f(x_0)|\geq \varepsilon$. Then we can find a convergent subsequence $\{x_{n_k}\}$ such that $\forall k$, $|f(x_{n_k}) - f(x_0)|\geq \varepsilon$. The sequence $f(x_{n_k})$ is bounded in $\mathbb{R}^m$, then it has a convergent subsequence $\{f(x_{n_{k_l}})\}$ converging to $y_0$. And now we have 
    \begin{align*}
        G_f \ni \left(x_{n_{k_l}},f(x_{n_{k_l}})\right) \to (x_0,y_0)
    \end{align*}
    and since $G_f$ is closed, then $(x_0,y_0)\in G_f$ and $y_0 = f(x_0)$. Therefore $f(x_{n_{k_l}})\to f(x_0)$, which is a contradiction.
\end{enumerate}
\end{proof}

\medskip
 
Next we give some important examples and theorems about continuity and metric space.

\begin{exercise}
Let $\{f_n\}^\infty_{n=1}, f_n:[0,1]\to\mathbb{R}$ be a sequence of continuous functions such that:
\begin{enumerate}
    \item $f_n \geq 0$.
    \item $f_{n+1}\leq f_n$.
    \item $\forall x\in [0,1], f_n(x)\to 0$.
\end{enumerate}
Then $f_n$ uniformly converges to $0$.
\end{exercise}
\begin{proof}
Given $\varepsilon > 0$, we need to find $N > 0$ such that if $\forall n \geq N$ and $\forall x\in [0,1]$, then $0 < f_n(x) < \varepsilon$.

For $x\in [0,1]$, let $N_x$ be the least integer such that $f_{N_x} < \varepsilon$. Then for $\forall n \geq N_x$, $f_n(x) < \varepsilon$. Since $f_{N_x}$ is continuous function, so there exists an open neighborhood $U_x$ of $x$ in $[0,1]$ such that for $z\in U_x$, we have $f_{N_x}(x) < \varepsilon$. 

Since $[0,1]$ is compact, then there exists a finite open covering such that $[0,1]\subset U_{x_1}\cup U_{x_2} \cup \cdots \cup U_{x_k}$. Now we pick $N = \max\{N_{x_1},N_{x_2},\cdots,N_{x_k}\}$, where $N_{x_j}$ is the least number such that $f_{N_{x_j}}(x_j) < \varepsilon$. If $n\geq N$ and for $x\in[0,1]$, then $x\in U_{x_i}$ for some $i\in\{1,2,\cdots, k\}$, which implies $0 \leq f_n(x) \leq f_N(x) \leq f_{N_i}(x) < \varepsilon$.
\end{proof}

\medskip

\begin{exercise}
Let $F:\mathbb{R}^n\to\mathbb{R}$ be a norm, i.e., for $\forall x,y\in \mathbb{R}^n$ and $t\in\mathbb{R}$, we have
\begin{enumerate}
    \item $F(x)\geq 0$ and $F(x) = 0$ if and only if $x = 0$.
    \item $F(x+y)\leq F(x) + F(y)$.
    \item $F(tx) = |t|F(x)$
\end{enumerate}
Then there exist $A,B > 0$ such that $A\|x\|\leq F(x)\leq B\|x\|$ for all $x\mathbb{R}$.
\end{exercise}
\begin{proof}
~\begin{enumerate}
    \item We claim that $F$ is bounded on unit sphere $\{\|x\| = 1\}$. \\
    Let $\{e_1,e_2,\cdots,e_n\}$ be orthonormal basis for $\mathbb{R}^n$, then any $x\in\mathbb{R}^n$ can be written as
    \begin{align*}
        x = \sum^n_{i=1} c_ie_i
    \end{align*}
    If $\|x\| = 1$, then we have $|c_i| \leq 1$. And we have 
    \begin{align*}
        F(x) = F\left(\sum^n_{i=1} c_ie_i\right) \leq \sum^n_{i=1} |c_i| F(e_i) \leq \sum^n_{i=1} F(e_i) = B
    \end{align*}
    Then there exists a $B > 0$.
    \item Now we claim $F$ is continuous. \\
    If $x \neq y$, then we have $y = x + \|y-x\|\cdot \frac{y-x}{\|y-x\|}$. Thus, we have
    \begin{align*}
        & F(y) \leq F(x) + \|y-x\| F \left(\frac{y-x}{\|y-x\|}\right) \\
        \Rightarrow & F(y) - F(x) \leq B\|y-x\|
    \end{align*}
    Now we switch $x$ and $y$, then we have $F(x) - F(y) \leq B\|y-x\|$. Thus we have $|F(x) - F(y)|\leq B \|y-x\|$, which implies $F$ is continuous. \\

    Now we complete the proof. Since $F$ is continuous, so it obtains its minimum $A$ on the compact unit sphere, i.e.,
    \begin{align*}
        & A = \inf_{\|x\| = 1}F(x) = F(x_0) > 0 \\
        \Rightarrow & A\leq F(x) \leq B, \|x\| = 1
    \end{align*}
    Now if $\|x\|\neq 0$ is any point in $\mathbb{R}^n$, then 
    \begin{align*}
        & F(x) = F\left(\|x\|\cdot\frac{x}{\|x\|}\right) = \|x\|\cdot F\left(\frac{x}{\|x\|}\right) \\
        \Rightarrow & A\|x\|\leq F(x)\leq B\|x\|
    \end{align*}
\end{enumerate}
\end{proof}

\begin{exercise}
Prove that if $X$ is a metric space, and $f:X\times[0,1]\to\mathbb{R}$ is continuous, then $g:X\to\mathbb{R}$, which is defined by 
\begin{align*}
    g(x) = \sup_{t\in[0,1]}f(x,t)
\end{align*}
is continuous.
\end{exercise}
\begin{proof}
Prove by contradiction, and suppose $g$ is not continuous, i.e., there exists $\varepsilon > 0$, for $\forall \delta > 0$, $\exists x_0 \in[0,1]$ such that if $d_X(x,x_0) < \delta$, then $|g(x) - g(x_0)|\geq\varepsilon$. 

Fix such $\varepsilon > 0$, we pick $\delta = \frac{1}{n}$, then exists $x_n$ such that $d_X(x_n,x_0) < \frac{1}{n}$, then $|g(x_n) - g(x_0)| \geq \varepsilon$, which implies
\begin{align*}
    \left|\sup_t f(x_n,t) - \sup_t f(x_0,t)\right| \geq \varepsilon
\end{align*}
then there exist $t_n, t_0\in[0,1]$ such that 
\begin{align*}
    \left|f(x_n,t_n) - f(x_0,t_0)\right| \geq \varepsilon
\end{align*}
where $x_n\to x_0$. Then there exists a subsequence $t_{n_k}\to s$, such that $f(x_{n_k},t_{n_k})\to f(x_0,s)$. Then we have 
\begin{align*}
    f(x_{n_k},t_{n_k}) & = \sup_t f(x_{n_k},t) \geq f(x_{n_k},t_0) \\
    f(x_0,t_0) & = \sup_t f(x_0,t) \geq f(x_0,s) 
\end{align*}
Thus, we have 
\begin{align*}
    f(x_0,t_0) \leftarrow f(x_{n_k},t_0) \leq f(x_{n_k},t_{n_k}) \rightarrow f(x_0,s) \leq f(x_0,t_0)
\end{align*}
which means $f(x_{n_k},t_{n_k})\to f(x_0,t_0)$, and this is a contradiction to the assumption above.
\end{proof}

\medskip

\begin{exercise}
If $f:\mathbb{R}^n\to\mathbb{R}^m$ is a continuous mapping, which maps open sets to open sets and $f^{-1}(K)$ is compact whenever $K$ is compact. Show that $f(\mathbb{R}^n) = \mathbb{R}^m$.
\end{exercise}
\begin{proof}
It suffices to show that $f(\mathbb{R}^n)$ is open and closed at the same time. 
\begin{enumerate}
    \item $f(\mathbb{R}^n)$ being open is obvious, since $f$ maps open set to open set.
    \item For every $y\in{\rm cl}(f(\mathbb{R}^n))$, we need to prove that $y\in f(\mathbb{R}^n)$. Pick a sequence $\{y_n\}^\infty_{n = 1}\in \mathbb{R}^m$ such that $y = \lim_{n\to\infty}y_n = \lim_{n\to\infty} f(x_n)$. The set $K = \{y\}\cup \{y_1, y_2, \cdots\}$ is compact, since every open covering has a finite subcovering. Then we know $x_n\in f^{-1}(K)$, and $f^{-1}(K)$ is compact. Then there exists a subsequence $\{x_{n_k}\}$ converging to $x$. Then we have $y\Leftarrow y_{n_k} = f(x_{n_k}) \to f(x)$, thus, $y = f(x)\in f(\mathbb{R}^n)$, which implies $f(\mathbb{R}^n)$ is closed.
\end{enumerate}
\end{proof}

\medskip

\begin{exercise}
If $f:K\to K$ is a continuous, one-to-one and onto function, and $K$ is compact. Prove that $f^{-1}:K\to K$ is continuous.
\end{exercise}
\begin{proof}
It suffices to prove that if $y_n\to y$, then $x_n = f^{-1}(y_n)\to f(y) = x$. Suppose by contrary that $x_n \nrightarrow x$. Then for any $\varepsilon > 0$, we have $d\left(x_{n_k}, x\right)\geq \varepsilon, x_{n_k}\in\{x_n\}$. Since $K$ is compact, then there is a convergent subsequence $x_{n_{k_l}}$ of $\{x_{n_k}\}$ such that $x_{n_{k_l}}\to\Tilde{x}$ and $\Tilde{x}\neq x$. Also, we have 
\begin{align*}
    y \Leftarrow y_{n_{k_l}} = f\left(x_{n_{k_l}}\right) \to f(\Tilde{x}) \\
    \Rightarrow y = f(x) = f(\Tilde{x}), x \neq \Tilde{x}
\end{align*}
which is contradicted with $f$ being one-to-one. The proof is complete. 
\end{proof}

\medskip

\begin{exercise}
Prove that if $E\subset\mathbb{R}^n$ is not compact, then there exists a continuous and unbounded function $f:E\to\mathbb{R}$.
\end{exercise}
\begin{proof}
Since $E$ is not compact, then $E$ is not bounded or not closed. 
\begin{enumerate}
    \item If $E$ is not bounded, we can take $f(x) = |x|$.
    \item If $E$ is not closed, then there exists a sequence $E \ni\{x_i\}^\infty_{n = 1} \to x \notin E$, then we take $f(x_i) = \frac{1}{|x_i - x|}$.
\end{enumerate}
\end{proof}

\medskip

\begin{definition}
$E\subset X$ is a Gs set if there are open sets $U_i, i = 1,2,\cdots$ such that $E = \cap^\infty_{i=1}U_i$.
\end{definition}
\begin{exercise}
Prove that if $f:X\to\mathbb{R}$ is a continuous function, then the set $\{x\in X |\, f\, {\rm is \,\, continuous\,\, at}\, x\}$ is Gs set.
\end{exercise}
\begin{proof}
We can know  that $f$ is continuous at $x$ if and only if for $\forall n \in\mathbb{N}$, there exists $M\in\mathbb{N}$ such that if $\forall z,w$ satisfying $d(x,z) < 1/m, d(x,w) < 1/m$, then $|f(z) - f(w)| < 1/n$. Indeed, if $f$ is continuous, then $\forall n \in\mathbb{N}$, there exists $M\in\mathbb{N}$, such that if $d(\xi,x) < 1/m$, then $|f(\xi) - f(x)| < 1/2n$. Then, for $d(x,z) < 1/m, d(x,w) < 1/m$, we have $$|f(z) - f(w)| < |f(z) - f(x)| + |f(x) - f(w)| < 1/n.$$

The set 
\begin{align*}
    & \{x\in X |\, f\, {\rm is \,\, continuous\,\, at}\, x\} = \\
    & \bigcap^\infty_{n=1} \bigcup^\infty_{m=1} \left\{x |\, \forall z,w, d(x,z) < \frac{1}{m}, d(x,w) < \frac{1}{m} \Rightarrow |f(z) - f(w)| < \frac{1}{n} \right\} \\
    & = \bigcap^\infty_{n=1} \bigcup^\infty_{m=1} A_{n,m} = \bigcap^\infty_{n=1} U_n
\end{align*}
where $U_n = \cup^\infty_{m=1} A_{n,m}$. Then it suffices to prove that $U_n$'s are open. 

If $x\in U_n$, then there exists $M_0 > 0$ such that $d(x,z) < 1/M_0, d(x,w) < 1/M_0$, then $|f(z) - f(w)| < 1/n$. Now we prove that $B\left(x,\frac{1}{2M_0}\right)\subset U_n$. 

And it suffices to prove that if $d(x,x') < 1/2M_0$, then $x'\in A_{n,2M_0}\subset U_n$, i.e., if $d(x', z) < 1/2M_0, d(x', w) < 1/2M_0$, then we have $|f(z) - f(w)| < 1/n$. Indeed, suppose $d(x', z) < 1/2M_0, d(x', w) < 1/2M_0$, then we have 
\begin{align*}
    d(x,z) & \leq d(x,x') + d(x', z) < \frac{1}{2M_0} = \frac{1}{M_0} + \frac{1}{2M_0} = \frac{1}{M_0} \\
    d(x,w) & \leq d(x,x') + d(x', w) < \frac{1}{2M_0} = \frac{1}{M_0} + \frac{1}{2M_0} = \frac{1}{M_0}
\end{align*}
Then we have $|f(z) - f(w)| < 1/n$. Thus, $x'\in A_{n,2M_0}$, which implies $U_n$'s are open. The proof is complete.
\end{proof}

\medskip

\begin{exercise}
There is no continuous and one-to-one function $f:\mathbb{R}^2\to\mathbb{R}$.
\end{exercise}
\begin{proof}
Consider function $g = f|_{S'}: S'\to\mathbb{R}$ being continuous and one-to-one, where $S'$ is a unit circle. Since $S'$ is compact and connected, $g(S')$ is also compact and connected. Indeed, if $f:\mathbb{R}^2\to\mathbb{R}$ is continuous, then its image is connected, that is an interval in $\mathbb{R}$. However if we remove any point from $\mathbb{R}^2$ it remains connected, however if we remove a point whose image is in the interior of the interval then the image cannot be still connected if the function is injective.

Here we present two solutions:
\begin{enumerate}
    \item Consider $c \in (a,b)$ and $g(z) = c, z\in S'$. Then we have $g(S'\setminus \{z\}) = [a,c)\cup (c,b]$, where $S'\setminus \{z\}$ is connected and $[a,c)\cup (c,b]$ is disconnected.
    \item Consider $a = g(z_1), b = g(z_2)$, where $z_1, z_2\in S'$. And we denote one arc between $z_1$ and $z_2$ by $C_1$, and the other one $C_2$. Then we have $g(C_1) = [a,b]$ and $g(C_2) = [a,b]$, thus $g$ is not one-to-one.
\end{enumerate}
\end{proof}

\medskip

\begin{theorem}
If $A\subset U$ is a dense subset of a metric space, i.e., $\text{cl}(A) = X$, and $f:A\to\mathbb{R}$ is uniformly continuous, then there is a unique continuous function $F:X\to\mathbb{R}$ such that $F(x) = f(x)$ for all $x\in A$. Moreover, $F$ is uniformly continuous.
\end{theorem}

Before we prove the theorem, we first introduce an exercise, then we provide the proof of theorem.

\begin{exercise}
If $f:(a,b)\to\mathbb{R}$ is uniformly continuous, and $-\infty < a < b < \infty$, then $f$ extends to a continuous function $F:[a,b)\to\mathbb{R}$. In particular, $F$ is bounded.
\end{exercise}

\begin{proof}
For $x\in X$, we choose a unique $A\ni a_k^x\to x$. Since $f$ is uniformly continuous, then $\forall\varepsilon > 0$, there exists $\delta > 0$, and for $\forall x,y\in A$, if $d_X(x,y) < \delta$, then $|f(x) - f(y)| < \varepsilon$. For such $\delta > 0$, there exists a $N > 0$ such that $\forall k,l > N$, then $d_X(a_k^x, a_l^x) < \delta$, and hence $$|f(a_k^x) - f(a_l^x)| < \varepsilon$$
then we can know that $\{f(a_k^x)\}^\infty_{k=1}$ is a Cauchy sequence. Thus it is convergent. 

We now define $$F(x) = \lim_{k\to\infty}f(a_k^x)$$
If $d_X(x,y) < \delta$, then $d_X(a_k^x,a_k^y) < \delta$. Then for some $K > 0$, if $\forall k \geq K$, then $$|f(a_k^x) - f(a_k^y)| < \varepsilon \Rightarrow |F(x) - F(y)| < \varepsilon$$
Thus, $F$ is uniformly continuous.
\end{proof}

\medskip

Now we define a metric space with $l^\infty = \{x = (x_1,x_2,\cdots) | \|x\|_\infty = \sup_i |x_i| < \infty\}$ and metric $d_\infty(x,y) = \sup_i (x_i - y_i)$. Then we discuss some exercises. 

\begin{exercise}
Show that the Hilbert cube 
$$\mathcal{H} = \{x = (x_1,x_2,\cdots) | 0\leq x_i \leq 2^{-i}, i = 1,2,\cdots\}$$
is a compact subset of $l^\infty$.
\end{exercise}
\begin{proof}
Let $x^{(n)} = \left(x_1^{(n)},x_2^{(n)},\cdots \right)\in \mathcal{H}$, and using diagonal method, we can find a sequence $\{x^{(n_k)}\}$ such that for $\forall i$, $x_i^{(n_k)}$ converges, such that $x_i^{(n_k)}\to x_i$, with $0\leq x_i^{(n_k)}\leq 2^{-i}$. Then we have $0\leq x_i\leq 2^{-i}$, which implies that $x = \left(x_1, x_2, \cdots \right)\in \mathcal{H}$. 

It remains to show that $x^{(n_k)}\stackrel{l^\infty}{\longrightarrow}x$. Given $\varepsilon > 0$, let $N > 0$ be such that $2^{-N} < \varepsilon/2$. Also, there exists $K$, for $\forall k \geq K$, such that $\left|x_i^{(n_k)} - x_i\right| < \varepsilon/2, i = 1,2,\cdots, N$. Then for $i > N$, we have 
$\left|x_i^{(n_k)} - x_i\right| < \left|x_i^{(n_k)}\right| + |x_i| < \varepsilon$
Thus, for $\forall k \geq K$ and $\forall n\in \mathbb{N}$, we have 
\begin{align*}
    & \left|x_i^{(n_k)} - x_i\right| < \varepsilon \\
    \Rightarrow & \|x_i^{(n_k)} - x_i\|_\infty < \varepsilon \\
    \Rightarrow & x^{(n_k)}\stackrel{l^\infty}{\longrightarrow}x
\end{align*}
The proof is complete.
\end{proof}


\medskip

\begin{theorem}[Weierstrass]\label{Weierstrass_1}
If $f:[a,b]\to\mathbb{R}$ is a continuous function, then for every $\varepsilon > 0$, there is a polynomial $p_\varepsilon$ such that
$$\left|f(x) - p_\varepsilon \right| < \varepsilon$$
for all $x\in[a,b]$.
\end{theorem}

\medskip

Before we prove this theorem, we need to consider some material about metric space. Now recall that 
\begin{align*}
    C([a,b],\mathbb{R}) = \{f:[a,b]\to\mathbb{R} | f\, \text{is continuous}\}
\end{align*}
is a metric space with the metric $d_\infty(f,g) = \|f - g\|_\infty = \sup_{x\in[a,b]} |f(x) - g(x)|$. We use compactness of $[a,b]$ to ensure that $d_\infty(f,g) < \infty$ for every $f,g\in C([a,b],\mathbb{R})$. The compactness of $[a,b]$ is needed. For example, $f(x) = x$ and $g(x) = 0$ for $x\in\mathbb{R}$ belong to to $C(\mathbb{R},\mathbb{R})$ but $d_\infty(f,g) = \sup_{x\in\mathbb{R}}|x| = \infty$, which means $d_\infty$ is not a metric in $C(\mathbb{R},\mathbb{R})$.

\medskip

\begin{lemma}
Suppose $f_n,f\in C([a,b])$. Then $f_n$ uniformly converges to $f$, i.e., $f_n \rightrightarrows f$ if and only if $d_\infty(f_n,f)\to 0$.
\end{lemma}
\begin{proof}
\begin{align*}
    & f_n\rightrightarrows f\, \text{in}\, d_\infty \Leftrightarrow d_\infty(f_n,f)\to 0 \\
    \Leftrightarrow & \forall \varepsilon > 0, \exists N, \forall n\geq N, d_\infty(f_n,f) < \varepsilon \\
    \Leftrightarrow & \forall \varepsilon > 0, \exists N, \forall n\geq N, \forall x\in [a,b], \left|f_n(x) - f(x)\right| < \varepsilon \\
    \Leftrightarrow & f_n \rightrightarrows f
\end{align*}
\end{proof}

\begin{remark}
Similarly, if $E\subset X$ is a compact subset, then $$C(E,\mathbb{R}) = \{f:E\to \mathbb{R} | f\, {\rm is \,\, continuous}\}$$ 
is a metric space, where $d_\infty(f,g) = \sup_{x\in E}\left(f(x)-g(x)\right)$.
\end{remark}

The following lemma can be proved by the exact the same argument mentioned above.

\begin{lemma}
Suppose $E\subset X$ is a compact subset and $f_n,f\in C(E,\mathbb{R}), n = 1,2,\cdots$. Then $f_n\to f$ in $C(E,\mathbb{R})$ if and only if $f_n\rightrightarrows f$.
\end{lemma}

\begin{theorem}
Suppose $E\subset X$ is a compact subset. Then $\left(C(E), d_\infty\right)$ is a complete metric space.
\end{theorem}
\begin{proof}
Let $\{f_n\}_n\in C(E)$ be Cauchy sequence, i.e., for $\forall \varepsilon > 0$, $\exists N > 0$, such that $\forall n,m \geq N$, $d_\infty(f_n,f_m) < \varepsilon$, and this is equivalent to the statement that for $\forall \varepsilon > 0$, $\exists N > 0$, such that $\forall n,m \geq N$ and $\forall x\in E$, $\left|f_n(x) - f_m(x)\right| < \varepsilon$. 

For $\forall x\in E$, $\{f_n(x)\}_n$ is a Cauchy sequence, then convergent. Let $f(x) = \lim_{n\to\infty}f_n(x)$, and for $n,m\geq N$, we have $\left|f_n(x) - f_m(x)\right| < \varepsilon$. Now we fix $n$ and let $m\to\infty$, then we have $\left|f_n(x) - f(x)\right| < \varepsilon$. Then for $\forall \varepsilon > 0$, there exists $N > 0$, such that for $\forall n\geq N$, $\left|f_n(x) - f(x)\right| < \varepsilon$, which implies $f_n\rightrightarrows f$ in $d_\infty$. Then $f$ is continuous, which means $f\in C(E)$. Thus, $\left(C(E), d_\infty\right)$ is a complete metric space.
\end{proof}

\medskip

We have another definition of dense subset.

\begin{definition}
A subset $A\subset X$ is dense if $\text{cl}(A) = X$.
\end{definition}

\begin{proposition}
Let $A\subset X$ be a subset. Then the following conditions are equivalent:
\begin{enumerate}
    \item $A$ is dense in $X$.
    \item $\text{cl}(A) = X$.
    \item For $\forall x\in A$, there is a sequence $x_n\in A$ such that $x_n\to x$.
    \item Every ball of $x$ contains elements of $A$, i.e., $\forall x\in A$, there exists $r > 0$, such that $B(x,r)\cap A\neq\varnothing$.
\end{enumerate}
\end{proposition}

\begin{theorem}[Weieratrass]
The class of polynomials on $[a,b]$ form a dense subset of $C\left([a,b],\mathbb{R}\right)$.
\end{theorem}

The Weieratrass theorem is a direct result from the following theorem.

\begin{theorem}[Stone-Weieratrass]
Let $X$ be a metric space and $E\subset X$ a compact subset. Let $\mathcal{A}\subset C(E,\mathbb{R})$ satisfies the following properties:
\begin{enumerate}
    \item $\mathcal{A}$ is an algebra, i.e., if $f,g\in \mathcal{A}, \alpha\in\mathbb{R}$, then $f+g,fg,\alpha f\in\mathcal{A}$.
    \item The constant function $f(x)\equiv 1$ for $x\in E$ belongs to $\mathcal{A}$.
    \item $\mathcal{A}$ separates points, i.e., for every $x,y\in E, x\neq y$, there exists $f\in\mathcal{A}$ such that $f(x)\neq f(y)$.
\end{enumerate}
Then $\mathcal{A}$ is a dense subset of $C(E,\mathbb{R})$, i.e., $\text{cl}(A) = C(E,\mathbb{R})$.
\end{theorem}

Observe that the set $\mathcal{A} = \{f:[a,b]\to\mathbb{R} | f\, \text{is a polynomial}\}$ has all three properties above and hence the Weierstrass theorem follows the Stone-Weieratrass theorem. 
\begin{proof}
We want to prove that $\text{cl}(A) = C(E,\mathbb{R})$. The set $\text{cl}(A)$ satisfies the properties $(1),(2)$ and $(3)$ as well. Indeed, properties $(2)$ and $(3)$ are obvious because they are already satisfied by elements of $\mathcal{A}$, which is a subset of $\text{cl}(A)$, and the property $(1)$ can be proved as follows: 

Let $f,g\in \text{cl}(A), \alpha\in\mathbb{R}$. Then there are sequences $\{f_n\},\{g_n\}\in\mathcal{A}$ such that $f_n\rightrightarrows f$ and $g_n\rightrightarrows g$. And hence 
\begin{align*}
    f_n+g_n \rightrightarrows f+g,
    f_n g_n \rightrightarrows fg,
    \alpha f_n \rightrightarrows \alpha f
\end{align*}
we have $f+g,fg,\alpha f\in\text{cl}(A)$. It follows from Weierstrass theorem \ref{Weierstrass_1} that for every $n\in\mathbb{N}$, there is a polynomial $p_n$ such that $\left||t| - p_n(t)\right| < 1/n$ for $-n\leq t \leq n$. Thus, we have
\begin{align*}
    \left||f(x)| - p_n(f(x))\right| < \frac{1}{n}
\end{align*}
provided $-n \leq f(x) \leq n$. If $f\in\text{cl}(A)$, then $f$ is continuous and hence bounded (since $E$ is bounded), so if $n$ is sufficiently large enough such that $-n \leq f(x) \leq n$ for all $x\in E$ and hence 
\begin{equation}
    \label{equ_1}
    \left||f(x)| - p_n(f(x))\right| < \frac{1}{n}, \forall x\in E
\end{equation}

Since $\text{cl}(A)$  is an algebra, it follows that $p_n(f(x))\in\text{cl}(A)$ and hence (\ref{equ_1}) implies that $|f|$ is a limit of an uniformly convergent sequence of functions in $\text{cl}(A)$, i.e., the limit of a sequence in $\text{cl}(A)$ that converge in the metric space. Therefore, we have
\begin{align*}
    |f| \in \text{cl}(A)
\end{align*}
We proved that if $f\in\text{cl}(A)$, then $|f|\in\text{cl}(A)$. Now we introduce notation 
\begin{align*}
    (f \wedge g)(x) & = \max\{f(x),g(x)\}\\
    (f \vee g)(x) & = \min\{f(x),g(x)\}
\end{align*}
and since 
\begin{align*}
    f \wedge g & = \frac{f+g}{2} + \frac{|f-g|}{2} \\
    f \vee g & = \frac{f+g}{2} - \frac{|f-g|}{2}
\end{align*}
we can conclude that if $f+g\in\text{cl}(A)$, then $f\wedge g, f\vee g\in \text{cl}(A)$. 

Let $h\in C(E,\mathbb{R})$ be arbitrary. We need to prove that for every $\varepsilon > 0$, there exists $f\in\text{cl}(A)$ such that $|f(z) - h(z)| < \varepsilon$, for all $z\in E$. Indeed, this claim implies that $h\in \text{cl}(A)$.

Let $x_1, x_2\in E, x_1\neq x_2$. Then there exists a function in $\mathcal{A}$, denote it by $f_{x_1 x_2}$ such that $f_{x_1 x_2}(x_1) = h(x_1)$ and $f_{x_1 x_2}(x_2) = h(x_2)$. Indeed, choose $g\in\mathcal{A}$ such that $g(x_1)\neq g(x_2)$ and define $f_{x_1 x_2} = \alpha g+\beta$ for a suitable choice of $\alpha, \beta\in\mathbb{R}$.

Fix $\varepsilon > 0$. Let $x\in E$, and for $y\in E$, we have $f_{yx}(y) = h(y)$ and hence there is a neighborhood $U(y)$ of $y$ such that 
\begin{align*}
    f_{yx}(z) > h(z) - \varepsilon
\end{align*}
The sets $\{U(y)\}_{y\in E}$ form an open covering of $E$. Thus, there is a finite subcovering
\begin{align*}
    E = \bigcup^n_{i=1}U(y_i)
\end{align*}

Denote $f_x = f_{y_1 x}\vee \cdots f_{y_n x}$. Clearly, $f_x\in \text{cl}(A)$. We have if $z\in E$, then $z\in U(y_i)$ for some $i\in\{1,2,\cdots,n\}$, then we have $$f_{y_i x}(z) > h(z) - \varepsilon$$
which implies 
\begin{align*}
    f_x(z) = \max\{f_{y_1 x}(z), \cdots, f_{y_n x}(z)\} \geq f_{y_i x}(z) > h(z) - \varepsilon
\end{align*}
i.e., $f_x(z) > h(z) - \varepsilon$ for all $z\in E$. Also, we have 
\begin{align*}
    f_x(x) = \max\{\underbrace{f_{y_1 x}(x)}_{h(x)}, \cdots, \underbrace{f_{y_n x}(x)}_{h(x)}\} = h(x)
\end{align*}
which implies $f_x(x) = h(x)$. 

Hence there is a neighborhood $V(x)$ of $x$ such that 
\begin{align*}
    f_x(z) < h(z) + \varepsilon
\end{align*}
for all $z\in V(x)$. The sets $\{V(x)\}_{x\in E}$ form an open covering of $E$, so there is a finite subcoveirng 
\begin{align*}
    E = \bigcup^m_{i=1}V(x_i)
\end{align*}
We define $f = f_{x_1}\vee\cdots\vee f(x_m)$ and clearly $f\in \text{cl}(A)$. Also, we have 
\begin{align*}
    f(z) = \min\{\underbrace{f_{x_1}(z)}_{>h(z)-\varepsilon}, \cdots, \underbrace{f_{x_m}(z)}_{>h(z)-\varepsilon}\} > h(z) - \varepsilon
\end{align*}
i.e.,  
\begin{equation}\label{equ_2}
    f(z) > h(z) -\varepsilon, \forall z\in E
\end{equation}

On the other hand, we have if $z\in E$, then $z\in V(x_i)$ for some $i$, and then $f_{x_i}(z) < h(z) + \varepsilon$. Thus, we have 
\begin{equation}\label{equ_3}
    f(z) = \min\{f_{x_1}(z), \cdots,f_{x_m}(z)\} \leq f_{x_i}(z) < h(z) + \varepsilon
\end{equation}
The inequality (\ref{equ_2}) and (\ref{equ_3}) gives 
\begin{align*}
    h(z) - \varepsilon < f(z) & < h(z) + \varepsilon, \forall z\in E \\
    \Rightarrow \left|f(z) - h(z)\right| & < \varepsilon, \forall z\in E
\end{align*}
The proof is complete.
\end{proof}

\begin{corollary}
If $f:\overline{B^n}(0,1)\to\mathbb{R}$ is a continuous function on the closed unit ball in $\mathbb{R}^n$, then for every $\varepsilon > 0$, there is a polynomial $$p_\varepsilon(x) = p_\varepsilon(x_1,\cdots,x_n) = \sum_{k_1,\cdots,k_n}a_{k_1 \cdots k_n}x_1^{k_1}\cdots x_n^{k_n}$$
such that $|f(x) - p_\varepsilon(x)| < \varepsilon$ for all $x\in \overline{B^n}(0,1)$.
\end{corollary}
\begin{proof}
Indeed, polynomials of $n$-variables as in the corollary satisfy the conditions of Stone-Weieratrass theorem.
\begin{enumerate}
    \item $p,q$ are polynomials and $\alpha\in\mathbb{R}$, then $p+q, pq$ and $\alpha p$ are polynomials.
    \item $p\equiv 1$ is a polynomial.
    \item Polynomials separate points. If $x\neq y$, then $x_i\neq y_i$ for some $i$ and hence the polynomial $p(x) = x_i$ satisfies $p(x) = x_i \neq y_i = p(y)$.
\end{enumerate}
\end{proof}


\begin{corollary}[Weieratrass]
Any $2\pi$-periodic function of $x\in\mathbb{R}$ can be uniformly approximated by trigonometric polynomial
\begin{align*}
    T(x) = \sum^n_{k=0}a_k \cos kx + \sum^n_{k=0}b_k \sin kx
\end{align*}
i.e., if $f:\mathbb{R}\to\mathbb{R}$ is continuous and $2\pi$-periodic, then foe every $\varepsilon > 0$, there is a trigonometric polynomial $T_\varepsilon(x)$ such that
\begin{align*}
    |f(x) - T_\varepsilon(x)| < \varepsilon
\end{align*}
for all $x\in\mathbb{R}$.
\end{corollary}
\begin{proof}
It suffices to prove the estimate $|f(x) - T_\varepsilon(x)| < \varepsilon$ for all $x\in[0,2\pi)$. Observe that trigonometric polynomials have the following properties:
\begin{enumerate}
    \item They can form an algebra.
    \item $T\equiv 1$ is a polynomial.
    \item They separate points in $[0,2\pi)$.
\end{enumerate}

However, we cannot apply Stone-Weierstrass theorem directly, because the interval $[0,2\pi)$ is not compact. Since $2\pi$-periodic functions have the following property $f(0) = f(2\pi)$, then we can consider the parameterization of the unit circle $S$: 
\begin{equation}\label{map_unit_circle}
    \varphi: [0,2\pi]\ni x \xlongrightarrow{\varphi}(\cos x, \sin x) = e^{ix}\in S
\end{equation}
Observe that $\varphi(0) = \varphi(2\pi)$, so the paramterization $\varphi$ connects the endpoints of the interval $[0,2\pi]$ to make it a circle. This paramterization allows us to identify continuous functions on $[0,2\pi]$ satisfying (\ref{map_unit_circle}) with continuous functions on $S$. Indeed, if $\Tilde{f}:S\to\mathbb{R}$ is continuous, then
\begin{align*}
    f(x) = \Tilde{f}(\cos x,\sin x):[0,2\pi]\to\mathbb{R}
\end{align*}
is continuous and satisfies (\ref{map_unit_circle}). In other direction, if $f:[0,2\pi]\to\mathbb{R}$ is continuous and satisfies (\ref{map_unit_circle}), then $\Tilde{f}(\cos x,\sin x) = f(x)$ is a continuous function on $S$. And continuity is clear if $x\in(0,2\pi)$ and we need to check it at the endpoints which corresponding to the point $(1,0) = (\cos 0,\sin 0) = (\cos 2\pi,\sin 2\pi)$ on the circle. And the continuity at this point follows from (\ref{map_unit_circle}), which gives 
\begin{align*}
    \Tilde{f}(\cos 0,\sin 0) = f(0) = f(2\pi) = \Tilde{f}(\cos 2\pi,\sin 2\pi)
\end{align*}

In particular, the trigonometric polynomials define a class of continuous functions on $S$. Because of the properties $(1),(2)$ and $(3)$ proved above, this class of functions on $S$ form an algebra. Since $S$ is compact, then the conditions of Stone-Weierstrass theorem are satisfied. 

Now if $f:\mathbb{R}\to\mathbb{R}$ is $2\pi$-periodic and continuous, then for a corresponding continuous function $\Tilde{T}$ on $S$, there is a function $T_\varepsilon$ associated with a trigonometric polynomial such that 
$$|\Tilde{T}_\varepsilon - \Tilde{f}| < \varepsilon \,\, \text{on} \,\, S$$
and hence 
$$|T_\varepsilon(x) - f(x)| < \varepsilon$$
for all $x\in[0,2\pi)$.
\end{proof}

\medskip

Consider a space of complex valued continuous function $C(E,\mathbb{C})$, where $E$ is a compact set. The space is defined exactly in the same way as n the case of real valued functions and the only difference is that we replace $\mathbb{R}$ with $\mathbb{C}$ in definition. And $C(E,\mathbb{C})$ is a complete metric space. 

\begin{exercise}
Prove that the complex polynomials 
\begin{align*}
    p(z) = \sum^k_{n=0}c_n z^n, c_n\in\mathbb{C}
\end{align*}
are not dense in $C(\overline{D},\mathbb{C})$, where $\overline{D} = \{z\in \mathbb{C} \,| \left|z\right|\leq 1\}$ is the closed unit disc in $\mathbb{C}$.
\end{exercise}
\begin{proof}
For $z = e^{ix} = \cos x + i\sin x$ on the unit circle, we have $\bar{z} = z^{-1}$, then $$\bar{p}(z) = \sum^k_{n=0}\bar{c_n} z^{-n}$$
which is not a polynomial, since the exponents are negative.
\end{proof}

Observe that the class $Q$ of all complex polynomials satisfy:
\begin{enumerate}
    \item $Q$ is a complex algebra.
    \item $p\equiv 1 \in Q$.
    \item $Q$ separates points.
\end{enumerate}
The exercise and the above properties show that the Stone-Weierstrass theorem does not extend to the case of complex valued functions. However, we have Stone-Weierstrass theorem in complex case.

\medskip

\begin{theorem}[Stone-Weieratrass]
Let $X$ be a metric space and $E\subset X$ a compact subset. Let $\mathcal{A}\subset C(E,\mathbb{C})$ satisfies the following properties:
\begin{enumerate}
    \item $\mathcal{A}$ is a complex algebra, i.e., if $f,g\in \mathcal{A}, \alpha\in\mathbb{C}$, then $f+g,fg,\alpha f\in\mathcal{A}$.
    \item The constant function $f(x)\equiv 1$ for $x\in E$ belongs to $\mathcal{A}$.
    \item $\mathcal{A}$ separates points, i.e., for every $x,y\in E, x\neq y$, there exists $f\in\mathcal{A}$ such that $f(x)\neq f(y)$.
    \item $\mathcal{A}$ is self-adjoint, i.e., if $f\in \mathcal{A}$, then $\bar{f}$ defined by $\bar{f}(x) = \overline{f(x)}$ also belongs to $\mathcal{A}$.
\end{enumerate}
Then $\mathcal{A}$ is a dense subset of $C(E,\mathbb{C})$, i.e., $\text{cl}(A) = C(E,\mathbb{C})$, and for every $\varepsilon > 0$, there is a $g_\varepsilon\in\mathcal{A}$ such that
\begin{align*}
    \left|f(x) - g_\varepsilon(x)\right| < \varepsilon
\end{align*}
for all $x\in E$.
\end{theorem}
\begin{proof}
Let $\mathcal{A}_R$ be a subset of $\mathcal{A}$ consisting of functions that are real valued. The class $\mathcal{A}_R$ satisfies the assumptions of the previous version of the Stone-Weieratrass theorem, i.e.,
\begin{enumerate}
    \item $u,v\in\mathcal{A}_R$, $\alpha\in\mathbb{R}$, then $u+v,uv,\alpha u\in\mathcal{A}_R$.
    \item $u\equiv 1 \in \mathcal{A}_R$.
    \item $\mathcal{A}_R$ separates points.
\end{enumerate}
The properties $(1)$ and $(2)$ are obvious, but $(3)$ requires a proof.

If $f\in\mathcal{A}$, then $f = u+iv$, where $u,v$ are continuous real valued functions, Then $u = \frac{1}{2}(f+\bar{f})\in\mathcal{A}$, because $\mathcal{A}$ is self-adjoint. Since the function $u$ is real valued, then $u\in\mathcal{A}_R$. Since $\mathcal{A}$ separates points, then for every $x,y\in E, x\neq y$, there is $g\in\mathcal{A}$ such that $g(x)\neq g(y)$, and hence for some $\alpha, \beta\in\mathbb{C}$, $f = \alpha g+\beta$ satisfies $$f(x) = 1\neq 0 = f(y)$$
Hence $u(x) = 1\neq 0 = u(y)$, so $u\in\mathcal{A}_R$ separates points.

We proved that $\mathcal{A}_R$ satisfies the assumptions of the previous version of the Stone-Weieratrass theorem. If $f = u+iv$, where $u,v\in C(E,\mathbb{R})$ and hence there are functions $u_n,v_n\in \mathcal{A}_R$ such that $u_n\to u, v_n\to v \, \text{in}\,\, C(E,\mathbb{R})$. Thus, 
\begin{align*}
    \mathcal{A}\ni f_n = u_n + iv_n \to u+iv = f\,\, \text{in}\,\, C(E,\mathbb{R})
\end{align*}
because 
\begin{align*}
    \left|f_n - f\right| \leq \left|u_n - v\right| + \left|v_n - v\right| \rightrightarrows 0
\end{align*}
\end{proof}

\medskip

As a consequence of the complex version of Stone-Weieratrass theorem, we have:
\begin{corollary}
Let $\overline{D} = \{z\in \mathbb{C} \,| \left|z\right|\leq 1\}$ be the closed unit disc. Then for every $f\in C(\overline{D}, \mathbb{C})$ and every $\varepsilon > 0$, there is a polynomial 
$$p_\varepsilon(z) = \sum^n_{k,l=0}c_{kl}x^k y^l, c_{kl}\in\mathbb{C}, z = x+iy$$
such that 
$$\left|f(z) - p_\varepsilon(z)\right| < \varepsilon$$
for all $z\in\overline{D}$.
\end{corollary}

\medskip

\section{Banach Space}
A Banach space is a vector space $X$ over any scalar field $K$, which is equipped with a norm ${\|\cdot \|_{X}}$ and which is complete with respect to the distance function induced by the norm, that is to say, for every Cauchy sequence ${x_n}$ in $X$, there exists an element $x$ in $X$ such that 
\begin{align*}
    \lim_{n\to\infty}x_n = x
\end{align*}
or equivalently:
\begin{align*}
    \lim _{n\to \infty }\left\|x_{n} - x\right\|_{X} = 0
\end{align*}

The vector space structure allows one to relate the behavior of Cauchy sequences to that of converging series of vectors. A normed space $X$ is a Banach space if and only if each absolutely convergent series in $X$ converges in $X$, i.e.,
\begin{align*}
    \sum^\infty_{n=0}\left\|x_n\right\|_X < \infty\,\, \text{implies that}\,\, \sum^\infty_{n=0}x_n\,\,\text{converges in}\,\, X
\end{align*}
Every finite-dimensional normed space over $\mathbb{R}$ or $\mathbb{C}$ is a Banach space.

\medskip

\subsection{The Banach Contraction Principle}
\begin{definition}
Let $X$ be a metric space. A contraction of $X$ is a mapping $T:X\to X$ such that $d_X\left(T(x),T(y)\right)\leq kd_X\left(x,y\right)$, for some constant $0<k<1$ and all $x,y\in X$.

In another words, a contraction $T:X\to X$ is a Lipschitz mapping with a Lipschiz mapping with a Lipschiz constant strictly less than $1$.
\end{definition}

\medskip

Now we introduce the Banach Contraction Principle (theorem 9.23 in Rudin's book).
\begin{theorem}[The Banach Contraction Principle]
Suppose $T:X\to X$ is a contraction of a complete metric space $X$. Then there is a unique fixed point of $T$, i.e., a unique point $x^*\in X$ such that $T(x^*) = x^*$. Moreover, for any $x\in X$, we have 
\begin{align*}
    \lim_{n\to\infty} T^n(x) = x^*, \,\,{\rm where}\,\, T^n = \underbrace{T \circ T \circ\cdots\circ T}_{n}
\end{align*}
\end{theorem}
\begin{proof}
Choose $x_0\in X$ and define $x_n = T^n(x_0)$. Then we have
\begin{align*}
    d(x_n,x_{n+1}) = \,& d\left(T(x_{n-1}),T(x_n)\right) \\
    \leq \,& k d\left(x_{n-1},x_n\right) = k d\left(T(x_{n-2}),T(x_{n-1})\right) \\
    \leq \,& k^2 d\left(x_{n-2},x_{n-1}\right) \\
    & \cdots \\
    \leq \,& k^n d\left(x_{0},x_{1}\right)
\end{align*}
i.e., $d(x_n,x_{n+1}) \leq k^n d\left(x_{0},x_{1}\right)$. This inequality implies that $\{x_n\}$ is a Cauchy sequence in $X$. Indeed, let $\varepsilon > 0$ be given, we can find $N$ large enough such that 
\begin{align*}
    \frac{k^N}{1 - k} d\left(x_{0},x_{1}\right) < \varepsilon
\end{align*}
Then for $n > m \geq N$, we have
\begin{align*}
    d(x_m,x_n) &\leq \, d(x_m,x_{m+1}) + d(x_{m+1},x_{m+2}) + \cdots + d(x_{n-1},x_{n})\\
    &\leq \, k^m d(x_{0},x_{1}) + k^{m+1} d(x_{0},x_{1}) + \cdots + k^{n-1}d(x_{0},x_{1})\\
    &= \, k^m(1 + k + k^2 + \cdots + k^{n-m-1})d(x_{0},x_{1})\\
    &\leq \, k^N \left(\sum^\infty_{i=0}k^i\right)d(x_{0},x_{1}) \\
    &= \, \frac{k^N}{1 - k} d\left(x_{0},x_{1}\right) < \varepsilon
\end{align*}
Since $X$ is complete, the sequence $\{x_n\}$ converges to a point $x^*\in X$. We have
\begin{align*}
    d\left(x^*,T(x^*)\right) \leq &\,  d\left(x^*,x_n\right) + d\left(x_n,T(x_n)\right) + d\left(T(x_n),T(x^*)\right) \\
    \leq &\, d\left(x^*,x_n\right) + k^n d\left(x_1,x_0\right) + k d\left(x_n,x^*\right)\\
    = &\, k^n d\left(x_1,x_0\right) + (1+k) d\left(x_n,x^*\right) \xrightarrow[n\to\infty]{} 0
\end{align*}
Thus, $x^*$ is fixed point.

Now we prove the the uniqueness. If $x_1^*, x_2^*\in X$ are two fixed points of $T$, then 
\begin{align*}
    d\left(x_1^*, x_2^*\right) = d\left(T(x_1^*), T(x_2^*)\right) \leq k d(x_1^*, x_2^*)
\end{align*}
Since $0<k<1$, we can know that $d(x_1^*, x_2^*) = 0$, which implies $x_1^* = x_2^*$.
\end{proof}

\medskip

\begin{exercise}
Prove that if $\left|a_{ij}\right| < 1/n$ for $i,j = 1,2,\cdots, n$, then for every $b_1,b_2,\cdots,b_n\in\mathbb{R}$, the system of linear equations 
\begin{equation}\label{equ_4}
    x_i = \sum^n_{j=1}a_{ij}x_j + b_i, i = 1,2,\cdots,n
\end{equation}
has unique solution $x = (x_1,x_2,\cdots,x_n)$.
\end{exercise}
\begin{proof}
Define a mapping $T:\mathbb{R}^n\to\mathbb{R}^n$ by $T(x_1,x_2,\cdots,x_n) = (y_1,y_2,\cdots,y_n)$, where $y_i = \sum^n_{j=1}a_{ij}x_j + b_i$. Clearly, $x = (x_1,x_2,\cdots,x_n)$ is a solution to the system above if and only if $T(x) = x$. Thus, we need to prove that $T$ has a unique fixed point. 

It suffice to prove that $T$ is a contraction. Let $M = \max\{|a_{ij}|,i,j = 1,2,\cdots,n\}$. Then $M < \frac{1}{n}$. Denote $T(x) = y, T(x') = y'$. We have
\begin{align*}
    \left|y_i - y_i'\right| & = \left|\sum^n_{j=1}a_{ij}(x_j - x_j')\right| \\
    & \leq M \sum^n_{j=1}\left|x_j - x_j'\right| \\
    & \leq M \sqrt{n} \|x - x'\|
\end{align*}
where the last step follows from Cauchy-Schwarz inequality, which is 
\begin{align*}
    \sum^n_{j=1}\left|x_j\right| = \sum^n_{j=1}\left|x_j\right|\cdot 1 \leq \left(\sum^n_{j=1}1\right)^{\frac{1}{2}} \left(\sum^n_{j=1}\left|x_j\right|^2\right)^{\frac{1}{2}} = \sqrt{n} \|x\|
\end{align*}

Now we have 
\begin{align*}
    \|T(x) - T(x')\| & = \|y - y'\| \\
    & = \left(\sum^n_{i=1}|y-y'|^2\right)^{\frac{1}{2}} \\
    & \leq \left(\sum^n_{i=1}(M \sqrt{n} \|x - x'\|)^2\right)^{\frac{1}{2}} \\
    & = \underbrace{Mn}_{ =\, k < 1} \|x - x'\|
\end{align*}
Hence the mapping $T:\mathbb{R}^n\to\mathbb{R}^n$ is a contraction and therefore it has a unique fixed point, which is the unique solution to (\ref{equ_4}).
\end{proof}

\medskip

\begin{exercise}
Prove that if $\left|a\right| < 1/2$, then the system of equations
\begin{align*}
    \left\{
    \begin{aligned}
        & x = a(\sin x + \cos y)\\
        & y = a(\cos x + \sin y)
    \end{aligned}
    \right.
\end{align*}
has exactly one solution $(x,y)\in \mathbb{R}^2$.
\end{exercise}
\begin{proof}
Consider the mapping $T:\mathbb{R}^2\to\mathbb{R}^2$ defined as $T(x,y) = \left(a(\sin x + \cos y), a(\cos x + \sin y)\right)$. And it suffices to prove that $T$ is a contraction. We have
\begin{dmath}
    \|T(x_1,y_1) - T(x_2,y_2)\| = |a|\sqrt{(\sin x_1 + \cos y_1 - \sin x_2 - \cos y_2)^2 
    + (\cos x_1 + \sin y_1 - \cos x_2 - \sin y_2)^2}
\end{dmath}
and we denote the right hand side by $M$. We need following elementary inequality 
\begin{align*}
    \left|\sin a - \sin b\right| \leq \left|a - b\right|, \left|\cos a - \cos b\right| \leq \left|a - b\right|
\end{align*}
where the first one follows from the estimate 
\begin{align*}
    \left|\sin a - \sin b\right| = \left|\int^b_a \sin' t \,\text{dt} \right| \leq \int^b_a \left|\cos t \,\text{dt}\right| \leq \left|a - b\right|
\end{align*}
and the second one follows from the similar argument. These inequalities yield 
\begin{align*}
    \left|\sin x_1 + \cos y_1 - \sin x_2 - \cos y_2\right|^2 &\leq \left(\left|\sin x_1 - \sin x_2\right| + \left|\cos y_1 - \cos y_2\right|\right)^2 \\
    &\leq \left(\left|x_1 - x_2\right| + \left|y_1 - y_2\right|\right)^2 \\
    &\leq 2 \left(\left|x_1 - x_2\right|^2 + \left|y_1 - y_2\right|^2 \right)
\end{align*}
Similarly, we have 
\begin{align*}
    \left|\cos x_1 + \sin y_1 - \cos x_2 - \sin y_2\right|^2 \leq 2 \left(\left|x_1 - x_2\right|^2 + \left|y_1 - y_2\right|^2 \right)
\end{align*}
Hence, we have 
\begin{align*}
    M \leq |a| \sqrt{4 \left(\left|x_1 - x_2\right|^2 + \left|y_1 - y_2\right|^2 \right)} = 2|a| \cdot \|(x_1,y_1),(x_2,y_2)\|
\end{align*}
which implies that $T$ is a contraction.
\end{proof}

\begin{exercise}
Let $g:[0,1]\to\mathbb{R}$ be continuous. Prove that there is a unique continuous function $f:[0,1]\to\mathbb{R}$ such that 
\begin{align*}
    f(x) - \int^x_0 f(x - t)e^{-t^2} \text{dt} = g(x), x\in [0,1]
\end{align*}
\end{exercise}
\begin{proof}
Consider the mapping $T:C([0,1],\mathbb{R})\to C([0,1],\mathbb{R})$ defined by 
\begin{align*}
    T(f)(x) = g(x) + \int^x_0 f(x - t)e^{-t^2} \text{dt} = f(x)
\end{align*}
Clearly, $f$ is a solution to the problem if and only if $T(f) = f$. Since the space $C([0,1],\mathbb{R})$ is compact, the existence of unique fixed point of $T$ will follows from the fact that $T$ is a contraction.

Given $f,h\in C([0,1],\mathbb{R})$, we have 
\begin{align*}
    d_\infty \left(T(f), T(h)\right)  & = \sup_{x\in[0,1]} \left|\left(g(x) + \int^x_0 f(x - t)e^{-t^2} \text{dt}\right) -  \left(g(x) + \int^x_0 h(x - t)e^{-t^2} \text{dt}\right)\right| \\
    & \leq \sup_{x\in[0,1]} \int^x_0 \left|f(x-t) - h(x-t)\right|e^{-t^2} \text{dt} \\
    & \leq d_\infty(f,h) \underbrace{\int^1_0 e^{-t^2} \text{dt}}_{=\, k < 1}
\end{align*}
Thus, we proved that $T:C([0,1],\mathbb{R})\to C([0,1],\mathbb{R})$ is a contraction and hence there is a unique $f\in C([0,1],\mathbb{R})$ such that $T(f) = f$.
\end{proof}

\medskip

Now we show how to use the Banach theorem in the proof of one of the most important results in the theory of ordinary differential equations. Consider a continuous function $f(t,x)$ defined in a neighborhood of $(t_0,x_0)\in\mathbb{R}^2$. Assume the following Lipschitz condition: there is a $K > 0$ such that 
$$\left|f(t,x_1) - f(t,x_2)\right| \leq K \left|x_1 - x_2\right|$$
for all $(t,x_1), (t,x_2)$ in a neighborhood of $(t_0,x_0)$.
\begin{theorem}
Under the above assumption, the differential equation 
\begin{equation}\label{equ_5}
    \dv{x}{t} = f(x,t), x(t_0) = x_0
\end{equation}
has unique $C^1$ solution in a neighborhood of $t_0$, i.e., there is a $\delta > 0$ such that there is a unique $C^1$ function $x = \varphi(t)$ defined for $t_0 - \delta < t < t_0 + \delta$ satisfying 
\begin{align*}
    \left\{
    \begin{aligned}
        \dv{\varphi}{t} & = f\left(t,\varphi(t)\right),\, {\rm for}\,\, t_0 - \delta < t < t_0 + \delta\\
        \varphi(t_0) & = x_0
    \end{aligned}
    \right.
\end{align*}
\end{theorem}
\begin{proof}
$x = \varphi(t)$ is a solution to equation (\ref{equ_5}) if and only if 
$$\varphi(t) = x_0 + \int^t_{t_0} f(s,\varphi(s))\, \text{d}s$$
i.e, if $\varphi$ is a fixed point of the following transformation $T$:
\begin{align*}
    T(\varphi)(t) = x_0 + \int^t_{t_0} f(s,\varphi(s))\, \text{d}s.
\end{align*}

There is a neighborhood $\Omega$ of $(x_0,t_0)$ such that $\left|f(t,x)\right|\leq L$ in $\Omega$ and $f$ satisfies the Lipschitz condition. Then we choose $\delta$ small enough such that the closed rectangle with sides $2\delta$ and $2L\delta$ centered at $(t_0,x_0)$ is contained in $\Omega$, i.e., $\left|t - t_0\right| \leq \delta, \left|x - x_0\right| \leq L\delta \Rightarrow (t,x)\in\Omega$. We can also assume that $\delta L < 1$. Consider the following function spaces 
\begin{align*}
    \mathcal{C}& = C\left([t_0 - \delta, t_0 + \delta], \mathbb{R}\right) \\
    \mathcal{M}& = \left\{\varphi\in\mathcal{C} | \varphi(t_0) = x_0, \left|\varphi(t) - x_0\right| \leq L\delta, \right\} \, {\rm for}\,\, t \in [t_0 - \delta, t_0 + \delta]
\end{align*}
Then $\mathcal{M}$ is a closed subset of $\mathcal{C}$ and hence it is a compact metric space with respect to the metric 
\begin{align*}
    d_\infty(\varphi_1, \varphi_2) = \sup_{t_0 - \delta \leq t \leq t_0 + \delta} \left|\varphi_1(t) - \varphi_2(t)\right|
\end{align*}

Define $T:\mathcal{M}\to\mathcal{C}$ by
\begin{align*}
    T(\varphi)(t) = x_0 + \int^t_{t_0} f(s,\varphi(s))\, \text{d}s.
\end{align*}
the this mapping $T$ is well defined because the function $T(\varphi)$ is continuous. Indeed, we have 
\begin{align*}
    \left|T(\varphi)(t_1) - T(\varphi)(t-2)\right| \leq \left|\int^{t_2}_{t_1} f(s,\varphi(s))\, \text{d}s \right| \leq L |t_1 - t_2|
\end{align*}
Clearly, $\varphi$ is a solution of equation (\ref{equ_5}) if and only if it is a fixed point of $T$. Also, the mapping $T$ does not only maps $\mathcal{M}$ to $\mathcal{C}$, but it maps $\mathcal{M}$ to $\mathcal{M}$. Indeed, $T(\varphi)(t_0) = x_0$ and  
\begin{align*}
    \left|T(\varphi)(t) - x_0\right| \leq \int^{t}_{t_0} \left|f(s,\varphi(s))\right|\, \text{d}s \leq \delta L.
\end{align*}

Moreover, $T$ is a contraction of $\mathcal{M}$. Indeed, we have 
\begin{align*}
    d_\infty\left(T(\varphi_1), T(\varphi_2)\right) & = \sup_{t} \left|\int^{t}_{t_0} \left(f(s,\varphi_1(s)) - f(s,\varphi_2(s)\right) \, \text{d}s\right|\\
    & \leq \delta L \sup_{s} \left|\varphi_1(s) - \varphi_2(s) \right| \\
    & = \underbrace{\delta L}_{< 1} \sup_{s} d_\infty(\varphi_1, \varphi_2)
\end{align*}
Thus $T$ has a unique fixed point by the Contraction Principle. The proof is complete.
\end{proof}

\medskip

\subsection{Arzel-Ascoli Theorem}
\begin{definition}
Let $A\subset X$ be a subset of a metric space $(X,d_X)$, and let $(Y,d_Y)$ be another metric space. Let $\mathcal{F}\subset C(A,Y)$ be a family of continuous functions from $A$ to $Y$. We say that the family $\mathcal{F}$ is equiconitnuous if for $\forall\varepsilon > 0$, there exists $\delta > 0$ such that if $\forall f\in\mathcal{F}, \forall x,y\in A$ and $d_X(x,y) < \delta$, then $d_Y(f(x),f(y)) < \varepsilon$.

In particular, every function in $\mathcal{F}$ is uniformly continuous, but equiconitnuity is a stronger condition than the uniform continuity of every function in $\mathcal{F}$, since it requires for every $\varepsilon > 0$, there exists a $\delta > 0$ that works for every $f\in\mathcal{F}$. In another words, equiconitnuity indicates that every function in $\mathcal{F}$ is uniformly continuous in the same way.
\end{definition}

\medskip

\begin{theorem}[Arzel-Ascoli Theorem]
Let $E\subset X$ be compact. Then the set $\mathcal{C}\subset C(E,\mathbb{R}^n)$ is compact if and only if it is bounded, closed and equicontinuous.
\end{theorem}

\medskip

A subset of the Euclidean space is compact if and only if it is bounded and closed, and in general being bounded and closed is a necessary condition for the compactness, but not a sufficient one. Now we consider a corollary and some exercise before we present the proof of Arzel-Ascoli theorem.

\begin{corollary}
Let $E\subset X$ be compact. If $\mathcal{F}\subset C(E,\mathbb{R}^n)$ is bounded and equicontinuous, then every sequence in $\mathcal{F}$ has a uniformly convergent subsequence.
\end{corollary}
\begin{proof}
It suffices to prove that ${\rm cl}(\mathcal{F})$ is compact, i.e., bounded and closed and equicontinuous. Clearly it is bounded and closed. It remains to prove equicontinuity. We have for $\forall\varepsilon > 0$, there exists $\delta > 0$ such that if $\forall f\in\mathcal{F}, \forall x,y\in E$ and $d(x,y) < \delta$, then $\|f(x),f(y)\| < \varepsilon/2$. 

And we want to prove that for $\forall\varepsilon > 0$, there exists $\delta > 0$ such that if $\forall f\in{\rm cl}(\mathcal{F}), \forall x,y\in E$ and $d(x,y) < \delta$, then $\|f(x),f(y)\| < \varepsilon/2$. Let $\varepsilon > 0$ be arbitrary and let $\delta > 0$ be the same as in the first condition. Let $f\in{\rm cl}(\mathcal{F})$ and $x,y\in E$. Then there exists $f_i\in \mathcal{F}$ such that $f_i$ uniformly converges to $f$. Hence, we have
\begin{align*}
    d(x,y) < \delta & \Rightarrow \|f_i(x) - f_i(y)\| < \varepsilon/2 \\
    & \Rightarrow \|f(x) - f(y)\| \leq  \varepsilon/2 < \varepsilon
\end{align*}
since $f_i(x)\to f(x)$ and $f_i(y)\to f(y)$. The proof is complete.
\end{proof}

\medskip

\begin{exercise}
Let $\mathcal{F}\subset C([0,1],\mathbb{R})$ be bounded, closed and equicontinuous. Let $I:\mathcal{F}\to \mathbb{R}$ be defined by 
$$I(f) = \int^1_0 f(x) \, {\rm d}x$$
Prove that there is $f_0\in\mathcal{F}$ at which the value of $I$ is maximized.
\end{exercise}
\begin{proof}
$\mathcal{F}\subset C([0,1],\mathbb{R})$ is continuous, since 
\begin{align*}
    \left|I(f) - I(f_i)\right| \leq \int^1_0 \left|f(x) - f_i(x)\right| \to 0
\end{align*}
if $f_i \to f$ in $C([0,1],\mathbb{R})$, i.e., $f_i$ uniformly converges to $f$. Since $\mathcal{F}$ is compact, $I$ attains maximun in $\mathcal{F}$.
\end{proof}

\medskip

\begin{exercise}
Let the functions $f_n:[a,b]\to\mathbb{R}$ be uniformly bounded and continuous. Define the set 
\begin{align*}
    F_n(x) = \int^x_0 f_n(t)\, {\rm d}t, a\leq x\leq b
\end{align*}
Prove that $F_n$ has a uniformly convergent subsequence.
\end{exercise}
\begin{proof}
It suffices to prove that the family $\mathcal{F} = \{F_n \,|\, n = 1,2,3,\cdots\}$ is bounded and equicontinuous. 

Uniform boundedness of $\{f_n\}$ means that there is a constant $M > 0$ such that $|f_n(t)|\leq M$ for $\forall n > 0$ and all $\forall t\in[a,b]$. Hence we have $|F_n(x)|\leq M|b-a|$ for $\forall x\in[a,b]$. Thus, $d_\infty(F_n, 0)\leq M|b-a|$, which implies that the family $\mathcal{F}$ is contained in the ball centered at the zero function with radius $M|b-a|$, i.e., $\mathcal{F}$ is bounded. 

The family $\mathcal{F}$ is also equicontinuous. Indeed, let $\varepsilon > 0$ be arbitrary. Take $\delta < \varepsilon/M$, if $|x - y| < \delta$, then we have 
\begin{align*}
    \left|F_n(x) - F_n(y)\right| = \left|\int^y_x F_n(t)\, {\rm d}t \right| \leq \delta M < \varepsilon
\end{align*}
Since the family $\mathcal{F}$ is bounded and equicontinuous, it has a uniformly convergent subsequence.
\end{proof}

\medskip

Now we present the proof of Arzel-Ascoli theorem.

\begin{proof}
~\begin{enumerate}
    \item ($\Rightarrow$) Let $\mathcal{F}\subset C(E,\mathbb{R}^n)$ be compact. Obviously $\mathcal{F}$ is bounded and closed. It remains to prove that that $\mathcal{F}$ is equicontinuous. 
    
    Prove by contradiction and suppose $\mathcal{F}$ is not equicontiunous, we have $\exists \varepsilon > 0$, for $\forall \delta > 0$, there exists $f\in\mathcal{F}$ and $x,y\in E$ such that if $d(x,y) < \delta$, then $\|f(x) - f(y)\| \geq \varepsilon$. 
    
    In particular, for $\delta = 1/n$ we can find $f_n\in\mathcal{F}$ and $x_n, y_n\in E$ such that $d(x_n,y_n) < 1/n$ and $\|f_n(x_n) - f_n(y_n)\| \geq \varepsilon$. Since $\mathcal{F}$ is compact, the $\{f_n\}$ has a convergent subsequence $\{f_{n_k}\}$ uniformly converging to $f$. Since $E$ is also compact, the function $f$ is uniformly continuous on $E$. Then we have 
    \begin{align*}
        \varepsilon & \leq \|f_{n_k}\left(x_{n_k}\right) - f_{n_k}\left(y_{n_k}\right)\| \\
        & \leq \underbrace{\|f_{n_k}\left(x_{n_k}\right) - f\left(y_{n_k}\right)\|}_{\longrightarrow 0, \,f_{n_k}\rightrightarrows f} + \underbrace{\|f\left(x_{n_k}\right) - f\left(y_{n_k}\right)\|}_{\longrightarrow 0,\, d(x_{n_k},y_{n_k})\to 0} + \underbrace{\|f\left(y_{n_k}\right) - f_{n_k}\left(y_{n_k}\right)\|}_{\longrightarrow 0, \,f_{n_k}\rightrightarrows f} \\
        & \to 0
    \end{align*}
    which is contradicted with the assumption above.
    \item ($\Leftarrow$) Suppose now that $\mathcal{F}\subset C(E,\mathbb{R}^n)$ is bounded, closed and equicontinuous. It suffices to prove that $\mathcal{F}$ is compact. 
    
    Let $f_n\in\mathcal{F}$. We want to prove that $f_n$ has a subsequence that is uniformly convergent. Since $E$ is compact, it has a countable dense subset 
    $$\{x_1, x_2, x_3,\cdots \}\subset E$$
    The sequence $\{f_n(x_1)\}$ is bounded in $\mathbb{R}$, so it has a convergent subsequence. Denote this subsequence by 
    \begin{align*}
        f_{11}(x_1), f_{12}(x_1), f_{13}(x_1), \cdots 
    \end{align*}
    which converges in $\mathbb{R}^n$. Now the sequence $\{f_{1n}(x_2)\}$ is bounded in $\mathbb{R}^n$, so it has a convergent subsequence, denoted by 
    \begin{align*}
        f_{21}(x_2), f_{22}(x_2), f_{23}(x_2), \cdots 
    \end{align*}
    which converges in $\mathbb{R}^n$. Now the sequence $\{f_{2n}(x_3)\}$ is bounded in $\mathbb{R}^n$, so it has a convergent subsequence, denoted by
    \begin{align*}
        f_{31}(x_3), f_{32}(x_3)& , f_{33}(x_3), \cdots \\
        & \vdots
    \end{align*}
    
    Continue this process and we can have
    \begin{align*}
        & f_{11}, f_{12}, f_{13}, f_{14} \cdots \\
        & f_{21}, f_{22}, f_{23}, f_{24}\cdots \\
        & f_{31}, f_{32}, f_{33}, f_{34}\cdots \\
        & f_{41}, f_{42}, f_{43}, f_{44}\cdots \\
        & \cdots
    \end{align*}
    where sequence in each line is a subsequence of the previous line. We select a subsequence along the diagonal  $\{f_{11}, f_{22}, f_{33},\cdots\}$. We claim that the sequence $\{f_{nn}(x_k)\}$ is convergent for every $k = 1,2,3,\cdots$. Indeed, the sequence 
    \begin{align*}
        f_{11}(x_k), f_{22}(x_k), f_{33}(x_k),\cdots
    \end{align*}
    is a subsequence of the convergent sequence $f_{k1}(x_k), f_{k2}(x_k), f_{k3}(x_k),\cdots$ starting from $n = k$. 
    
    The method described above of selecting the subsequence $\{f_{nn}\}$ is called the diagonal method. Hence the sequence of functions $f_{nn}$ is convergent at every point of a dense subset $\{x_1, x_2, x_3,\cdots\}$ of $E$. We will prove that the sequence $\{f_{nn}\}$ is actually convergent of $E$ and this is an uniform convergence, 
    
    Let $\varepsilon > 0$ be arbitrary. Take $\delta > 0$ as in the definition of equicontinuity. Then there is $k$ such that for $\forall x\in X$ and $\exists i \in \{1,2,\cdots, k\}$, $d(x,x_i) < \delta$, because of the density of $\{x_1, x_2, \cdots \}$ in $E$. Since the sequence $\{f_{nn}(x_i)\}$ is convergent for $i = 1,2,\cdots,k$, then there is $N > 0$ such that for every $n,m \geq N$, we have
    \begin{align*}
        \|f_{nn}(x_i) - f_{mm}(x_i)\| < \varepsilon, i = 1,2,\cdots,k
    \end{align*}
    Now we have
    \begin{align*}
        \|f_{nn}(x) - f_{mm}(x)\| \, \leq\, & \|f_{nn}(x) - f_{nn}(x_i)\| + \|f_{nn}(x_i) - f_{mm}(x_i)\| \\
        + & \|f_{nn}(x_i) - f_{mm}(x)\| < 3\varepsilon
    \end{align*}
    Hence $\{f_{nn}(x)\}$ is convergent as a Cauchy sequence, and we denote the limit by 
    $$f(x) = \lim_{n\to\infty}f_{nn}(x)$$
    
    For $n, m \geq N$, we have 
    \begin{align*}
        \|f_{nn}(x) - \underbrace{f_{mm}(x)}_{\to f(x)} \| < 3\varepsilon
    \end{align*}
    which yields that for $n \geq N$, $\|f_{nn}(x) - f(x) \|\leq 3\varepsilon$ and this proves that $f_{nn}$ uniformly converges to $f$. The proof is complete.
\end{enumerate} 
\end{proof}

\medskip

\begin{exercise}
Let $\{f_n\}^\infty_{n=1}, f_n:\mathbb{R}\to\mathbb{R}$ be a sequence of continuous functions such that:
\begin{enumerate}
    \item $f_n(0) = 0$.
    \item $|f_{n}'(x)|\leq e^{x^2}$ for all $x\in\mathbb{R}$.
\end{enumerate}
Prove that a subsequence of $\{f_n\}$ converges to a continuous function.
\end{exercise}
\begin{proof}
Since $f$ is continuous, then for $\forall M \in\mathbb{N}$, $\{f_n |\, x\in [-M,M]\}^\infty_{n = 1}$ is bounded and equicontinuous. Then we have $-e^{M^2} \leq f_n'(x) \leq e^{M^2}$. And we have
\begin{align*}
    \left|f_n(x)\right| & = \left|f_n(x) - f_n(0)\right| = \left|f_n'(\xi) x\right| \leq e^{M^2}M
\end{align*}
which implies $f_n(x)$ is bounded. Also, 
\begin{align*}
    \left|f_n(x) - f_n(y)\right| = \left|f_n'(\xi)(y - x)\right| \leq e^{M^2}|y - x|
\end{align*}
Since $f_n(x)$ is bounded, then $\{f_n|x\in [-1,1]\}$ has uniformly convergent subsequence $\{f_{1n}\}$. The sequence $\{f_{1n}|x\in [-2,2]\}$ has uniformly convergent subsequence $\{f_{2n}\}$. And the sequence $\{f_{2n}|x\in [-3,3]\}$ has uniformly convergent subsequence $\{f_{3n}\}$. We can continue this process and get a sequence $\{f_{nn}\}$ which is uniformly convergent on every interval $[-M, M]$.
\end{proof}








\end{document}
