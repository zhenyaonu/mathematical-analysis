\documentclass[12pt,leqno]{amsart}
\pagestyle{plain}
\usepackage{latexsym,amsmath,amssymb}
%\usepackage[notref,notcite]{showkeys}
\usepackage{amsfonts}
\usepackage{geometry}
\usepackage{graphicx}
\graphicspath{ {images/} }

\setlength{\oddsidemargin}{1pt}
\setlength{\evensidemargin}{1pt}
\setlength{\marginparwidth}{30pt} % these gain 53pt width
\setlength{\topmargin}{1pt}       % gains 26pt height
\setlength{\headheight}{1pt}      % gains 11pt height
\setlength{\headsep}{1pt}         % gains 24pt height
%\setlength{\footheight}{12 pt} 	  % cannot be changed as number must fit
\setlength{\footskip}{24pt}       % gains 6pt height
\setlength{\textheight}{650pt}    % 528 + 26 + 11 + 24 + 6 + 55 for luck
\setlength{\textwidth}{460pt}     % 360 + 53 + 47 for luck



\def\dsp{\def\baselinestretch{1.35}\large
\normalsize}
%%%%This makes a double spacing. Use this with 11pt style. If you
%%%%want to use this just insert \dsp after the \begin{document}
%%%%The correct baselinestretch for double spacing is 1.37. However
%%%%you can use different parameter.


\def\U{{\mathcal U}}

\begin{document}

\centerline{\bf Homework 6 for Math 1530}
\centerline{Zhen Yao}



\bigskip


\noindent
{\bf Problem 55.}
Prove that the two series
$$
\sum_{n=0}^\infty c_n x^n
\quad
\text{and}
\quad
\sum_{n=0}^\infty n(\log n)c_n x^{n+3}
$$
have the same radius of convergence.
\begin{proof}
The radius of convergence for series $\sum_{n=0}^\infty c_n x^n$ is $R_1 = \limsup_{n\to\infty}\sqrt[n]{|c_n|}$, and the radius for the second series is 
\begin{align*}
    R_2 &= \limsup_{n\to\infty}\sqrt[n]{|n(\log n)c_n|}\\
    &= \limsup_{n\to\infty}\sqrt[n]{|n(\log n)|} \sqrt[n]{|c_n|} \\
    &= \limsup_{n\to\infty}\sqrt[n]{|c_n|} = R_1
\end{align*}
The proof is complete.
\end{proof}

\medskip


\noindent
{\bf Problem 56.}
Let $f:(-\infty,\infty)\rightarrow\mathbb R$ be continuous and $\lim\limits_{x\rightarrow\infty}f(f(x))=\infty$.
Prove that $\displaystyle \lim\limits_{x\rightarrow\infty}|f(x)|=\infty$.
\begin{proof}
Suppose $\lim_{x\to\infty}f(x) = a<\infty$ which is finite. This means that for $\forall \varepsilon>0$, there exists $\delta >0$, such that $\forall x>\delta$, $|f(x)-a|<\varepsilon$. W e can pick a sequence $\{x_k\}$ such that $\lim_{k\to\infty}x_k=a$, since $f$ is continuous, then we have $\lim_{k\to\infty}f(x_k)=f(a)$. \\
\hspace*{3em}Also, we can pick a sequence $\{y_k\}\rightarrow \infty$ such that $f(y_k)=x_k$. Then we have $f(f(y_k))\rightarrow f(a)\neq \infty$, which is a contradiction.
\end{proof}

\medskip


\noindent
{\bf Problem 57.}
Let $f:[0,1)\to\mathbb{R}$ be a function that is not necessarily continuous. Define
$$
g(\delta)=\sup\{|f(y)-f(y')|:y,y'\in (1-\delta,1)\}.
$$
Prove that $\displaystyle\lim_{x\to 1^-} f(x)$ exists and is finite if and only if $\displaystyle\lim_{\delta\to 0^+}g(\delta)=0$.
\begin{proof}
(1)If $\lim_{\delta\to 0^+}g(\delta)=0$, then for $\forall \varepsilon>0$, there exists $\delta_0$, such that $\forall \delta<\delta_0$, $|f(y)-f(y')|\leq g(\delta)<\varepsilon$, where $|y-y'|<\delta$. Thus, by definition, $f$ is uniformly continuous on $(1-\delta,1)$. Then, we define $$\lim_{x\to 1^-}f(x)=\lim_{n\to\infty}f\left(1-\frac{1}{n}\right)=A$$
We can pick a sequence $\{x_k\}\rightarrow 1$, then for $\delta<\delta_0$ above, we can find $K$ and $N_1$ such that for $\forall n>N_1, \forall k > K$, $|x_k-(1-\frac{1}{n})|<\delta$. Also, we can find $N_2$ such that $\forall n>N_2$, $|f(1-1/n)-A|<\varepsilon$. Thus, for $\forall n>\max\{N_1,N_2\}, \forall k > K$, we have
\begin{align*}
    |f(x_k)-A|<\left|f(x_k)-f\left(1-\frac{1}{n}\right)\right|+\left|f\left(1-\frac{1}{n}\right)-A\right|<2\varepsilon
\end{align*}
Thus, $\lim_{x\to 1^-}f(x)$ exists and is finite. \\
\hspace*{3em}(2)Suppose $\lim_{x\to 1^-}f(x)=A$ exists and is finite, and we can pick a sequence $\{x_k\}\rightarrow 1$ such that $\lim_{k\to\infty}f(x_k)=A$. Then for $\forall \varepsilon >0$, there exist $\delta_1$, such that $|x_k-1|<\delta_1$, $|f(x_k)-A|<\varepsilon$. For this $\delta_1$, we could find $x_{k_1}$ and $x_{k_2}$ satisfying $x_{k_1}, x_{k_2}\in(1-\delta_1,1)$. Then we have 
\begin{align*}
    g(\delta_1) = \sup \{|f(x_{k_1})-f(x_{k_2})|;x_{k_1},x_{k_1}\in (1-\delta_1,1)\} 
\end{align*}
and we have 
\begin{align*}
    |f(x_{k_1})-f(x_{k_2})| < |f(x_{k_1})-A|+|A-f(x_{k_2})| < 2\varepsilon
\end{align*}
and this holds for all $\varepsilon$ and all $x_{k_1}, x_{k_2}\in (1-\delta_1,1)$, then we have $\lim_{\delta\to 0^+}g(\delta_1)=0$.
\end{proof}

\medskip




\noindent
{\bf Problem 58.}
Prove that if $f:\mathbb{R}\to\mathbb{R}$ is $\alpha$-H\"{o}lder continuous with some $\alpha>1$, then $f$ is constant.
\begin{proof}
For fixed $x$ and $x<y$, and we divide $y-x$ into $n$ small intervals, and denote $x_0=x, x_1=x+\frac{y-x}{n},\cdots, x_{n}=x+n\frac{y-x}{n}=y$. And we have 
\begin{align*}
    |f(y)-f(x)| &\leq \sum^{n}_{i=1}|f(x_{i+1})-f(x_i)|\leq C \sum^{n}_{i=1} |x_{i+1}-x_i|^\alpha \\
    & \leq c n \left(\frac{y-x}{n}\right)^\alpha = c \frac{(y-x)^\alpha}{n^{\alpha-1}}
\end{align*}
Taking $n\to\infty$, and we have $|f(y)-f(x)|\leq \lim_{n\to\infty}c \frac{(y-x)^\alpha}{n^{\alpha-1}} =0$, since $\alpha>1$. Thus, $f$ is constant.
\end{proof}

\medskip

\noindent
{\bf Problem 59.}
Let $f:(1,\infty)\to\mathbb{R}$ be differentiable. Prove that if
$$
\lim_{x\to\infty} f'(x) = g,\text{ then }\lim_{x\to\infty }\frac{f(x)}{x} = g.
$$
\begin{proof}
Since $\lim_{x\to\infty} f'(x) = g$, then for $\forall \varepsilon >0$, there exists $M>0$, such that $\forall x>M$, $|f'(x)-g |<\varepsilon$, which means, for fixed $x_0\in(1,\infty)$, we have
\begin{align*}
    &\lim_{x\to\infty}\frac{f(x)-f(x_0)}{x-x_0}=g \\
    \Rightarrow & \lim_{x\to\infty} f(x)-f(x_0)=g x-gx_0 \\
    \Rightarrow & \lim_{x\to\infty} \frac{f(x)}{x}=g+\frac{f(x_0)}{x}-\frac{f(x_0)}{gx}
\end{align*}
Taking $x\to\infty$, then we have $\lim_{x\to\infty }\frac{f(x)}{x} = g$.
\end{proof}

\medskip

\noindent
{\bf Problem 60.}
Let $f:\mathbb{R}\to\mathbb{R}$ be differentiable and such that
$$
\lim_{x\to \infty} f(x)=g_1\in\mathbb{R},
\qquad
\lim_{x\to\infty} f'(x) = g_2.
$$
Prove that $g_2=0$.
\begin{proof}
Since $\lim_{x\to \infty} f(x)=g_1$, then for $\forall \varepsilon >0$, there exists $M>0$, such that $\forall x>M$, $|f(x)-g_1|<\varepsilon$. And for any number $M<x_1<x_2$, we have
\begin{align*}
    f(x_2)-f(x_1) = f'(\xi)(x_2-x_1)
\end{align*}
where $\xi\in(x_1,x_2)$. Then we have 
\begin{align*}
    f'(\xi) &=\frac{f(x_2)-f(x_1)}{x_2-x_1} \\
    & \leq \left|\frac{f(x_2)-g-(f(x_1)-g)}{x_2-x_1}  \right| \\
    & \leq \frac{\left|f(x_2)-g\right|}{x_2-x_1} + \frac{\left|f(x_1)-g\right|}{x_2-x_1} \\
    & \leq \frac{2\varepsilon}{x_2-x_1}
\end{align*}
We can set $x_2-x_1=N$ to be fixed and take $x_1,x_2\rightarrow \infty$, we can have $f'(\xi)=0$.
\end{proof}

\medskip


\noindent
{\bf Problem 61.}
Suppose that a differentiable function $f:\mathbb{R}\to\mathbb{R}$ and its derivative $f'$ have no common zeros. Prove that $f$ has only finitely many zeros in $[0,1]$.
\begin{proof}
Set $Z=\{x\in[0,1];f(x)=0\}$ and suppose that $Z$ has infinitely many elements. Since there are infinitely many points in $[0,1]$, then there exists a point $p$ such that $x_k\rightarrow p, x_k\in Z$. Since $f$ is differential on $[0,1]$, then $f$ is continuous in this interval. Thus, we have $f(p)=\lim_{k\to\infty}f(x_k)=0$. Also, we have $f'(p)=\lim_{x_k\to\ p}\frac{f(x_k)-f(p)}{x_k-p}=0$, which is a contradiction.
\end{proof}

\medskip


\noindent
{\bf Problem 62.}
Suppose that $f:[0,\infty)\to\mathbb{R}$ is continuous on $[0,\infty)$ and differentiable on $(0,\infty)$, $f(0)=0$, and $\displaystyle\lim_{x\to\infty} f(x)=0$. Prove that there exists $c\in\mathbb{R}$ such that $f'(c)=0$.
\begin{proof}
Since $\lim_{x\to\infty}f(x)=0$, then $\forall \varepsilon>0$, there exists $M>0$, such that $\forall x>M$, $|f(x)|<\varepsilon$. With mean value theorem, we have $c\in(0,x)$ such that $f(c)=\frac{f(x)-f(0)}{x}<\varepsilon$. This holds for every $\varepsilon$, then we know there exists a $c$ such that $f(c)=0$.
\end{proof}

\medskip



\noindent
{\bf Problem 63.}
Let $f:[0,1]\to\mathbb{R}$ be continuous on $[0,1]$ and differentiable on $(0,1)$. Suppose that $f(0)<0<f(1)$ and $f'(x)\neq 0$ for all $x\in (0,1)$. Let
$S_1=\{x\in [0,1]:\,f(x)>0\}$ and $S_2=\{x\in [0,1]:\,   f(x)<0\}$. Prove that $\inf(S_1)=\sup(S_2)$.
\begin{proof}
Since $f(0)<0<f(1)$ and $f$ is continuous, then there exists a $c\in(0,1)$ such that $f(c)=0$. Now consider the interval $[0,c)$, we claim that $f$ is increasing in this interval. If not, then there exists a $x_1\in(0,c)$ such that $f(x_1)<f(0)<0$. Also, since $f$ is continuous, then there exists a $x_2\in(x_2,c)$ such that $f(x_2)=f(0)$. With Rolle Theorem, we can know that there must be a $\xi\in(0,x_2)\subset (0,c)$ such that $f'(\xi)=0$, which contradicts the fact that $f'(x)\neq 0, \forall x\in(0,1)$. Similarly, we can know that $f$ is increasing on interval $(c,1)$. Since $f$ is continuous, then $f$ is increasing on $[0,1]$. \\
\hspace*{3em}We have know that $f(c)=0, c\in(0,1)$. We claim that $c=\inf (S_1)$ and $c=\sup (S_2)$. First, we consider $x\in S_1$ such that $f(x)>0$, with $f$ being continuous and increasing, we can know that $c<\forall x\in S_1$. Then, $c$ is a lower bound of $S_1$. Also, we can find a sequence $\{x_k\}\rightarrow c$ where $x_k\in S_1$. For $\forall \varepsilon>0$, then there exists a $K>0$, such that $k>K$, $x_k<0+\varepsilon$ and $0<f(x_k)<f(\varepsilon)$. Then we proved that $c$ is a greatest lower bound of $S_1$. Similarly, we can know $c$ is also a least upper bound of $S_2$. Thus, $\inf(S_1)=\sup(S_2)$.
\end{proof}

\medskip


\noindent
{\bf Problem 64.}
Let $f:[0,\infty)\to\mathbb{R}$ be a differentiable function on $[0,\infty)$ such that $f(0)>0$ and
$$
f'(x)=\frac{1}{x^2+(f(x))^2}
\quad
\text{for all $x\in [0,\infty)$.}
$$
Prove that $\lim_{x\to\infty} f(x)$ exists and is finite.
\begin{proof}
Suppose $\lim_{\x\to\infty}f(x)$ exists and is not finite, then $\lim_{\x\to\infty}f(x)=\infty$. Also, with $f(0)>0$, we have $f'(0)=\frac{1}{f^2(0)}>0$, which means $f>0$ in a small interval $[0,\delta)$. Then we can know that $f$ is increasing in $[0,\infty)$. Also, we have 
\begin{align*}
    \lim_{x\to\infty}f'(x)=\lim_{x\to\infty}\frac{1}{x^2+f^2(x)}=0
\end{align*}
Since $\lim_{x\to\infty}f'(x)=0$, then $f$ cannot go to infinity as $x\rightarrow \infty$.
\end{proof}

\medskip


\noindent
{\bf Problem 65.}
Prove that for $x\in\mathbb{R}$
$$
\cos x\geq 1-\frac{x^2}{2}.
$$
\begin{proof}
Define $f(x)=\cos x-1+\frac{x^2}{2}$, then we have $f'(x)=-\sin x+x$. Then $f''(x)=-\cos x +1\geq 0$, which means that $f'(x)$ is increasing. Also we have $f'(0)=0$. Then we can know that $f(x)$ is decreasing on $(-\infty,0]$ and increasing on $(0,\infty)$. Thus, $\inf f(x)=f(0)=0$, which implies $\cos x-1+\frac{x^2}{2}\geq 0 \Rightarrow \cos x\geq 1-\frac{x^2}{2}$.
\end{proof}

\medskip


\noindent
{\bf Problem 66.}
Prove that for $x\in [0,1]$ and $p>1$ the following inequality is satisfied
$$
\frac{1}{2^{p-1}}\leq x^p + (1-x)^p\leq 1.
$$
\begin{proof}
Since $x\in[0,1]$ and $p>1$, then we have $x^p\leq x$ and $(1-x)^p\leq (1-x)$, then we have $x^p + (1-x)^p\leq 1$. On the other hand, we define $f(x)=x^p + (1-x)^p$. Then, $f'(x)=p[x^{p-1}-(1-x)^{p-1}]$, and $f'(x)$ is increasing on $[0,1]$ with $f'(1/2)=0$. Then $f$ is decreasing on $[0,1/2]$ and increasing on $(1/2,1]$, which means $\min f(x)=f(1/2)=1/2^{p-1}$. Thus, we have $\frac{1}{2^{p-1}}\leq x^p + (1-x)^p\leq 1$.
\end{proof}

\medskip


\noindent
{\bf Problem 67.}
Let $W(x)$ be a polynomial such that $W(x)\geq 0$ for $x\in\mathbb{R}$. Prove that
$$
u(x) = W(x) + W'(x) + W''(x)+\ldots\geq 0.
$$
\begin{proof}
Since $u(x)=W(x) + W'(x) + W''(x)+ \cdots +W^{(n)}(x) + \cdots$. Then we have
\begin{align*}
    u'(x) = W'(x) + W''(x)+ \cdots +W^{(n)}(x) + \cdots
\end{align*}
Then we have 
\begin{align*}
    u(x)=W(x)+u'(x)
\end{align*}
And $u(x)$ will obtains its minimum at some point $c$ such that $u'(c)=0$, then we have 
\begin{align*}
    u(x)\geq u(c)=W(c)+u'(c)\geq 0
\end{align*}
The proof is complete.
\end{proof}

\medskip

\noindent
{\bf Problem 68.}
Prove that the polynomial
$$
W_n(x) = 1+\frac{x}{1!} + \frac{x^2}{2!} + \cdots + \frac{x^n}{n!}.
$$
has no multiple roots.
\begin{proof}
We have $W_n'(x)=1+\frac{x^2}{2!}+\cdots+\frac{x^{n-1}}{(n-1)!}$, and then we get $W_n'(x)=W_n(x)-\frac{x^n}{n!}$. If $r$ is a root of $W_n(x)$, then we have $W_n'(r)=0$, and it follows 
\begin{align*}
    W_n'(r) & =W_n(r)-\frac{r^n}{n!} = 0\\
    \Rightarrow \frac{r^n}{n!} & = 0
\end{align*}
so we have $r$ must be $0$. Also, we can know that $W_n(0)=1\neq 0$, then we know $W_n(x)$ has no multiple roots.
\end{proof}

\medskip

\noindent
{\bf Problem 69.}
Suppose that $f\in C^\infty(\mathbb{R})$ and $f(a)=0$. Prove that there is $g\in C^\infty(\mathbb{R})$ such that $f(x)=(x-a)g(x)$ for all $x\in\mathbb{R}$.
\begin{proof}
Since $f(x)\in C^\infty(\mathbb{R})$, we can know that $f(x)$ can be expressed as polynomial, with $f(a) = 0$
\begin{align*}
    f(x) & = f(a) + f'(a)(x-a) + \frac{f''(a)}{2}(x-a)^2 + \frac{f'''(a)}{3!}(x-a)^3 + \cdots \\
    & = (x-a)\sum^\infty_{n=2}\frac{f^{(n)}(a)}{n!}(x-a)^{n-1}
\end{align*}
Then we can define $g(x) = \sum^\infty_{n=2}\frac{f^{(n)}(a)}{n!}(x-a)^{n-1}$ and it is easy to see that $g(x)\in C^\infty(\mathbb{R})$.
\end{proof}

\medskip

\noindent
{\bf Problem 70.}
Let $f(x)=e^{-1/x^2}$ for $x\neq 0$ and $f(0)=0$. Prove that $f\in C^\infty(\mathbb{R})$ and $f^{(n)}(0)=0$ for all $n=0,1,2,\ldots$\\
{\bf Hint:} {\em Use induction to prove that $f$ is $n$-times differentiable, $f^{(n)}(0)=0$ and $f^{(n)}(x)=W_n(1/x)e^{-1/x^2}$ for $x\neq 0$, where $W_n$ is a polynomial.}

\noindent
{\bf Remark.}
This is a very important example. Since all derivatives at $0$ are equal zero, Maclaurin's series of $f$ equals zero. However, $f(x)>0$ for $x\neq 0$ so it is not equal to the Maclaurin series at any point except $x=0$. Another reason why this is so important is that it allows to construct compactly supported smooth functions, see Problem~71.
\begin{proof}
First, we have $f'(x) = 2\left(\frac{1}{x}\right)^3 e^{-1/x^2}, x \neq 0$. Then $f'(x) = W_1(1/x)e^{-1/x^2}$ with $W_1(1/x) = 2\left(\frac{1}{x}\right)^3$ being a polynomial of $1/x$. Suppose that for $k>1$, $f^{(k)}(x) = W_k(1/x) e^{-1/x^2}$, we need to prove that $f^{(k+1)}(x)$ still has the form of $W_{k+1}(1/x)e^{-1/x^2}$. We can know 
\begin{align*}
    f^{(k+1)}(x) & = (f^{(k)}(x))' \\
    & = -\left(\frac{1}{x}\right)^2 W_k'(1/x)e^{-1/x^2} + 2\left(\frac{1}{x}\right)^3 W_k(1/x) e^{-1/x^2} \\
    & = \left(-\left(\frac{1}{x}\right)^2 W_k'(1/x) + 2\left(\frac{1}{x}\right)^3 W_k(1/x) \right)e^{-1/x^2} 
\end{align*}
Since the derivative of polynomial is still a polynomial, then we can know $f^{(k+1)}(x)$ is indeed of form of $W_{k+1}(1/x)e^{-1/x^2}$ with
\begin{align*}
    W_{k+1}(1/x) = \left(-\left(1/x\right)^2 W_k'(1/x) + 2\left(1/x\right)^3 W_k(1/x) \right)
\end{align*}
Then, we concluded that $f(x)\in C^\infty(\mathbb{R}\setminus \{0\})$.\\
\hspace*{3em}Second, we prove the derivative of $f(x)$ at point $0$ exists, we have 
\begin{align*}
    f'(0)=\lim_{x\rightarrow 0}\frac{e^{-\frac{1}{x^2}}-0}{x-0} = \lim_{x\rightarrow 0}\frac{1}{x e^{1/x^2}} = \lim_{t\to\infty}\frac{t}{e^{t^2}} = \lim_{t\to\infty}\frac{1}{2te^{t^2}} = 0
\end{align*}
Then $f(x)$ is differential at point $x=0$, thus, $f\in C^1(\mathbb{R})$. Then, we assume that $f^{(K)}(0) = 0$, and we want to prove that $f^{(k+1)}(x) = 0$. By definition of derivative, we have 
\begin{align*}
    f^{(K+1)}(0) & = \lim_{x\to 0}\frac{f^{(K)}(x) - f^{(K)}(0)}{x - 0}\\
    & = \lim_{x\to 0}\frac{f^{(K)}(x)}{x} \\
    & = \lim_{x\to 0}\frac{W_K(1/x)e^{-1/x^2}}{x} \\
    & = \lim_{x\to 0}\frac{\left(W_K(1/x)e^{-1/x^2}\right)'}{1} \\
    & = \lim_{x\to 0} - \frac{1}{x^2}W_K'(1/x)e^{-1/x^2} + \frac{2}{x^4} W_K(1/x)e^{-1/x^2} \\
    & = \lim_{x\to 0} - \frac{W_K'(1/x)}{x^2 e^{1/x^2}} + \frac{2 W_K(1/x)}{x^4 e^{1/x^2}} \\
    & = 0
\end{align*}
In the last step, we could use L'Hospital's rule to determine the limit, and in limit steps, saying there exists $k_1$ and $k_2$ such that $(W_K'(1/x))^{(k_1)}$ and $(W_K(1/x))^{(k_2)}$ are constants, while the denominator always has the term $e^{1/x^2}$, and we already know that $\lim_{x\to 0}e^{1/x^2} = \infty$. Thus, we can know that $f^{(K+1)}(0) = 0$. \\
\hspace*{3em}
\end{proof}

\medskip

\noindent
{\bf Problem 71.}
Use the function from Problem~70 to construct $f\in C^\infty(a,b)$ such that $f(x)=0$ for $x\in\mathbb{R}\setminus (a,b)$.
\begin{proof}
Set the function in Problem 63 as $g(x):[0,1]\rightarrow \mathbb{R}$, then $g$ is continuous on $[0,1]$ and differentiable on $(0,1)$. Also, $g(0)<0<g(1)$ and $g'(x)\neq 0, \forall x\in(0,1)$.\\
\hspace*{3em}Now consider $f(x)=g\left(\frac{x-a}{b-a}\right), x\in [a,b]$ and $f(x)=0, x\in \mathbb{R}\setminus [a,b]$. And for $f(x)$, using Taylor Theorem, we have 
\begin{align*}
    f(x) & = \sum^\infty_{k=0}\frac{f^{(k)}(0)}{k!}x^k \\
    & = \sum^\infty_{k=0}\frac{g^{(k)}(0)}{k!}\left(\frac{x-a}{b-a}\right)^k 
\end{align*}
Then, we define $f(x)=\sum^\infty_{k=0}\frac{g^{(k)}(0)}{k!}\left(\frac{x-a}{b-a}\right)^k $, and $f\inC^\infty(a,b)$ and $f(x)=0$ for $x\in\mathbb{R}\setminus (a,b)$.
\end{proof}

\medskip



\noindent
{\bf Problem 72.}
Let $n\geq 3$. Consider an $n$-times continuously differentiable function $f\in C^n(\mathbb{R})$ such that
$f^{(k)}(0)=0$,  for $k=2,3,\dots,n-1$ and $f^{(n)}(0)\neq 0$.
Clearly, by the mean value theorem for any $h>0$ there is $0<\theta(h)<h$ such that
$$
f(h)-f(0)=hf'(\theta(h)).
$$
Prove that
$$
\lim_{h\to 0}\frac{\theta(h)}{h}=\left(\frac{1}{n}\right)^{\frac{1}{n-1}}\, .
$$
{\bf Hint:}  Expand $f$ and $f'$ using Taylor's formula.
\begin{proof}
With Taylor Theorem, we have
\begin{align*}
    f(h) & = f(0) + f'(0)h + \frac{f''(0)}{2!}h^2 + \cdots + \frac{f^{(n)}(0)}{n!}h^n + h-[^{n+1}\psi(h)] \\
    f'(\theta) & = f'(0) + f''(0)h + \frac{f^{(3)}(0)}{2!}h^2 + \cdots + \frac{f^{(n)}(0)}{(n-1)!}\theta^{n-1}
\end{align*}
With $f(h)-f(0)=hf'(\theta(h))$, $f^{(k)}(0)=0,k=2,3,\dots,n-1$ and $f^{(n)}(0)\neq 0$, we have 
\begin{align*}
    f(h) - f(0) = \left(f'(0)+\frac{f^{(n)}(0)}{(n-1)!}\right)h^n = &  h \left(f'(0)+\frac{f^{(n)}(0)}{(n-1)!}\theta^{n-1}\right) \\
    \Rightarrow \frac{h^{n-1}}{n!} = \frac{\theta^{n-1}}{(n-1)!} & \\
    \Rightarrow \left(\frac{\theta}{h} \right)^{n-1} = \frac{1}{n}
\end{align*}
Thus we have $\lim \theta/h = \left(1/n\right)^{\frac{1}{n-1}}$.
\begin{align*}
    
\end{align*}
\end{proof}

\medskip

\end{document}
