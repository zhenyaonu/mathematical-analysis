\documentclass[11pt]{article}
\pagestyle{plain}
%\documentclass{article}
%\usepackage[utf8]{inputenc}
%\usepackage[english]{babel}

\usepackage{latexsym,amsmath,amssymb}
\usepackage{amsthm}
%\usepackage[notref,notcite]{showkeys}
\usepackage{amsfonts}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{lmodern}
\usepackage{pifont}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{thmtools}
\usepackage{wrapfig}
\usepackage{extarrows}
\usepackage{breqn}
\usepackage{physics}
\usepackage{afterpage}
\usepackage{enumitem}
\usepackage[utf8]{inputenc}
\usepackage{mathrsfs}
\usepackage{scalerel}
\usepackage{stackengine,wasysym}
\usepackage{aligned-overset}
\usepackage{stackengine}
\usepackage{mathtools}
\usepackage{nccmath}
\usepackage{url}
\graphicspath{ {images/} }


\setlength{\oddsidemargin}{1pt}
\setlength{\evensidemargin}{1pt}
\setlength{\marginparwidth}{30pt} % these gain 53pt width
\setlength{\topmargin}{1pt}       % gains 26pt height
\setlength{\headheight}{1pt}      % gains 11pt height
\setlength{\headsep}{1pt}         % gains 24pt height
%\setlength{\footheight}{12 pt} 	  % cannot be changed as number must fit
\setlength{\footskip}{24pt}       % gains 6pt height
\setlength{\textheight}{650pt}    % 528 + 26 + 11 + 24 + 6 + 55 for luck
\setlength{\textwidth}{460pt}     % 360 + 53 + 47 for luck

\title{Sections and Chapters}

\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}{Proposition}[section]
\newtheorem{exercise}{Exercise}[section]
\newtheorem{remark}{Remark}[section]
\theoremstyle{definition}
\newtheorem{example}{Example}[section]
\numberwithin{equation}{subsection}

\def\dsp{\def\baselinestretch{1.35}\large
\normalsize}
%%%%This makes a double spacing. Use this with 11pt style. If you
%%%%want to use this just insert \dsp after the \begin{document}
%%%%The correct baselinestretch for double spacing is 1.37. However
%%%%you can use different parameter.


\def\U{{\mathcal U}}

\begin{document}

\centerline{\Large \bf Analysis Qualifying Exam}
\centerline{Zhen Yao}

\bigskip

\section{May 2019 Exam}

\noindent{\bf Problem 1.}
Let $\sigma > 0$. Let $\left\{f_k\right\}_{k\in \mathbb{N}}$ be a sequence of functions $f_k: \mathbb{R} \to \mathbb{R}$ with $f_k(0) = 0$. Moreover, let $\left\{A_k\right\}_{k\in \mathbb{N}} \subset [0,\infty)$ be a {\it bounded} sequence of real numbers such that 
\begin{align*}
    \left|f_k(x) - f_k(y)\right| \leq A_k |x - y|^\sigma \,\, \text{for all} \,\, x, y\in \mathbb{R}.
\end{align*}
\begin{enumerate}[label=(\alph*)]
    \item Show that there exists $f: \mathbb{R}\to \mathbb{R}$ such that a subsequence $f_{k_i}$ converges uniformly to $f$ in every interval $[-a,a], a > 0$.
    
    \item* Show that $f$ satisfies 
    \begin{align*}
        |f(x) - f(y)| \leq A|x - y|^\sigma,
    \end{align*}
    where $A = \liminf_{k\to\infty}A_k$.
\end{enumerate}
\begin{proof}
~\begin{enumerate}[label=(\alph*)]
    \item First, since $\left\{A_k\right\}_{k\in \mathbb{N}}$ is bounded, then there exists $M > 0$ such that for all $k > 0, \left|A_k\right| < M$. For all $k > 0$ and all $x\in [-a,a]$, with $f_k(0) = 0$, we have
    \begin{align*}
        \left|f_k(x)\right| = \left|f_k(x) - f_k(0)\right| \leq A_k |x|^\sigma \leq a^\sigma M.
    \end{align*}
    Then, $\left\{f_k\right\}_{k\in \mathbb{N}}$ is bounded.
    
    Second, we want to prove that $\left\{f_k\right\}_{k\in \mathbb{N}}$ is equicontinuous. For $\forall \varepsilon > 0$, there exists $\delta = \left(\frac{\varepsilon}{M}\right)^{\frac{1}{\sigma}}$, then for $\forall f_k, \forall x, y \in [-a,a]$, if $|x - y| \leq \delta$, then 
    \begin{align*}
        \left|f_k(x) - f_k(y)\right| \leq A_k |x - y|^\sigma \leq M \frac{\varepsilon}{M} = \varepsilon.
    \end{align*}
    Then the set of all $f_k$ is compact. By Arzela-Ascoli theorem, there exists subsequence of $f_k$ converges uniformly to $f$ on $[-a,a]$.
    
    \item 
    \begin{enumerate}[label = \arabic*)]
        \item We use diagonal method to prove that there exists a subsequence $\left\{f_{k_i}\right\}^\infty_{i=1}$ of $\left\{f_k\right\}_{k\in \mathbb{N}}$ converging pointwise to $f$ on $\mathbb{R}$. For interval $[-1,1]$, $\left\{f_k\right\}_{k\in \mathbb{N}}$ has a convergent subsequence, denoted by $f_{11}, f_{12}, \cdots$. Now the sequence $\left\{f_{1n}\right\}$ is bounded on the interval $[-2,2]$, thus it has convergent subsequence, denoted by $f_{21}, f_{22}, \cdots$. Continue this process and we have subsequences
        \begin{align*}
            & f_{11}, f_{12}, f_{13}, \cdots \\
            & f_{21}, f_{22}, f_{23}, \cdots \\
            & f_{31}, f_{32}, f_{33}, \cdots \\
            & \cdots 
        \end{align*}
        and sequence in each line is a subsequence of the previous one. Now we select $f_{11}, f_{22}, f_{33}, \cdots$. 
    
        Now we claim $\{f_{nn}\}$ is pointwise convergent at every point in $\mathbb{R}$. First, $\{f_{nn}(x), x \in [-i, i]\}$ is convergent for for every $i = 1,2,\cdots$. Indeed, the sequence 
        $$f_{11}(x), f_{22}(x), f_{33}(x), \cdots$$
        is a subsequence of the convergent sequence $f_{i1}(x), f_{i2}(x), f_{i3}(x), \cdots$. Second, let $\varepsilon > 0$, take $\delta > 0$ as before. Then, for $\forall x \in \mathbb{R}$, and $|x - y| < \delta$, there exists $N_1 > 0$ such that $x, y\in [-N_1,N_2] \subset [-a,a]$. Since the sequence $f_{nn}(y)$ is convergent, then there is $N_2 > 0$ such that for all $n,m \geq N_2$, 
        \begin{align*}
            \left|f_{nn}(y) - f_{mm}(y)\right| \leq \varepsilon.
        \end{align*}
        Now, for $N = \max\{N_1, N_2\}$, and $\forall n, m > N$, if $|x - y| < \delta$, then 
        \begin{align*}
            \left|f_{nn}(x) - f_{mm}(x)\right| & \leq \left|f_{nn}(x) - f_{nn}(y)\right| + \left|f_{nn}(y) - f_{mm}(y)\right| + \left|f_{nn}(y) - f_{mm}(x)\right| \leq 3 \varepsilon.
        \end{align*}
        Hence, $\{f_{nn}(x)\}$ is convergent as a Cauchy sequence. Set $f(x) = \lim_{m\to\infty}f_{mm}(x)$, then for $x\in \mathbb{R}$, there exists $N > 0$ such that for all $n > N$, 
        \begin{align*}
            \left|f_{nn}(x) - f(x)\right| \leq 3\varepsilon.
        \end{align*}
        Thus, $\{f_{nn}(x)\}$ is pointwise convergent to $f(x)$ on $\mathbb{R}$.
        
        \item Now we have a subsequence $\{f_{k_i}\}$ of $\{f_k\}$ such that for any $x \in \mathbb{R}$, $\lim_{i\to \infty}f_{k_i}(x) = f(x)$. Then, 
        \begin{align*}
            \left|f(x) - f(y)\right| = \lim_{i\to\infty} \left|f_{k_i}(x) - f_{k_i}(y)\right|.
        \end{align*}
        Also, we know a proposition about $\liminf$ \footnote{This proposition states that let $\{x_n\}$ be a bounbed sequence in $\mathbb{R}$ and $a\in \mathbb{R}$, if $a > \liminf x_n$, then there exists $k \in \mathbb{N}$ such that for all $n \geq k$, $x_n > a$.} that if $H > \liminf_{k\to\infty} A_k$, then there exists $N > 0$, for all $k > N$, such that $A_k < H$\cite{1}. Then we take $H = \liminf_{k\to\infty}A_k + \varepsilon$ and let $\varepsilon \to 0$, then we have $\lim_{i\to\infty} \left|f_{k_i}(x) - f_{k_i}(y)\right| \leq \liminf_{k\to\infty}A_k |x - y|^\sigma$.
    \end{enumerate}
\end{enumerate}
\end{proof}

\medskip

\noindent{\bf Problem 2*.}
Prove that if $X$ is a metric space and $f:X \times [0,1] \to \mathbb{R}$ is a continuous function, then $g:X \to \mathbb{R}$, defined by $g(x) = \sup_{t\in [0,1]}f(x,t)$ is also continuous. 
\begin{proof}
Prove by contradiction and suppose $g$ is not continuous. Then there exists $\varepsilon > 0$, for all $\delta > 0$, there exists $x_0 \in X$ such that if $d_X(x,x_0) < \delta$, then $|g(x) - g(x_0)| > \varepsilon$. 

Fix such $\varepsilon$ and pick $\delta = 1/n$, then there exists $x_n \in X$ such that if $d_X(x_n, x_0) < \delta$, then $|g(x_n, x_0)| > \varepsilon$, i.e., 
\begin{align*}
    \left|\sup_{t}f(x_n,t) - \sup_{t}f(x_0,t)\right| > \varepsilon.
\end{align*}
Also, there exists $t_n, t_0 \in [0,1]$ such that $f(x_n, t_n) = \sup_{t}f(x_n,t)$ and $f(x_n, t_0) = \sup_{t}f(x_0,t)$. Then, we have 
\begin{align*}
    \left|f(x_n,t_n) - f(x_0,t_0)\right| > \varepsilon,
\end{align*}
where $x_n \to x_0$. Since $\{t_n\}$ is bounded in compact set $[0,1]$, then it has a convergent subsequence $\{t_{n_k}\}$ such that $t_{n_k}\to s$ and $f(x_{n_k}, t_{n_k}) \to f(x_n, s)$ since $f$ is continuous. Then, 
\begin{align*}
    f\left(x_{n_k}, t_{n_k}\right) & = \sup_{t} f\left(x_{n_k}, t\right) \geq f\left(x_{n_k}, t_0\right), \\
    f\left(x_n, t_0\right) & = \sup_{t}f(x_n,t) \geq f(x_n, s),
\end{align*}
which yields
\begin{align*}
    f\left(x_n, t_0\right) \gets f\left(x_{n_k}, t_0\right) \leq f\left(x_{n_k}, t_{n_k}\right) \to f\left(x_n, s\right) \leq f\left(x_n, t_0\right).
\end{align*}
Thus, $f\left(x_{n_k}, t_{n_k}\right) \to f\left(x_n, t_0\right)$, which is a contradiction.
\end{proof}

\medskip

\noindent{\bf Problem 3*.}
Prove that there is no continuous and one-to-one function $f:\mathbb{R}^2 \to \mathbb{R}$. \textbf{Hint:} \textit{Assume that such a function exists and then restrict the function to the unit circle in $\mathbb{R}^2$}.
\begin{proof}
Let $S^1 = \{(x,y)| x^2 + y^2 = 1\}$. Suppose there exists continuous and one-to-one function $f: S^1 \to \mathbb{R}$. Now let $g(x) = f(x) - f(-x)$, then $g$ is also continuous. And,
\begin{align*}
    g(-x) = f(-x) - f(x) = - g(x),
\end{align*}
then $g$ is an odd function. If $g(x) = 0$, then $f(x) = -f(x)$. If not, then $g(x) > 0$ and $g(-x) < 0$ of $g(x) < 0$ and $g(-x) > 0$. In either case, $S^1$ is a connected subspace of $\mathbb{R}^2$, with intermediate value theorem, there exists $c$ between $x$ and $-x$ such that $g(c) = 0$. Thus, $f(c) = f(-c)$. Thus, $f$ cannot be one-to-one, which is a contradiction\cite{2}.
\end{proof}

We present another approach to prove this problem.
\begin{proof}
Since $S^1$ is compact, then $f$ attains maximum $a$ at some point $x_a \in S^1$ and minimum $b < a$ at some point $x_b \in S^1$. These two points separate the circle into two arcs. On each of the two arcs, the function $f$ will attain $\frac{a+b}{2}$ at some points, denoted by $x_1$ and $x_2$, since $f$ is continuous. Then $f(x_1) = f(x_2)$, which is contradicted by the fact that $f$ is one-to-one\cite{3}.
\end{proof}

\medskip

\noindent{\bf Problem 4.}
Suppose $f: \mathbb{R}^2_+ \to \mathbb{R}$ is a continuous function defined on
\begin{align*}
    \mathbb{R}^2_+ = \{(x,y): x \in \mathbb{R}, y > 0\}.
\end{align*}
Assume also that the limits
\begin{align*}
    g(u,v) & = \lim_{t \to 0} \frac{f((u+t)\cos v, (u+t)\sin v) - f(u\cos v, u\sin v)}{t}, \\
    h(u,v) & = \lim_{t \to 0} \frac{f(u\cos (v+t), u\sin (v+t)) - f(u\cos v, u\sin v)}{t},
\end{align*}
exist and define continuous functions $g, h$ on the domain $D = \{(u,v): u > 0, 0 < v < \pi\}$. Prove that the function $f$ is differentiable on $\mathbb{R}^2_+$.
\begin{proof}
Define $M(u,v) = f(u\cos v, v\sin v) = f(x,y)$, where $u > 0, 0 < v < \pi$. And by assumption, $\frac{\partial M}{\partial u}$ and $\frac{\partial M}{\partial v}$ exist and are continuous. Then, for any $(u_1, v_1), (u_2, v_2) \in D$, there exist $\xi \in (u_1, u_2)$ and $\zeta \in (v_1,v_2)$ such that
\begin{align*}
    M(u_2,v_2) - M(u_1,v_1) & = M(u_2,v_2) - M(u_1,v_2) + M(u_1,v_2) - M(u_1,v_1) \\
    & = \frac{\partial M}{\partial u}(\xi, v_2)(u_2 - u_1) + \frac{\partial M}{\partial v}(u_1, \zeta)(v_2 - v_1).
\end{align*}
Then,
\begin{align*}
    & \lim_{(u_2,v_2) \to (u_1,v_1)}  \frac{\left|M(u_2,v_2) - M(u_1,v_1) - \frac{\partial M}{\partial u}(u_1, v_1)(u_2 - u_1) - \frac{\partial M}{\partial v}(u_1, v_1)(v_2 - v_1) \right|}{\left\|(u_2,v_2) - (u_1,v_1)\right\|} \\
    \leq & \underbrace{\left(\left|\frac{\partial M}{\partial u}(\xi, v_2) - \frac{\partial M}{\partial u}(u_1, v_1)\right| + \left|\frac{\partial M}{\partial v}(u_1, \zeta) - \frac{\partial M}{\partial u}(u_1, v_1)\right| \right)}_{\to 0} \underbrace{\frac{|u_2 - u_1|}{\left\|(u_2,v_2) - (u_1,v_1)\right\|}}_{\leq 1} \to 0.
\end{align*}
Thus, $M(u,v)$ is differentiable in $D$. So is $f$ on $\mathbb{R}^2_+$.
\end{proof}

We present another approach to prove this problem.
\begin{proof}
For any $(x_1, y_1), (x_2, y_2) \in \mathbb{R}^2_+$, there exist $(u_1, v_1), (u_2, v_2) \in D$ such that $(x_1, y_1) = (u_1 \cos v_1, u_1 \sin v_1)$ and $(x_2, y_2) = (u_2 \cos v_2, u_2 \sin v_2)$. Then,
\begin{align*}
    & \lim_{(x_2,y_2) \to (x_1,y_1)} \frac{\left|f(x_2,y_2) - f(x_1,y_1) - g(u_1,v_1)(u_2 - u_1) - h(u_1,v_1)(v_2 - v_1) \right|}{\sqrt{(x_2-x_1)^2 + (y_2-y_1)^2}} \\
    = & \lim_{(x_2,y_2) \to (x_1,y_1)} | f(u_2 \cos v_2, u_2 \sin v_2) - f(u_1 \cos v_2, u_2 \sin v_2) + f(u_1 \cos v_2, u_2 \sin v_2) \\
    & - f(u_1 \cos v_1, u_1 \sin v_1) - g(u_1,v_1)(u_2 - u_1) - h(u_1,v_1)(v_2 - v_1)| / \|x_2-x_1, y_2-y_1\| \\
    = &\,\,  0,
\end{align*}
where in the last step we used the definition of $g(u,v)$ and $h(u,v)$. Thus, $f$ is differentiable in $\mathbb{R}^2_+$.
\end{proof}

\medskip

\noindent{\bf Problem 5.}
Let $f \in C^2(\Omega) \cap C^0(\overline{\Omega})$, where $\Omega \subset \mathbb{R}^n$ is open and bounded.
Let $\Delta f = \sum_{i=1}^n \partial^2f/\partial x_i^2$ be the Laplace operator.
\begin{enumerate}
    \item[(a)] Show that if for some $\varepsilon > 0$ and $x_0 \in \Omega$ we have $\Delta f(x_0) \geq \varepsilon$, then $f$ has no local maximum at $x_0$.
    
    \item[(b)] Conclude that if $\Delta f(x) \geq \varepsilon$ for some $\varepsilon > 0$ and all $x \in \Omega$, then we have $\sup_{\Omega} f = \sup_{\partial \Omega} f$.
    
    \item[(c)] Conclude that if $\Delta f(x) \geq 0$ for all $x \in \Omega$, then we have $\sup_{\Omega} f = \sup_{\partial \Omega} f$.
\end{enumerate}
{\bf Hint for part (c):} {\em Observe that $\Delta |x|^2 = 2n$. Use it to modify a function $f$ in (c) so that you can apply part (b).}
\begin{proof}
~\begin{enumerate}
    \item[(a)] Local maximum requires that $H_{x_0}(f)$ is positive semidefinitely, which means the trace $\partial^2f/\partial x_i^2, i = 1,2,\cdots,n$ of $H_{x_0}(f)$ are not positive. This is a contradiction with the fact $\Delta f(x_0) \geq \varepsilon$, then $f$ has no local maximum at $x_0$.
    
    \item[(b)] With (a), we can know that $f$ has no local maximum in $\Omega \setminus \partial \Omega$. Thus, $\sup_{\Omega} f = \sup_{\partial \Omega} f$.
    
    \item[(c)] Let $f_\varepsilon(x) = f(x) + \varepsilon |x|^2$, then $\Delta f_\varepsilon(x) = \Delta f(x) + 2 \varepsilon n$. Then, we have
    \begin{align*}
        \sup_{\Omega} f(x) \leq \sup_{\Omega} f_\varepsilon(x) \leq \sup_{\partial\Omega} f_\varepsilon(x) \leq \sup_{\partial \Omega} f(x) + 2 \varepsilon n \xrightarrow{\varepsilon \to 0} \sup_{\partial \Omega} f(x).
    \end{align*}
\end{enumerate}
\end{proof}

\medskip

\noindent{\bf Problem 6.}
For $x = (x_1, x_2) \in \mathbb{R}^2$, let $|x| = \sqrt{x_1^2 + x_2^2}$. Let $D = \{x \in \mathbb{R}^2: |x| < 1\}$ and let $f: \overline{D} \to \mathbb{R}$ be continuous on $\overline{D}$. Prove that
\begin{align*}
    \lim_{n\to\infty} \int\int_D (n + 2)|x|^n f(x)\, dA = \int^{2\pi}_0 f(\cos t, \sin t)\, dt.
\end{align*}
\begin{proof}
Since $\overline{D}$ is compact, then $f$ attains maximum on $\overline{D}$, then there exists $M$ such that $|f(x)| \leq M, \forall x \in \overline{D}$. With polar coordinates, we want to prove that 
\begin{align*}
    \lim_{n\to\infty} \int^{2\pi}_0 \int^1_0 (n+2) |r|^{n+1} \left[f(r\cos t,r\sin t) - f(\cos t, \sin t) \right] \, dr dt = 0.
\end{align*}
Indeed, for any $\varepsilon > 0$, choose $a < 1$ such that $|f(r\cos t,r\sin t) - f(\cos t, \sin t)| < \varepsilon$ for $a < r < 1$, then 
\begin{align*}
    & \left| \int^{2\pi}_0 \int^1_0 (n+2) |r|^{n+1} \left[f(r\cos t,r\sin t) - f(\cos t, \sin t) \right] \, dr dt \right| \\
    \leq & \left| \int^{2\pi}_0 \int^a_0 (n+2) |r|^{n+1} \left[f(r\cos t,r\sin t) - f(\cos t, \sin t) \right] \, dr dt \right| \\
    & + \left| \int^{2\pi}_0 \int^1_a (n+2) |r|^{n+1} \left[f(r\cos t,r\sin t) - f(\cos t, \sin t) \right] \, dr dt \right| \\
    \leq & \underbrace{\int^{2\pi}_0 2 M a^{n+2} \, dt}_{\to 0\,\,{\rm as}\,\, n \to \infty}  + \underbrace{\int^{2\pi}_0 (n+2) \varepsilon \, dt}_{\to 0\,\,{\rm as}\,\, \varepsilon \to 0} \to 0.
\end{align*}
Thus, we complete the proof\footnote{This method comes from homework for Math1530 Advanced Calculus I: Let $f:[0,1] \to \mathbb{R}$ be continuous function. Prove that $\lim_{n\to\infty} n \int^1_0 x^n f(x)\, dx = f(1)$.}.
\end{proof}

\newpage

\section{August 2018 Exam}
\noindent{\bf Problem 1.}
For $n$ a positive integer, put:
\begin{align*}
    t_n = \frac{1}{2n + 1} - \frac{1}{2n + 2} + \frac{1}{2n + 3} - \frac{1}{2n + 4} + \cdots + \frac{1}{4n - 1} - \frac{1}{4n},
\end{align*}
with $2n$ terms in the right hand side. Find, with proof, the following limit $\mathcal{T}$:
\begin{align*}
    \mathcal{T} = \lim_{n\to\infty} nt_n.
\end{align*}
{\bf Hint:} {\em Relate the given limit to suitable Riemann sums for the function $(1 + x)^{-1}$.}
\begin{proof}
\begin{align*}
    \mathcal{T} & = n \left(\frac{1}{2n + 1} + \frac{1}{2n + 3} + \cdots + \frac{1}{4n - 1}\right) - n \left(\frac{1}{2n + 2} + \frac{1}{2n + 4} + \cdots +  \frac{1}{4n}\right) \\
    & = n \int^2_0 \frac{1}{2 + x}\, dx - 2n \int^1_0 \frac{1}{1 + x}\, dx \\
    & = n\ln 4 - n\ln 2 - n\ln 2 \\
    & = 0.
\end{align*}
\end{proof}

\medskip

\noindent{\bf Problem 2*.}\cite{4}
Prove that if $f: [a,b] \to \mathbb{R}$ is continuous, the 
\begin{align*}
    \lim_{n\to\infty} \sqrt[n]{\int^b_a |f(x)|^n\, dx} = \sup_{x\in[a,b]} |f(x)|.
\end{align*}
\begin{proof}
~\begin{enumerate}[label=(\alph*)]
    \item Since $f$ is continuous on compact space $[a,b]$, then $f$ attains its maximum at some point $c \in [a,b]$ such that $|f(c)| = \sup_{x\in[a,b]} |f(x)| = M$. Then\footnote{We cannot use $\lim$ here since we could use it unless the limit exists. However, we do not know the limit exists. Thus, we use $\liminf$ and $\limsup$.},
    \begin{align*}
        \limsup_{n\to\infty} \sqrt[n]{\int^b_a |f(x)|^n\, dx} & \leq \limsup_{n\to\infty} M (b - a)^{\frac{1}{n}} = \sup_{x\in[a,b]} |f(x)|.
    \end{align*}
    
    \item Given $\varepsilon > 0$, it follows from the continuity of $|f|$ that $|f(x)| \geq M - \varepsilon$ for all $x \in [a,b]$ in some interval $I$ that contains $c$. Then,
    \begin{align*}
        \liminf_{n\to\infty} \sqrt[n]{\int^b_a |f(x)|^n\, dx} & \geq  \liminf_{n\to\infty} \sqrt[n]{\int_I |f(x)|^n\, dx} \geq \liminf_{n\to\infty} (M - \varepsilon) |I|^{\frac{1}{n}} = M - \varepsilon.
    \end{align*}
    Since the above inequality holds for any $\varepsilon > 0$, then taking $\varepsilon \to 0$ gives
    \begin{align*}
        M \leq \liminf_{n\to\infty} \sqrt[n]{\int^b_a |f(x)|^n\, dx} \leq \limsup_{n\to\infty} \sqrt[n]{\int^b_a |f(x)|^n\, dx} \leq M.
    \end{align*}
    Thus, the equality holds.
\end{enumerate}
\end{proof}

\medskip

\noindent{\bf Problem 3.}
Let $\mathcal{M}$ denote the space of all real $2 \times 2$ matrices, equipped with the norm $\|A\| = \sqrt{{\rm tr} \left(A^T A\right)}$, for $A \in \mathcal{M}$. Consider the map $F$ from $\mathbb{R}^2$ to $\mathcal{M}$ given by formula, for any $(s,t) \in \mathbb{R}^2$:
\begin{align*}
    F(s,t) = \frac{1}{2} 
    \begin{vmatrix}
        \cos t + \cos s & \sin t + \sin s \\
        - \sin t + \sin s & \cos t - \cos s
    \end{vmatrix}.
\end{align*}
Denote by $\mathcal{N} \subset \mathcal{M}$ the space of all real $2 \times 2$ matrices of rank one and norm one. Prove that the image of $F$ is the space $\mathcal{N}$ and that the map $F$ is a local homeomorphism to its image. 
\begin{proof}
~\begin{enumerate}[label=(\alph*)]
    \item \begin{enumerate}[label=\arabic*)]
        \item Firstly, consider the elementary row operation of $F(s,t)$, which is
        \begin{align*}
            F(s,t) \to \frac{1}{2} 
            \begin{vmatrix}
                \cos t + \cos s & \sin t + \sin s \\
                0 & (\cos t - \cos s) + \frac{\sin^2 t - \sin^2 s}{\cos t + \cos s}
            \end{vmatrix} \to 
            \frac{1}{2}\begin{vmatrix}
                \cos t + \cos s & \sin t + \sin s \\
                0 & 0
            \end{vmatrix}.
        \end{align*}
        Also, $F(s,t)$ has rank one. Also, we have 
        $$\sqrt{{\rm tr} \left(F^T F\right)} = \sqrt{1/2 (\cos^2 t + \sin^2 t + \cos^2 s + \sin^2 s)} = 1.$$ 
        Thus, $F$ maps $\mathbb{R}^2$ to $\mathcal{N}$.
        
        \item Now we need to prove that $F$ is onto $\mathcal{N}$. For any matrix $A \in \mathcal{N}$, since $\rank A = 1$, we can assume 
        \begin{align*}
            A = \begin{vmatrix}
            a & b \\
            ka & kb
            \end{vmatrix},
        \end{align*}
        and then with norm being one, we have $(k^2 + 1)(a^2 + b^2) = 1$. 
        
        Now take\cite{5}
        \begin{align*}
            a & = \frac{\cos t + \cos s }{2} = \cos\left(\frac{t+s}{2}\right) \cos \left(\frac{t-s}{2}\right), \\
            b & = \frac{\sin t + \sin s }{2} = - \cos \left(\frac{t+s}{2}\right) \sin \left(\frac{t-s}{2}\right),
        \end{align*}
        and plug it back into $(k^2 + 1)(a^2 + b^2) = 1$ gives $k^2 = \sin^2 \left(\frac{t-s}{2}\right)/\cos^2 \left(\frac{t-s}{2}\right)$. Choosing $k = - \sin \left( \frac{t-s}{2} \right)/\cos \left( \frac{t-s}{2} \right)$ implies that $A$ can be represent by $F(s,t)$. Thus, $F$ is onto. Hence, the image of $F$ is the space $\mathcal{N}$.
    \end{enumerate}
    
    \item* The space $\mathcal{N}$ can be characterised as
    \begin{align*}
        \mathcal{N} = \left\{ \begin{pmatrix}
            a & b \\ 
            c & d
        \end{pmatrix}: a^2 + b^2 + c^2 + d^2=1, ad-bc = 0\right\}.
    \end{align*}
    The map $F$ can be viewed from $(s,t)$ to $\begin{pmatrix}
        x(s,t) & y(s,t) \\ 
        z(s,t) & w(s,t)
    \end{pmatrix}$, and the map $\begin{pmatrix}
        x & y\\ 
        z & w
    \end{pmatrix} \to \begin{pmatrix}
        a & b \\ 
        c & d
    \end{pmatrix}$ is a linear transformation and hence a homeomorphism\cite{6}.
\end{enumerate}
\end{proof}

\medskip

\noindent{\bf Problem 4*.}
Let $\mathcal{F} \subset C^\infty[0,1]$ be a uniformly bounded and equicontinuous family of smooth functions on $[0,1]$ such that $f' \in \mathcal{F}$ whenever $f \in \mathcal{F}$. Suppose that 
\begin{align*}
    \sup_{x\in[0,1]} \left|f'(x) - g'(x)\right| \leq \frac{1}{2} \sup_{x\in[0,1]} \left|f(x) - g(x)\right|, \,\, {\rm for all}\,\, f, g \in \mathcal{F}.
\end{align*}
Show that there exists a sequence $f_n$ of functions in $\mathcal{F}$ that converges uniformly to $Ce^x$ for some real value $C$.\\
{\bf Hint:} {\em Use the contraction principle. In order to apply the the contraction principle you can use, without proof, the fact that if $X$ is a complete metric space, $A \subset X$ and $T: A \to X$ is uniformly continuous, then $T$ uniformly converges to a continuous map $\overline{T}: \overline{A} \to X$ defined on the closure $\overline{A}$.}
\begin{proof}
$\mathcal{F}$ is a subset of the complete metric space $\left(C([0,1]), d_\infty \right)$. Let $\overline{\mathcal{F}}$ be the closure in that space, clearly, $\left(\overline{\mathcal{F}}, d_\infty \right)$ is a complete metric space as a closed subset of a metric space\footnote{If $X$ is a complete metric space, then a subset of $X$ is closed if and only if it is complete.\cite{7}} \footnote{{\bf Theorem:} Let $A \subset X$ be a closed subspace of a complete metric space $(X, d)$, then
$(A, d)$ is a complete metric space as well.\cite{8}}. The mapping $T: \mathcal{F} \to \mathcal{F} \subset \overline{\mathcal{F}}, Tf = f'$ satisfies
\begin{align*}
    d_\infty(Tf, Tg) \leq \frac{1}{2} d_\infty(f, g), \,\, \forall f,g \in \mathcal{F}.
\end{align*}
That means $T: \mathcal{F} \to \overline{\mathcal{F}}$ is Lipschitz continuous and hence uniformly continuous\cite{9}. Extend $T$ uniquely to a continuous mapping $\overline{T}: \overline{\mathcal{F}} \to \overline{\mathcal{F}}$ \footnote{Let $\left(X, d_X\right)$ be a metric space, $A \subset X$ is a dense subset and $\left(Y, d_Y\right)$ a complete metric space. If $f: A \to Y$ is uniformly continuous, then there is a unique continuous function $F: X \to Y$ such that $F(x) = f(x)$ for all $x \in A$. Also, $F$ is uniformly continuous.} such that 
\begin{align*}
    \overline{T}f = Tf = f', \,\, f \in \mathcal{F}.
\end{align*}
Note that 
\begin{align*}
    d_\infty \left(\overline{T}f, \overline{T}g \right) \leq \frac{1}{2} d_\infty (f,g), \,\, f, g \in \overline{\mathcal{F}}.
\end{align*}
Indeed, if $f, g \in \overline{\mathcal{F}}$, then there exists $\mathcal{F} \ni f_n \rightrightarrows f$ and $\mathcal{F} \ni g_n \rightrightarrows g$. Then,
\begin{align*}
    d_\infty \left(\overline{T}f, \overline{T}g \right) = \lim_{n\to\infty} d_\infty \left(\overline{T}f_n, \overline{T}g_n \right) \leq \lim_{n\to\infty} \frac{1}{2} d_\infty \left(f_n, g_n\right) = \frac{1}{2} d_\infty (f,g).
\end{align*}
Thus, $\overline{T}: \overline{\mathcal{F}} \to \overline{\mathcal{F}}$ is a contraction. Since $\left(\overline{F}, d_\infty \right)$ is complete, then $\overline{T}$ has a unique fixed point $\overline{T} f = f$. However, we cannot claim that $\overline{T}f = f'$, since $\overline{T}$ is defined as an extension of $Tg = g'$ to the space $\overline{\mathcal{F}}$ of continuous functions. 

However, we can argue as follows. If $g \in \mathcal{F} \subset \overline{\mathcal{F}}$ is any function, with the contraction principle, the iterations $\mathcal{F} \ni g_n = g^{(n)} = T^n g = \overline{T}^n g \rightrightarrows f$ converge uniformly to the unique fixed point of $\overline{T}$. Note that 
\begin{align*}
    g_n' = g^{(n+1)} = g_{n+1} \rightrightarrows f.
\end{align*}
Since $g_n \rightrightarrows f$, then $g_n' \rightrightarrows f$, and thus $f$ is differentiable and $f = f'$. For the completeness, 
\begin{align*}
    f(x) - f(0) \leftarrow g_n(x) - g_n(0) = \int^x_0 g_n'(t)\, dt \to \int^x_0 f_n'(t)\, dt,
\end{align*}
and then $f(x) - f(0) = \int^x_0 f_n'(t)\, dt$. Thus, $f'(x) = f(x)$ for $x \in [0,1]$, and hence $f(x) = Ce^x$ for some $C \in \mathbb{R}$. Indeed, 
\begin{align*}
    \left(f e^{-x} \right)' = f' e^{-x} - f e^{-x} = 0,
\end{align*}
and then $f e^{-x} = C$ for some $C$. Now we proved that if $g \in \mathcal{F}$, then
\begin{align*}
    \mathcal{F} \ni g_n = g^{n} \rightrightarrows C e^x.
\end{align*}
\end{proof}

\medskip

\noindent{\bf Problem 5*.}
Let $f: \mathbb{R}^n \to \mathbb{R}^n$ be a mapping of class $C^1$. Prove that there is an open and dense set $\Omega \subset \mathbb{R}^n$ such that the function $R(x) = \rank Df(x)$ is locally constant on $\Omega$, i.e., it is constant in a neighborhood of every point $x \in \Omega$.
\begin{proof}
Let $\Omega$ be the set of points where $R(x) = \rank Df(x)$ attains a local maximum, that is
\begin{align*}
    \Omega = \left\{x \,|\, \exists \varepsilon_1 > 0, \forall y \in B^n(x, \varepsilon), \rank Df(y) \leq \rank Df(x) \right\}.
\end{align*}
\begin{enumerate}[label=(\alph*)]
    \item We claim that $\Omega$ is open and $\rank Df$ is locally constant in $\Omega$. Indeed, $\{\rank Df \geq k\}$ is open \footnote{If $\rank Df(x) \geq k$, then the determinant of a certain $k\times k$ minor of $Df(x)$ is nonzero. Then we can choose a point $y \in B(x, \varepsilon)$ such that $\rank Df(y) \geq k$, since $\det$ function is continuous.}, so if $x \in \Omega$ and $\rank Df(x) = k$, then $\rank Df(y) \geq k$ in $B(x, \varepsilon_2)$. But $\rank Df$ attains locally maximum at $x$, then $\rank Df(y) = k$ in $B^n(x, \varepsilon)$, where $\varepsilon = \min \{\varepsilon_1, \varepsilon_2\}$. In particular, $B^n(x, \varepsilon) \subset \Omega$. This proves that $\Omega$ is open in $\Omega$ and $\rank Df$ is locally constant in $\Omega$. 
    
    \item It remains to prove that $\Omega$ is dense, Let $B^n(x, \varepsilon) \subset \mathbb{R}^n$ be any ball. It suffices to show that $\Omega \cap B^n(x, \varepsilon) \neq \varnothing$. Since $\rank Df$ attains only finitely many values, then it attains a global maximum in $B^n(x, \varepsilon)$, which is a local maximum in $\mathbb{R}^n$, so $\Omega \cap B^n(x, \varepsilon) \neq \varnothing$.
\end{enumerate}
\end{proof}

\medskip

\noindent{\bf Problem 6.}
Let $\Phi: \mathbb{R}^2 \to \Phi\left(\mathbb{R}^2\right) \subset \mathbb{R}^2$ be a diffeomorpism. Prove that
\begin{align*}
    \int_{B^2(0,1)} \left\|D\Phi \right\| = \int_{\Phi(B^2(0,1))} \left\|D\left(\Phi^{-1}\right) \right\|,
\end{align*}
where $\|A\| = \left(\sum^2_{i,j=1} a_{ij}^2\right)^{1/2}$ is the Hilbert-Schmidt norm of the matrix.\\
{\bf Hint:} {\em Compare $\|A\|$ and $\left\|A^{-1}\right\|$ for a $2 \times 2$ matrix.}
\begin{proof}
For $A = \begin{pmatrix} 
    a & b \\
    c & d
\end{pmatrix}$, we have $\|A\| = \left(a^2 + b^2 + c^2 + d^2\right)^{1/2}$, then $A^{-1} = \frac{1}{ad - bc}\begin{pmatrix} 
    d & -b \\
    -c & a
\end{pmatrix}$ and thus $\left\|A^{-1}\right\| = \frac{\left(a^2 + b^2 + c^2 + d^2\right)^{1/2}}{ad - bc}$. 

Now we consider $\Phi: \mathbb{R}^2 \to \Phi\left(\mathbb{R}^2\right) \subset \mathbb{R}^2$, and for $x \in \mathbb{R}^2$, there exists $y \in \mathbb{R}^2$, $\Phi(x) = y$. Then, with inverse function theory,
\begin{align*}
    \int_{\Phi(B^2(0,1))} \left\|D\left(\Phi^{-1}\right) \right\| & = \int_{B^2(0,1)} \left\|\left(D\Phi\right)^{-1} \right\| \det (D\Phi) \\
    & = \int_{B^2(0,1)} \left\|D\Phi \right\|,
\end{align*}
since in the last step, we used the fact that for $2 \times 2$ matrix $D\Phi$, we have
\begin{align*}
    \left\|\left(D\Phi\right)^{-1} \right\| \det (D\Phi) = \left\|D\Phi \right\|.
\end{align*}
\end{proof}







\newpage
\bibliographystyle{unsrt}
\bibliography{bibliography}


\end{document}
