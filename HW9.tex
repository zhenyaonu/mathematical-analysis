\documentclass[12pt,leqno]{amsart}
\pagestyle{plain}
\usepackage{latexsym,amsmath,amssymb}
\usepackage{amsthm}
%\usepackage[notref,notcite]{showkeys}
\usepackage{amsfonts}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{lmodern}
\usepackage{pifont}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{thmtools}
\usepackage{wrapfig}
\usepackage{extarrows}
\usepackage{breqn}

\usepackage{enumitem}
\graphicspath{ {images/} }

\setlength{\oddsidemargin}{1pt}
\setlength{\evensidemargin}{1pt}
\setlength{\marginparwidth}{30pt} % these gain 53pt width
\setlength{\topmargin}{1pt}       % gains 26pt height
\setlength{\headheight}{1pt}      % gains 11pt height
\setlength{\headsep}{1pt}         % gains 24pt height
%\setlength{\footheight}{12 pt} 	  % cannot be changed as number must fit
\setlength{\footskip}{24pt}       % gains 6pt height
\setlength{\textheight}{650pt}    % 528 + 26 + 11 + 24 + 6 + 55 for luck
\setlength{\textwidth}{460pt}     % 360 + 53 + 47 for luck

\theoremstyle{definition}
\newtheorem{problem}{Problem}
\setcounter{problem}{0}
%\numberwithin{problem}{chapter}
\renewcommand\theproblem{\arabic{problem}}


\def\dsp{\def\baselinestretch{1.35}\large
\normalsize}
%%%%This makes a double spacing. Use this with 11pt style. If you
%%%%want to use this just insert \dsp after the \begin{document}
%%%%The correct baselinestretch for double spacing is 1.37. However
%%%%you can use different parameter.


\def\U{{\mathcal U}}









\begin{document}





\centerline{\bf Homework 2 for Math 1540}
\centerline{Zhen Yao}

\bigskip





\noindent
{\bf Problem 20.}
Let $A=[a_{ij}]$ be the matrix of a linear mapping
$A\in L(\mathbb{R}^n,\mathbb{R}^m)$. Prove that the norm
$$
\Vert A\Vert=\sup_{\Vert x\Vert=1}\Vert Ax\Vert
$$
satisfies the inequality
$$
\Vert A\Vert \leq\left(\sum_{i=1}^m\sum_{j=1}^na_{ij}^2\right)^{1/2}.
$$
{\bf Hint:} {\em You may use the following argument: Write the components of
the vector $Ax$ as scalar products of rows on $A$ and $x$.
Then use the Schwarz inequality to estimate the length of the vector $Ax$.}
\begin{proof}
For $\forall x\in\mathbb{R}^n$, we have
\begin{align*}
    \|Ax\|^2 & = \sum^m_{i=1} \left(\sum^n_{j=1} a_{ij} x_j\right)^2 \\
    & \leq \sum^m_{i=1} \left(\sum^n_{j=1} a_{ij}^2 \right) \left(\sum^n_{j=1} x_{j}^2 \right) \\
    & = \left(\sum_{i=1}^m\sum_{j=1}^na_{ij}^2\right) \|x\|.
\end{align*}
Also, we can have
$$\|A\| = \sup_{\Vert x\Vert=1} \|Ax\| \leq \left(\sum_{i=1}^m\sum_{j=1}^na_{ij}^2\right)^{\frac{1}{2}}.$$
\end{proof}

\medskip

\noindent
{\bf Problem 21.}
Let $f:\mathbb{R}\to\mathbb{R}$ be differentiable and $F:\mathbb{R}^2\to\mathbb{R}$ be defined by
$F(x,y)=f(xy)$. Prove that
$$
x\frac{\partial F}{\partial x}=y\frac{\partial F}{\partial y}\, .
$$
\begin{proof}
We have $\frac{\partial F}{\partial x} = f'(xy)y$ and $\frac{\partial F}{\partial y} = f'(xy)x$. Thus, we have 
\begin{align*}
    x\frac{\partial F}{\partial x} = y\frac{\partial F}{\partial y} = xy f'(xy).
\end{align*}
\end{proof}

\medskip

\noindent
{\bf Problem 22.}
We say that a function $f:\mathbb{R}^n\to\mathbb{R}$ is homogeneous of degree $m$ if
$f(tx)=t^mf(x)$ for all $x\in\mathbb{R}^n$ and all $t>0$.
Prove that if $f$ is differentiable on $\mathbb{R}^n$ and homogeneous of
degree $m$, then
$$
\sum_{i=1}^n x_i\frac{\partial f}{\partial x_i}(x) = mf(x)
\quad
\mbox{for all $x\in\mathbb{R}^n$.}
$$
\begin{proof}
Differentiating both sides of the equation $f(tx)=t^mf(x)$ with respect to $t$ and we have
\begin{align*}
    x \cdot \nabla f(tx) = m t^{m-1} f(x).
\end{align*}
Choosing $t = 1$ and we have 
\begin{align*}
    x \cdot \nabla f(x) = \sum^n_{i=1} x_i \frac{\partial f}{\partial x_i}(x) = m f(x).
\end{align*}
\end{proof}

\medskip

\noindent
{\bf Problem 23.}
We know that a function $f(x,y)$ is differentiable at $(0,0)$. We also know the
directional derivatives
$$
\begin{array}{ccc}
D_uf(0,0)=1    & \mbox{where $u=[1/\sqrt{5},2/\sqrt{5}]$,}\\
D_vf(0,0)=1 &   \mbox{where $v=[1/\sqrt{2},1/\sqrt{2}]$}.
\end{array}
$$
Find the gradient $\nabla f(0,0)$.
\begin{proof}
We have 
\begin{align*}
    \left\{
    \begin{aligned}
        \frac{1}{\sqrt{5}}\frac{\partial f}{\partial x}(0,0) + \frac{2}{\sqrt{5}}\frac{\partial f}{\partial y}(0,0) = 1\\
        \frac{1}{\sqrt{2}}\frac{\partial f}{\partial x}(0,0) + \frac{1}{\sqrt{2}}\frac{\partial f}{\partial y}(0,0) = 1
    \end{aligned}
    \right.
\end{align*}
Then we have $\nabla f(0,0) = \left(\frac{\partial f}{\partial x}(0,0), \frac{\partial f}{\partial y}(0,0) \right) = \left(2\sqrt{2}-\sqrt{5}, \sqrt{5}-\sqrt{2} \right)$.
\end{proof}

\medskip

\noindent
{\bf Problem 24.}
Let $f\in C^1(\mathbb{R}^2)$ be such that $f(1,1)=1$ and $\nabla f(1,1)=(a,b)$.
Let $\varphi(x)=f(x,f(x,f(x,x)))$. Find $\varphi(1)$ and $\varphi'(1)$.
\begin{proof}
First, we have $\varphi(1) = f(1,f(1,f(1,1))) = f(1,f(1,1)) = f(1,1) = 1$. Second, we have
\begin{align*}
    \varphi'(1) & = \left(\frac{\partial f}{\partial x}(1,1), \frac{\partial f}{\partial f(x,f(x,x))} \left(\frac{\partial f(x,f(x,x))}{\partial x}, \frac{\partial f(x,f(x,x))}{\partial f(x,x)} \nabla f(x,x) \right)(1,1) \right) \\
    & = \nabla f(1,1)=(a,b).
\end{align*}
\end{proof}

\medskip

\noindent
{\bf Problem 25.}
A function $f:\mathbb{R}^n\to\mathbb{R}$ is differentiable. Find the derivative of the function
$$
F(t)=(f(t,t^2,\ldots,t^n))^2,\quad t\in\mathbb{R}
$$
of one variable.
\begin{proof}
We have
\begin{align*}
    F'(t) = 2 f(t,t^2,\ldots,t^n) (1 + 2t + \cdots + n t^{n-1}) \frac{\partial f}{\partial t}.
\end{align*}
\end{proof}

\medskip

\noindent
{\bf Problem 26.}
Verify by a direct computation that the vector field $F(x)=x|x|^{-n}$ defined on
$\mathbb{R}^n\setminus\{0\}$ is divergence free, i.e.
$$
{\rm div}\, F(x)=\sum_{i=1}^n \frac{\partial}{\partial x_i}\left(\frac{x_i}{|x|^n}\right) = 0
\quad
\mbox{for all $x\neq 0$.}
$$
\begin{proof}
\begin{align*}
    {\rm div}\, F(x) & = \sum^n_{i=1} \left(|x|^{-n} - n |x|^{-n-1} x_i^2\right) \\
    & = n |x|^{-n} - n |x|^{-n-2} |x|^2 = 0.
\end{align*}
\end{proof}

\medskip

\noindent
{\bf Problem 27.}
Prove that for $\alpha>0$ the function $\Phi:\mathbb{R}^n\to\mathbb{R}^n$,
$$
\Phi(x)=x|x|^\alpha
$$
is of class $C^1$. Find $D\Phi(x)$.
\begin{proof}
\begin{align*}
    D\Phi(x) & = \left(|x|^\alpha + \alpha x_1 |x|^{\alpha-1}, \cdots, |x|^\alpha + \alpha x_n |x|^{\alpha-1} \right).
\end{align*}
\end{proof}

\medskip

\noindent
{\bf Problem 28.}
Find all the points $(x,y)\in\mathbb{R}^2$ where the function
$$
f(x,y)=|e^x-e^y|\cdot(x+y-2)
$$
is differentiable.
\begin{proof}
We have $\frac{\partial F}{\partial x}(0,0) = 0$ and $\frac{\partial F}{\partial y}(0,0) = 0$, also $f$ is continuous at $(0,0)$. Then, $f$ is differentiable at $(0,0)$. Thus, $f$ is differentiable at every point.
\end{proof}


\medskip

\noindent
{\bf Problem 29.}
Consider the function $g : \mathbb{R}^2 \to \mathbb{R}$ given by
$$
g(x, y) = x^{2/3}y^{2/3}, \ \text{for all} \ (x, y) \in \mathbb{R}^2 \,
.
$$
Prove that $g$ is {\it differentiable} at $(0, 0)$.
\begin{proof}
We have $\frac{\partial g}{\partial x}(0,0) = 0$ and $\frac{\partial g}{\partial y}(0,0) = 0$. Also, we have
\begin{align*}
    \lim_{h\to0} \frac{h^{2/3}h^{2/3}}{h} = 0 = f(0,0).
\end{align*}
Thus, $f$ is continuous at $(0,0)$, hence differentiable at $(0,0)$.
\end{proof}

\medskip

\noindent
{\bf Problem 30.}
Find a function $f:\mathbb{R}^2\to\mathbb{R}$ that is differentiable at each point,
but whose partial derivatives are not continuous at $(0,0)$.
\begin{proof}
Take 
\begin{align*}
    f(x,y) = \left\{
    \begin{aligned}
        & (x^2 + y^2) \sin \left(\frac{1}{\sqrt{x^2 + y^2}}\right),\, {\rm if }\,\, (x,y)\neq (0,0)\\
        & 0, \, {\rm if }\,\, (x,y) = (0,0)
    \end{aligned}
    \right.
\end{align*}
Then we have 
\begin{align*}
    \frac{\partial f}{\partial x}(0,0) & = \lim_{h\to 0} \frac{f(h,0) - f(0,0)}{h} = \lim_{h\to 0} h \sin \left(1/|h|\right) = 0 \\
    \frac{\partial f}{\partial y}(0,0) & = \lim_{h\to 0} \frac{f(h,0) - f(0,0)}{h} = \lim_{h\to 0} h \sin \left(1/|h|\right) = 0 
\end{align*}
Also, we have
\begin{align*}
    \frac{\partial f}{\partial x}(x,y) & = 2x \sin \left(\frac{1}{\sqrt{x^2 + y^2}}\right) - \frac{x \cos \left(\frac{1}{\sqrt{x^2 + y^2}}\right)}{\sqrt{x^2 + y^2}} \\
    \frac{\partial f}{\partial y}(x,y) & = 2y \sin \left(\frac{1}{\sqrt{x^2 + y^2}}\right) - \frac{y \cos \left(\frac{1}{\sqrt{x^2 + y^2}}\right)}{\sqrt{x^2 + y^2}}
\end{align*}
which oscillate rapidly near the origin. Thus, the partial derivatives are not continuous at $(0,0)$.
\end{proof}

\medskip

\noindent
{\bf Problem 31.}
Prove that the partial derivatives (of first order) of a function
$f:\mathbb{R}^n\to\mathbb{R}$ exist everywhere and they are bounded, then
the function $f$ is continuous.
\begin{proof}
Let $x_0 = (x_{01},\cdots,x_{0n}) \in \mathbb{R}^n$ be arbitray, and define $f_i = \frac{\partial f}{\partial x_i}$. Since partial derivatives exist everywhere and bounded, then we define $M = \sum^n_{i=1}\sup |f_i(x)|, x\in \mathbb{R}^n$. Then, for $x = (x_1,\cdots,x_n)$, we have
\begin{align*}
    |f(x_0) - f(x)| \leq & |f(x_{01},\cdots,x_{0n}) - f(x_1, x_{02}, \cdots, x_{0n})| + \\
    & |f(x_1, x_{02}, \cdots, x_{0n}) - f(x_1, x_{2}, x_{03}, \cdots, x_{0n})| + \cdots  \\
    & + |f(x_{1},\cdots, x_{n-1}, x_{0n}) - f(x_1, \cdots, x_n)| \\
    \leq & M |(x_{01},\cdots,x_{0n}) - (x_1, x_{02}, \cdots, x_{0n})| + \\
    & M |(x_1, x_{02}, \cdots, x_{0n}) - (x_1, x_{2}, x_{03}, \cdots, x_{0n})| + \cdots  \\
    & M |(x_{1},\cdots, x_{n-1}, x_{0n}) - (x_1, \cdots, x_n)|,
\end{align*}
where in the last step we used Mean Value theorem. Thus, we can know that for any $x\in \mathbb{R}^n$, $f(x)$ is bounded.
\end{proof}

\medskip

\noindent
{\bf Problem 32.}
Prove that if $f,g\in C^k(\Omega)$, $\Omega\subset\mathbb{R}^n$, then for any multiindex
$\alpha$ with $|\alpha|\leq k$ we have
$$
D^\alpha(fg)=\sum_{\beta\leq \alpha}\binom{\alpha}{\beta}D^\beta f D^{\alpha-\beta}g\, ,
$$
where
$\beta\leq\alpha$ means that $\beta_i\leq\alpha_i$ for $i=1,2,\ldots,n$,
$\alpha-\beta=(\alpha_1-\beta_1,\ldots,\alpha_n-\beta_n)$ and 
$$
\binom{\alpha}{\beta}=\frac{\alpha!}{\beta!(\alpha-\beta)!}\, .
$$
\begin{proof}
We have
\begin{align*}
    D^1(fg) & = D^1f g + f D^1 g \\
    D^2(fg) & = D^2f g + D^1 f D^1 g + D^1 f D^1 g + f D^2 g \\
    & \cdots \\
    D^\alpha(fg) & = \sum_{\beta\leq \alpha}\binom{\alpha}{\beta}D^\beta f D^{\alpha-\beta}g,
\end{align*}
where it is like the Binomial theorem.
\end{proof}
\end{document}

